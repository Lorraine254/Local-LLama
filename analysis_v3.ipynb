{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.utilities import SQLDatabase \n",
    "from langchain_experimental.sql import SQLDatabaseChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"localhost\"\n",
    "database = \"LLama\"\n",
    "user = os.getenv('SQL_USER')\n",
    "password = os.getenv('SQL_PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transcript2', 'transcript', 'trial', 'trial2', 'trial 3', 'essays']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection_string = f\"postgresql://{user}:{password}@{host}/{database}\"\n",
    "engine = create_engine(connection_string)\n",
    "insp = inspect(engine)\n",
    "insp.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED   \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    3 days ago    \n",
      "llama2:latest              78e26419b446    3.8 GB    3 days ago    \n",
      "gemma:7b                   a72c7f4d0a15    5.0 GB    3 days ago    \n",
      "mistral:latest             f974a74358d6    4.1 GB    3 days ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"some kind of a crazy quantum mechanical system that somehow gives you buffer overflow, somehow\\ngives you a rounding error in the floating point.\\nSynthetic intelligences are kind of like the next stage of development.\\nAnd I don't know where it leads to.\\nLike at some point, I suspect the universe is some kind of a puzzle.\\nThese synthetic AIs will uncover that puzzle and solve it.\\nThe following is a conversation with Andrei Kapathe, previously the director of AI at\\nTesla, and before that at OpenAI and Stanford.\\nHe is one of the greatest scientists, engineers, and educators in the history of artificial\\nintelligence.\\nThis is the Lex Friedman podcast.\\nTo support it, please check out our sponsors.\\nAnd now, dear friends, here's Andrei Kapathe.\\nWhat is a neural network?\\nAnd why does it seem to do such a surprisingly good job of learning?\\nWhat is a neural network?\\nIt's a mathematical abstraction of the brain.\\nI would say that's how it was originally developed.\\nAt the end of the day, it's a mathematical expression.\\nIt's a fairly simple mathematical expression when you get down to it.\\nIt's basically a sequence of matrix multipliers, which are really dot products mathematically,\\nand some non-linearity is thrown in.\\nIt's a very simple mathematical expression, and it's got knobs in it.\\nMany knobs.\\nMany knobs.\\nThese knobs are loosely related to the synapses in your brain.\\nThey're trainable, they're modifiable.\\nThe idea is we need to find the setting of the knobs that makes the neural net do whatever\\nyou want it to do, like classify images and so on.\\nThere's not too much mystery, I would say, in it.\\nYou might think that you don't want to endow it with too much meaning with respect to the\\nbrain and how it works.\\nIt's really just a complicated mathematical expression with knobs, and those knobs need\\na proper setting for it to do something desirable.\\nYeah, but poetry is just a collection of letters with spaces, but it can make us feel a certain\\nway.\\nIn that same way, when you get a large number of knobs together, whether it's inside the\\nbrain or inside a computer, they seem to surprise us with their power.\\nI think that's fair.\\nI'm underselling it by a lot because you definitely do get very surprising emergent behaviors\\nout of these neural nets when they're large enough and trained on complicated enough problems,\\nlike say for example, the next word prediction in a massive data set from the internet.\\nThese neural nets take on pretty surprising magical properties.\\nYeah, I think it's interesting how much you can get out of even very simple mathematical\\nformalism.\\nWhen your brain right now is talking, is it doing next word prediction?\\nOr is it doing something more interesting?\\nWell, it's definitely some kind of a generative model that's a GPT-like and prompted by you.\\nSo you're giving me a prompt and I'm kind of responding to it in a generative way.\\nAnd by yourself perhaps a little bit?\\nAre you adding extra prompts from your own memory inside your head?\\nIt definitely feels like you're referencing some kind of a declarative structure of memory\\nand so on, and then you're putting that together with your prompt and giving away some answer.\\nHow much of what you just said has been said by you before?\\nNothing basically, right?\\nNo, but if you actually look at all the words you've ever said in your life and you do a\\nsearch, you'll probably have said a lot of the same words in the same order before.\\nYeah, could be.\\nI mean, I'm using phrases that are common, et cetera, but I'm remixing it into a pretty\\nunique sentence at the end of the day.\\nBut you're right, definitely there's a ton of remixing.\\nWhy, you didn't, it's like Magnus Carlsen said, I'm rated 2,900 whatever, which is pretty\\ndecent.\\nI think you're talking very, you're not giving enough credit to neural nets here.\\nWhy do they seem to, what's your best intuition about this emergent behavior?\\nI mean, it's kind of interesting because I'm simultaneously underselling them, but I also\\nfeel like there's an element to which I'm over, like it's actually kind of incredible\\nthat you can get so much emergent magical behavior out of them despite them being so\\nsimple mathematically.\\nSo I think those are kind of like two surprising statements that are kind of juxtaposed together.\\nAnd I think basically what it is, is we are actually fairly good at optimizing these neural\\nnets.\\nAnd when you give them a hard enough problem, they are forced to learn very interesting\\nsolutions in the optimization.\\nAnd those solution basically have these emergent properties that are very interesting.\\nThere's wisdom and knowledge in the knobs.\\nAnd so this representation that's in the knobs, does it make sense to you intuitively\\nthe large number of knobs can hold the representation that captures some deep wisdom about the data\\nit has looked at?\\nIt's a lot of knobs.\\nIt's a lot of knobs.\\nAnd somehow, you know, so speaking concretely, one of the neural nets that people are very\\nexcited about right now are GPTs, which are basically just next word prediction networks.\\nSo you consume a sequence of words from the internet and you try to predict the next word.\\nAnd once you train these on a large enough data set, you can basically prompt these neural\\nnets in arbitrary ways and you can ask them to solve problems and they will.\\nSo you can just tell them, you can make it look like you're trying to solve some kind\\nof a mathematical problem and they will continue what they think is the solution based on what\\nthey've seen on the internet.\\nAnd very often those solutions look very remarkably consistent, look correct potentially.\\nDo you still think about the brain side of it?\\nSo as neural nets is an abstraction or mathematical abstraction of the brain, you still draw wisdom\\nfrom the biological neural networks or even the bigger question.\\nSo you're a big fan of biology and biological computation.\\nWhat impressive thing is biology doing to you that computers are not yet?\\nThat gap?\\nI would say I'm definitely on, I'm much more hesitant with the analogies to the brain than\\nI think you would see potentially in the field.\\nAnd I kind of feel like certainly the way neural networks started is everything stemmed\\nfrom inspiration by the brain.\\nBut at the end of the day, the artifacts that you get after training, they are arrived\\nat by a very different optimization process than the optimization process that gave rise\\nto the brain.\\nAnd so I think, I kind of think of it as a very complicated alien artifact.\\nIt's something different.\\nThe brain?\\nI'm sorry, the neural nets that we're training.\\nThey are complicated alien artifact.\\nI do not make analogies to the brain because I think the optimization process that gave\\nrise to it is very different from the brain.\\nThere was no multi-agent self-play kind of setup in evolution.\\nIt was an optimization that is basically what amounts to a compression objective on a massive\\namount of data.\\nOkay.\\nSo artificial neural networks are doing compression and biological neural networks are not really\\ndoing anything.\\nThey're an agent in a multi-agent self-play system that's been running for a very, very\\nlong time.\\nThat said, evolution has found that it is very useful to predict and have a predictive\\nmodel in the brain.\\nAnd so I think our brain utilizes something that looks like that as a part of it, but\\nit has a lot more gadgets and gizmos and value functions and ancient nuclei that are all\\ntrying to make you survive and reproduce and everything else.\\nAnd the whole thing through embryogenesis is built from a single cell.\\nIt's just the code is inside the DNA and it just builds it up like the entire organism\\nwith arms and the head and legs.\\nAnd it does it pretty well.\\nIt should not be possible.\\nSo there's some learning going on.\\nThere's some kind of computation going through that building process.\\nI don't know where, if you were just to look at the entirety of history of life on earth,\\nwhat do you think is the most interesting invention?\\nIs it the origin of life itself?\\nIs it just jumping to eukaryotes?\\nIs it mammals?\\nIs it humans themselves, almost sapiens?\\nThe origin of intelligence or highly complex intelligence?\\nOr is it all just a continuation of the same kind of process?\\nCertainly I would say it's an extremely remarkable story that I'm only briefly learning about\\nrecently.\\nIt's a way from actually like you almost have to start at the formation of earth and all\\nof its conditions and the entire solar system and how everything is arranged with Jupiter\\nand moon and the habitable zone and everything.\\nAnd then you have an active earth that's turning over material.\\nAnd then you start with a bio genesis and everything.\\nSo it's all like a pretty remarkable story.\\nI'm not sure that I can pick like a single unique piece of it that I find most interesting.\\nI guess for me as an artificial intelligence researcher, it's probably the last piece.\\nWe have lots of animals that are not building technological society, but we do.\\nAnd it seems to have happened very quickly.\\nIt seems to have happened very recently.\\nAnd something very interesting happened there that I don't fully understand.\\nI almost understand everything else, I think intuitively, but I don't understand exactly\\nthat part and how quick it was.\\nBoth explanations will be interesting.\\nOne is that this is just a continuation of the same kind of process.\\nThere's nothing special about humans.\\nThat would be deeply understanding.\\nThat would be very interesting that we think of ourselves as special, but it was obvious.\\nIt was already written in the code that you would have greater and greater intelligence\\nemerging.\\nAnd then the other explanation, which is something truly special happened, something like a rare\\nevent, whether it's like crazy rare event like Space Odyssey.\\nWhat would it be?\\nSee, if you say like the invention of fire or the, as Richard Wrangham says, the beta\\nmales deciding a clever way to kill the alpha males by collaborating.\\nSo just optimizing the collaboration, the multi-agent aspect of the multi-agent and\\nthat really being constrained on resources and trying to survive the collaboration aspect\\nis what created the complex intelligence.\\nBut it seems like it's a natural algorithm, the evolutionary process.\\nWhat could possibly be a magical thing that happened, like a rare thing that would say\\nthat humans are actually human level intelligence, actually a really rare thing in the universe?\\nYeah, I'm hesitant to say that it is rare by the way, but it definitely seems like it's\\nkind of like a punctuated equilibrium where you have lots of exploration and then you\\nhave certain leaps, sparse leaps in between.\\nSo of course, like origin of life would be one, DNA, sex, eukaryotic life, the endosymbiosis\\nevent where the archaeon ate all bacteria, just the whole thing.\\nAnd then of course, emergence of consciousness and so on.\\nSo it seems like definitely there are sparse events where a massive amount of progress\\nwas made, but yeah, it's kind of hard to pick one.\\nSo you don't think humans are unique?\\nI've got to ask you, how many intelligent alien civilizations do you think are out there?\\nAnd is their intelligence different or similar to ours?\\nYeah, I've been preoccupied with this question quite a bit recently, basically the Fermi\\nparadox and just thinking through.\\nAnd the reason actually that I am very interested in the origin of life is fundamentally trying\\nto understand how common it is that there are technological societies out there in space.\\nAnd the more I study it, the more I think that there should be quite a lot.\\nWhy haven't we heard from them?\\nBecause I agree with you.\\nIt feels like I just don't see why what we did here on Earth is so difficult to do.\\nYeah, and especially when you get into the details of it, I used to think origin of life\\nwas very, it was this magical rare event, but then you read books like, for example,\\nNic Lane, The Vital Question, Life Ascending, etc.\\nAnd he really gets in and he really makes you believe that this is not that rare.\\nBasic chemistry.\\nYou have an active Earth and you have your alkaline vents and you have lots of alkaline\\nwaters mixing with the ocean and you have your proton gradients and you have the little\\nporous pockets of these alkaline vents that concentrate chemistry.\\nAnd basically as he steps through all of these little pieces, you start to understand that\\nactually this is not that crazy.\\nYou could see this happen on other systems.\\nAnd he really takes you from just a geology to primitive life and he makes it feel like\\nit's actually pretty plausible.\\nAnd also like the origin of life was actually fairly fast after formation of Earth.\\nIf I remember correctly, just a few hundred million years or something like that after\\nbasically when it was possible, life actually arose.\\nSo that makes me feel like that is not the constraint, that is not the limiting variable\\nand that life should actually be fairly common.\\nAnd then where the drop-offs are is very interesting to think about.\\nI currently think that there's no major drop-offs basically, and so there should be quite a\\nlot of life.\\nAnd basically where that brings me to then is the only way to reconcile the fact that\\nwe haven't found anyone and so on is that we just can't, we can't see them.\\nWe can't observe them.\\nJust a quick brief comment.\\nNick Lane and a lot of biologists I talked to, they really seem to think that the jump\\nfrom bacteria to more complex organisms is the hardest jump.\\nThe eukaryotic life basically.\\nYeah, which I don't, I get it.\\nThey're much more knowledgeable than me about like the intricacies of biology, but that\\nseems like crazy.\\nHow many single cell organisms are there?\\nAnd how much time you have?\\nSurely, it's not that difficult.\\nAnd a billion years is not even that long of a time really.\\nJust all these bacteria under constrained resources battling it out.\\nI'm sure they can invent more complex.\\nI don't understand, it's like how to move from a hello world program to like invent a\\nfunction or something like that.\\nI don't.\\nYeah.\\nSo I don't, yeah, so I'm with you.\\nI just feel like I don't see any, if the origin of life, that would be my intuition, that's\\nthe hardest thing.\\nBut if that's not the hardest thing, because it happens so quickly, then it's got to be\\neverywhere.\\nAnd yeah, maybe we're just too dumb to see it.\\nWell, it's just, we don't have really good mechanisms for seeing this life.\\nI mean, by what, how, so I'm not an expert just to preface this, but just from what I\\nthink about it.\\nI want to meet an expert on alien intelligence and how to communicate.\\nI'm very suspicious of our ability to find these intelligences out there and to find\\nthese earth, like radio waves, for example, are terrible.\\nTheir power drops off as basically one over R square.\\nSo I remember reading that our current radio waves would not be, the ones that we are broadcasting\\nwould not be measurable by our devices today.\\nOnly like, was it like one tenth of a light year away?\\nLike not even, basically tiny distance, because you really need like a targeted transmission\\nof massive power directed somewhere for this to be picked up on long distances.\\nAnd so I just think that our ability to measure is not amazing.\\nI think there's probably other civilizations out there.\\nAnd then the big question is why don't they build binomial probes and why don't they interstellar\\ntravel across the entire galaxy?\\nAnd my current answer is it's probably interstellar travel is like really hard.\\nYou have the interstellar medium.\\nIf you want to move at close to speed of light, you're going to be encountering bullets along\\nbecause even like tiny hydrogen atoms and little particles of dust are basically have\\nlike massive kinetic energy at those speeds.\\nAnd so basically you need some kind of shielding.\\nYou need, you have all the cosmic radiation.\\nIt's just like brutal out there.\\nIt's really hard.\\nAnd so my thinking is maybe interstellar travel is just extremely hard.\\nAnd you have to go very slow.\\nLike billions of years to build hard?\\nIt feels like, it feels like we're not a billion years away from doing that.\\nIt just might be that it's very, you have to go very slowly potentially as an example\\nthrough space.\\nRight.\\nAs opposed to close to the speed of light.\\nSo I'm suspicious basically of our ability to measure life and I'm suspicious of the\\nability to just permeate all of space in the galaxy or across galaxies.\\nAnd that's the only way that I can currently see around it.\\nIt's kind of mind blowing to think that there's trillions of intelligent alien civilizations\\nout there kind of slowly traveling through space to meet each other.\\nAnd some of them meet, some of them go to war, some of them collaborate.\\nOr they're all just independent.\\nThey're all just like little pockets.\\nWell statistically, if there's like, if it's this trillions of them, surely some of them,\\nsome of the pockets are close enough to get some of them happen to be close enough to\\nsee each other.\\nAnd once you see, once you see something that is definitely complex life, like if we see\\nsomething, we're probably going to be severe, like intensely aggressively motivated to figure\\nout what the hell that is and try to meet them.\\nBut what would be your first instinct to try to like at a generational level, meet them\\nor defend against them?\\nOr what would be your instinct as a president of the United States and a scientist?\\nI don't know which hat you prefer in this question.\\nYeah, I think the question, it's really hard.\\nI will say like, for example, for us, we have lots of primitive life forms on earth next\\nto us.\\nWe have all kinds of ants and everything else and we share space with them.\\nAnd we are hesitant to impact on them and to, we are, we're trying to protect them by\\ndefault because they are amazing, interesting, dynamical systems that took a long time to\\nevolve and they are interesting and special.\\nAnd I don't know that you want to destroy that by default.\\nAnd so I like complex dynamical systems that took a lot of time to evolve.\\nI think I'd like to, I like to preserve it if I can afford to.\\nAnd I'd like to think that the same would be true about the galactic resources and that\\nthey would think that we're kind of incredible, interesting story that took time.\\nIt took a few billion years to unravel and you don't want to just destroy it.\\nI could see two aliens talking about earth right now and saying, I'm a big fan of complex\\ndynamical systems.\\nSo I think it was a value to preserve these and who basically are a video game they watch\\nor show a TV show that they watch.\\nYeah, I think you would need like a very good reason, I think, to destroy it.\\nLike why don't we destroy these ant farms and so on?\\nBecause we're not actually like really in direct competition with them right now.\\nWe do it accidentally and so on, but there's plenty of resources.\\nAnd so why would you destroy something that is so interesting and precious?\\nWell from a scientific perspective, you might probe it.\\nYou might interact with it lightly.\\nYou might want to learn something from it, right?\\nSo I wonder there could be certain physical phenomena that we think is a physical phenomena,\\nbut it's actually interacting with us to like poke the finger and see what happens.\\nI think it should be very interesting to scientists, other alien scientists, what happened here.\\nAnd you know, it's a, what we're seeing today is a snapshot.\\nBasically it's a result of a huge amount of computation over like billion years or something\\nlike that.\\nSo it could have been initiated by aliens.\\nThis could be a computer running a program.\\nLike when, okay, if you had the power to do this, when you, okay, for sure, at least I\\nwould, I would pick an earth like planet that has the conditions based on my understanding\\nof the chemistry prerequisites for life and I would see it with life and run it.\\nRight?\\nLike, wouldn't you 100% do that and observe it and then protect?\\nI mean that that's not just a hell of a good TV show.\\nIt's a good scientific experiment.\\nAnd that it is it's physical simulation, right?\\nEvolution is the most like actually running it, uh, is the most efficient way to, uh,\\nunderstand computation or to compute stuff or to understand life or, you know, what life\\nlooks like and what branches it can take.\\nIt doesn't make me kind of feel weird that we're part of a science experiment, but maybe\\nit's everything's a science experiment.\\nSo does that change anything for us for a science experiment?\\nUm, I don't know.\\nTwo descendants of apes talking about being inside of a science experiment.\\nI'm suspicious of this idea of like a deliberate panspermia as you described it, sir.\\nI don't see a divine intervention in some way in the, in the historical record right\\nnow.\\nI do feel like, um, the story in these, in these books, like Nick Lane's books and so\\non sort of makes sense.\\nUh, and it makes sense how life arose on earth uniquely.\\nAnd uh, yeah, I don't need a, I mean, I don't need to reach for more exotic explanations\\nright now.\\nSure.\\nBut I think that inside of video game, don't, don't, don't observe any divine intervention\\neither.\\nAnd we might just be all NPCs running a kind of code.\\nMaybe eventually they will.\\nCurrently NPCs are really dumb, but once they're running GPTs, um, maybe they will be like,\\nHey, this is really suspicious.\\nWhat the hell?\\nSo you are famously tweeted.\\nIt looks like if you bombard earth with photons for a while, you can emit a roadster.\\nSo if like in hitchhiker's guide to the galaxy, we would summarize the story of earth.\\nSo in that book, it's mostly harmless.\\nUh, what do you think is all the possible stories, like a paragraph long or sentence\\nlong that earth could be summarized as once it's done, it's computation.\\nSo like all the possible full, if earth is a book, right?\\nUh, probably there has to be an ending.\\nI mean, there's going to be an end to earth and it could end in all kinds of ways.\\nIt can end soon.\\nIt can end later.\\nWhat do you think are the possible stories?\\nWell, definitely there seems to be, yeah, you're sort of, it's pretty incredible that\\nthese self replicating systems will basically arise from the dynamics and then they perpetuate\\nthemselves and become more complex and eventually become conscious and build a society.\\nAnd I kind of feel like in some sense, it's kind of like a deterministic wave, uh, that,\\nyou know, that kind of just like happens on any, you know, any sufficiently well-arranged\\nsystem like earth.\\nAnd so I kind of feel like there's a certain sense of inevitability in it.\\nUm, and it's really beautiful.\\nAnd it ends somehow, right?\\nSo it's a, it's a chemically a diverse environment where complex dynamical systems can evolve\\nand become more, more further and further complex.\\nBut then there's a certain, um, what is it?\\nThere's certain terminating conditions.\\nYeah, I don't know what the terminating conditions are, but definitely there's a trend line of\\nsomething and we're part of that story.\\nAnd like, where does that, where does it go?\\nSo you know, we're famously described often as a biological bootloader for AIs and that's\\nbecause humans, I mean, you know, we're an incredible, uh, biological system and we're\\nand, uh, you know, and love and so on.\\nUm, but we're extremely inefficient as well.\\nLike we're talking to each other through audio.\\nIt's just kind of embarrassing, honestly, that we're manipulating like seven symbols,\\nuh, serially, we're using vocal cords.\\nIt's all happening over like multiple seconds.\\nIt's just like kind of embarrassing when you step down to the frequencies at which computers\\noperate or are able to cooperate on.\\nSo basically it does seem like, um, synthetic intelligences are kind of like the next stage\\nof development.\\nAnd um, I don't know where it leads to.\\nLike at some point I suspect, uh, the universe is some kind of a puzzle and these, uh, synthetic\\nAIs will uncover that puzzle and, um, solve it.\\nAnd then what happens after, right?\\nLike what, cause if you just like fast forward earth, many billions of years, it's like,\\nit's quiet and then it's like to turmoil.\\nYou see like city lights and stuff like that.\\nAnd then what happens at like, at the end, like, is it like a poof?\\nIt's it, or is it like a calming, is it explosion?\\nIs it like earth like open, like a giant, cause you said, um, it roasters like, well,\\nlet's start emitting like, like a giant number of like satellites.\\nYes.\\nIt's some kind of a crazy explosion and we're living, we're like, we're stepping\\nthrough a explosion and we're like living day to day and it doesn't look like it, but\\nit's actually, if you, I saw a very cool animation of earth, uh, and life on earth and basically\\nnothing happens for a long time.\\nAnd then the last like two seconds, like basically cities and everything and just in the lower\\nearth orbit just gets cluttered and just the whole thing happens in the last two seconds.\\nAnd you're like, this is exploding.\\nThis is a state explosion.\\nSo if you play, yeah, yeah.\\nIf you play it at normal speed, it'll just look like an explosion.\\nIt's a firecracker.\\nWe're living in a firecracker.\\nWhere it's going to start emitting all kinds of interesting things.\\nYeah.\\nAnd then the, so explosion doesn't, it might actually look like a little explosion with,\\nwith lights and fire and energy emitted, all that kind of stuff.\\nBut when you look inside the details of the explosion, there's actual complexity\\nhappening where there's like, uh, yeah, human life or some kind of life.\\nWe hope it's not a destructive firecracker.\\nIt's kind of like a constructive firecracker.\\nAll right.\\nSo given that, I think, uh, hilarious discussion.\\nIt is really interesting to think about like what the puzzle of the universe is.\\nDid the creator of the universe, uh, give us a message?\\nLike for example, in the book, contact, um, Carl Sagan, uh, there's a message for\\nhumanity, for any civilization in, uh, digits in the expansion of PI in base 11,\\neventually, which is kind of interesting thought, uh, maybe, maybe we're supposed\\nto be giving a message to our creator.\\nMaybe we're supposed to somehow create some kind of a quantum mechanical system\\nthat alerts them to our intelligent presence here.\\nCause if you think about it from their perspective, it's just say like quantum\\nfield theory, massive, like cellular, ton of a ton like thing.\\nAnd like, how do you even notice that we exist?\\nYou might not even be able to pick us up in that simulation.\\nAnd so how do you, uh, how do you prove that you exist, uh, that you're\\nintelligent and that you're part of the universe?\\nSo this is like a touring test for intelligence from earth.\\nYeah.\\nI got the creator's, uh, I mean, maybe this is like trying to complete\\nthe next word in a sentence.\\nThis is a complicated way of that.\\nLike earth is just, is basically sending a message back.\\nYeah.\\nThe puzzle is basically like alerting the creator that we exist.\\nUh, or maybe the puzzle is just to just break out of the system and just, uh,\\nyou know, uh, stick it to the creator in some way.\\nUh, basically, like if you're playing a video game, you can, um, you can somehow\\nfind an exploit and find a way to execute on the host machine, uh, in the arbitrary\\ncode, uh, there's some, uh, for example, I believe someone got a Mario, a game of\\nMario to play pong just by, um, exploiting it and then, um, creating, uh,\\nbasically writing, writing code and being able to execute arbitrary code in the\\ngame.\\nAnd so maybe we should be, maybe that's the puzzle is that we should be, um, uh,\\nfind a way to exploit it.\\nSo, so I think like some of these synthetic guys will eventually find the\\nuniverse to be some kind of a puzzle and then solve it in some way.\\nAnd that's kind of like the end game somehow.\\nDo you often think about it as a, as a simulation?\\nSo, uh, as, or the universe being a kind of computation that has, might have bugs\\nand exploits.\\nYes.\\nYeah, I think so.\\nI said, well, physics is essentially, I think it's possible that physics has\\nexploits and we should be trying to find them, uh, arranging some kind of a crazy\\nquantum mechanical system that somehow gives you buffer overflow, uh, somehow\\ngives you a rounding error in the floating point.\\nUh, uh, yeah, that's right.\\nAnd we're like more and more sophisticated exploits.\\nThose are jokes, but that could be actually very close.\\nYeah.\\nWe'll find some way to extract infinite energy.\\nUh, for example, when you train a reinforcement learning agents, um, in\\nphysical simulations and you ask them to say, run quickly on the flat ground,\\nthey'll end up doing all kinds of like weird things, um, in part of that\\noptimization, right?\\nThey'll get on their back leg and they'll slide across the floor.\\nAnd it's because the optimization, um, the enforcement learning optimization on\\nthat agent has figured out a way to extract infinite energy from the friction\\nforces and, um, basically their poor implementation.\\nAnd, uh, they found a way to generate infinite energy and just slide across the\\nsurface and it's not what you expected.\\nIt's just, uh, it's sort of like a perverse solution.\\nAnd so maybe we can find something like that.\\nMaybe we can be that little dog in this physical simulation.\\nThe cracks or escapes the intended consequences of the physics that the\\nuniverse came up with will figure out some kind of shortcut to some weirdness.\\nYeah.\\nAnd then, man, but see the problem with that weirdness is the first person to\\ndiscover the weirdness, like sliding in the back legs.\\nThat's all we're going to do.\\nYeah.\\nIt's very quickly become everybody does that thing.\\nSo like the paperclip maximizer is a ridiculous idea, but that very well could\\nbe what then we'll just, uh, we'll just all switched that cause it's so fun.\\nWell, no person will discover it.\\nI think, by the way, I think it's going to have to be, uh, some kind of a super\\nintelligent AGI of a third generation.\\nLike we're building the first generation AGI.\\nAnd then, you know, third generation.\\nYeah.\\nSo the, the bootloader for an AI, the, that AI will be a\\nbootloader for another AI.\\nYeah.\\nAnd then there's no way for us to introspect like what that might even, uh,\\nI think it's very likely that these things, for example, like, say you have\\nthese AGI's it's very likely that, for example, they will be completely inert.\\nI like these kinds of sci-fi books sometimes where these things are just\\ncompletely inert, they don't interact with anything.\\nAnd I find that kind of beautiful because, uh, they probably, uh, they've\\nprobably figured out the meta meta game of the universe in some way, potentially\\nthere, they're doing something completely beyond our imagination.\\nUm, and, uh, they don't interact with simple chemical life forms.\\nLike, why would you do that?\\nSo I find those kinds of ideas compelling.\\nWhat's their source of fun?\\nWhat are they, what are they doing?\\nWhat's the source of pleasure solving in the universe, but in there.\\nSo can you define what it means inert?\\nSo they escape the interaction.\\nAs in, um, uh, they will behave in some very strange way to us, uh, because\\nthey're, uh, they're beyond, they're playing the meta game, uh, and the meta\\ngame is probably say like arranging quantum mechanical systems and some very\\nweird ways to extract infinite energy, uh, solve the digital expansion of\\npie to whatever amount, uh, they will build their own like little fusion\\nreactors or something crazy, like they're doing something beyond comprehension\\nand not understandable to us and actually brilliant under the hood.\\nWhat if quantum mechanics itself is the system and we're just thinking it's\\nphysics, but we're really parasites on, on, not parasite, we're not really\\nhurting physics, we're just living on this organisms, this organism, and\\nwe're like trying to understand it, but really it is an organism and with\\na deep, deep intelligence, maybe physics itself is, uh, the, the, the organism\\nthat's doing the super interesting thing.\\nAnd we're just like one little thing, yeah.\\nAnd sitting on top of it, trying to get energy from it.\\nWe're just kind of like these particles in the wave that I feel like is mostly\\ndeterministic and takes a universe from some kind of a big bang to some kind\\nof a super intelligent replicator, some kind of a stable point in the universe.\\nGiven these laws of physics, you don't think, uh, as Einstein said, God\\ndoesn't play dice, so you think it's mostly deterministic.\\nThere's no randomness in the thing.\\nI think it's deterministic.\\nOh, there's tons of, uh, well, I'm, I'm, I want to be careful with randomness.\\nPseudo random.\\nYeah.\\nI don't like random.\\nUh, I think maybe the laws of physics are deterministic.\\nUm, yeah, I think they're deterministic.\\nYou just got really uncomfortable with this question.\\nI just, do you have anxiety about whether the universe is random or not?\\nIs this a, what's, there's no randomness.\\nIt's, uh, you said you like goodwill hunting.\\nIt's not your fault, Andre.\\nIt's not your fault, man.\\nUm, so you don't like randomness.\\nUh, yeah, I think it's, uh, unsettling.\\nI think it's a deterministic system.\\nI think that things that look random, like say the, uh, collapse of the wave\\nfunction, et cetera, I think they're actually deterministic, just entanglement,\\nuh, and so on and, uh, some kind of a multiverse theory, something, something.\\nOkay.\\nSo why does it feel like we have a free will?\\nLike if I, if I raised his hand, I chose to do this now.\\nUm, what that doesn't feel like a deterministic thing.\\nIt feels like I'm making a choice.\\nIt feels like it.\\nOkay.\\nSo it's all feelings.\\nIt's just feelings.\\nYeah.\\nSo when RL agent is making a choice, is that, um, it's not really\\nmaking a choice.\\nThe choice was all already there.\\nYeah.\\nYou're interpreting the choice and you're creating a narrative for, for having made it.\\nYeah.\\nAnd now we're talking about the narrative.\\nIt's very meta looking back.\\nWhat is the most beautiful or surprising idea in deep learning or AI in general\\nthat you've come across?\\nYou've seen this field explode, uh, and grow in interesting ways.\\nJust what, what cool ideas like, like we made you sit back and go,\\nsmall, big or small.\\nWell, the one that I've been thinking about recently, the most probably is the,\\nthe transformer architecture.\\nUm, so basically, uh, neural networks have, uh, a lot of architectures that were\\ntrendy have come and gone for different sensory modalities, like for vision,\\naudio, text, you would process them with different looking neural nets.\\nAnd recently we've seen these, this convergence towards one architecture,\\nthe transformer, and, uh, you can feed it video or you can feed it, you know,\\nimages or speech or text, and it just gobbles it up and it's kind of like\\na bit of a general purpose, uh, computer.\\nThere's also trainable and very efficient to run on our hardware.\\nAnd so, uh, this paper came out in 2016.\\nI want to say, um, attention is all you need.\\nAttention is all you need.\\nYou criticize the paper title in retrospect that it wasn't, um, it didn't\\nforesee the bigness of the impact that it was going to have.\\nYeah.\\nI'm not sure if the authors were aware of the impact that that paper would go\\non to have, probably they weren't, but I think they were aware of some of the\\nmotivations and design decisions behind the transformer and they chose not to,\\nI think, uh, expand on it in that way in the paper.\\nAnd so I think they had an idea that there was more, um, than just the\\nsurface of just like, Oh, we're just doing translation and here's a better\\narchitecture.\\nYou're not just doing translation.\\nThis is like a really cool, differentiable, optimizable, efficient\\ncomputer that you've proposed.\\nAnd maybe they didn't have all of that foresight, but I think it's really\\ninteresting.\\nIsn't it funny, sorry to interrupt that that title is memeable that they went\\nfor such a profound idea.\\nThey went with a, I don't think anyone used that kind of title before, right?\\nAttention is all you need.\\nYeah.\\nIt's like a meme or something.\\nYeah.\\nIt's not funny that one, like, uh, maybe if it was a more serious title, it\\nwouldn't have the impact.\\nHonestly, I, yeah, there is an element of me that honestly agrees with you and\\nprefers it this way.\\nYes.\\nUh, if it was too grand, it would over promise and then under deliver\\npotentially.\\nSo you want to just, uh, meme your way to greatness.\\nThat should be a t-shirt.\\nSo you, you tweeted the transformer is a magnificent neural network architecture\\nbecause it is a general purpose, differentiable computer.\\nIt is simultaneously expressive in the forward pass, optimizable via back\\npropagation, gradient descent, and efficient high parallelism compute graph.\\nCan you discuss some of those details, expressive, optimizable, efficient\\nfor memory or, or in general, whatever comes to your heart?\\nYou want to have a general purpose computer that you can train on arbitrary\\nproblems, uh, like say the task of next work prediction or detecting if there's\\na cat in a image or something like that.\\nAnd you want to train this computer.\\nSo you want to set its, its weights.\\nAnd I think there's a number of design criteria that sort of overlap in the\\ntransformer simultaneously that made it very successful.\\nAnd I think the authors were kind of, uh, deliberately trying to, uh, make\\nthis really, uh, powerful architecture.\\nAnd, um, so basically it's very powerful in the forward pass because it's able\\nto express, um, very general computation as sort of something that looks like\\nmessage passing, uh, you have nodes and they all store vectors and, uh, these\\nnodes get to basically look at each other and it's, uh, each other's vectors\\nand they get to communicate and basically nodes get to broadcast, Hey,\\nI'm looking for certain things.\\nAnd then other nodes get to broadcast.\\nHey, these are the things I have.\\nThose are the keys and the values.\\nSo it's not just the tension.\\nYeah, exactly.\\nTransformers much more than just the attention component.\\nIt's got many pieces architectural that went into it.\\nThe residual connection of the weights arranged, there's a multi-layer perceptron\\nand they're the weights stacked and so on.\\nUm, but basically there's a message passing scheme where nodes get to look at\\neach other, decide what's interesting and then update each other.\\nAnd, uh, so I think the, um, when you get to the details of it, I think\\nit's a very expressive function.\\nUh, so it can express lots of different types of algorithms and forward pass.\\nNot only that, but the way it's designed with the residual connections,\\nlayer normalizations, the soft max attention and everything.\\nIt's also optimizable.\\nThis is a really big deal because there's lots of computers that are\\npowerful that you can't optimize.\\nUm, or they're not easy to optimize using the techniques that we have,\\nwhich is backpropagation and gradient and sent.\\nThese are first order methods, very simple optimizers really.\\nAnd so, um, you also need it to be optimizable.\\nUm, and then lastly, you want it to run efficiently in our hardware.\\nOur hardware is a massive throughput machine, like GPUs.\\nUh, they prefer lots of parallelism.\\nSo you don't want to do lots of sequential operations.\\nSo you want to do a lot of operations serially and the transformer is designed\\nwith that in mind as well.\\nAnd so it's designed for our hardware and it's designed to both be very\\nexpressive in a forward pass, but also very optimizable in the backward pass.\\nAnd you said that, uh, the residual connections support a kind of ability\\nto learn short algorithms fast and first, and then gradually extend them,\\nuh, longer during training.\\nWhat's, what's the idea of learning short algorithms?\\nRight.\\nThink of it as a, so basically a transformer is a, uh, series of, uh,\\nblocks, right?\\nAnd these blocks have attention and a little multilayer perceptual.\\nAnd so you, you go off into a block and you come back to this residual pathway.\\nAnd then you go off and you come back and then you have a number\\nof layers arranged sequentially.\\nAnd so the way to look at it, I think is, uh, because of the residual\\npathway in the backward pass, the gradients, uh, sort of flow along it uninterrupted\\nbecause addition, uh, distributes the gradient equally to all of its branches.\\nSo the gradient from the supervision at the top, uh, just floats\\ndirectly to the first layer.\\nAnd the, all the residual connections are arranged so that in the beginning\\nat during initialization, they contribute nothing to the residual pathway.\\nUm, so what it kind of looks like is imagine the transformer is kind of\\nlike a, uh, Python, uh, function, like a death.\\nAnd, um, you get to do various kinds of like lines of code.\\nUh, say you have a hundred layers, deep, uh, transformer, typically\\nthey would be much shorter, say 20.\\nSo if 20 lines of code, then you can do something in them.\\nAnd so think of during the optimization, basically what it looks like is first\\nyou optimize the first line of code and then the second line of code can kick\\nin and the third line of code can kick in.\\nAnd I kind of feel like because of the residual pathway and the dynamics of\\nthe optimization, uh, you can sort of learn a very short algorithm that\\ngets the approximate answer, but then the other layers can sort of kick in and\\nstart to create a contribution.\\nAnd at the end of it, you're, you're optimizing over an algorithm\\nthat is a 20 lines of code.\\nExcept these lines of code are very complex because it's an\\nentire block of a transformer.\\nYou can do a lot in there.\\nWell, it's really interesting is that this transformer architecture\\nactually has been a remarkably resilient.\\nBasically the transformer that came out in 2016 is the transformer\\nyou would use today, except you reshuffle some of the layer norms.\\nUh, the layer normalizations have been reshuffled to a pre-norm, um, formulation.\\nAnd so it's been remarkably stable, but there's a lot of bells and whistles\\nthat people have attached on it and try to, uh, improve it.\\nI do think that basically it's a, it's a big step in simultaneously optimizing\\nfor lots of properties of a desirable neural network architecture.\\nAnd I think people have been trying to change it, but it's proven\\nremarkably resilient.\\nUm, but I do think that there should be even better architectures potentially.\\nBut it's, uh, you're, you admire the resilience here.\\nYeah.\\nThere's something profound about this architecture that, that least\\nresilient, so maybe we can, everything can be turned into a, uh, into a problem\\nthat transformers can solve.\\nCurrently definitely looks like the transformer is taking over AI and you\\ncan feed basically arbitrary problems into it.\\nAnd it's a general, the French double computer and it's extremely powerful.\\nAnd, uh, at this conversions in AI has been, uh, really interesting\\nto watch, uh, for me personally.\\nWhat else do you think could be discovered here about transformers?\\nLike what's surprising thing or, or is it a stable, um, I want a stable place.\\nIs there something interesting we might discover about transformers?\\nLike aha moments maybe has to do with memory.\\nUm, maybe knowledge representation, that kind of stuff.\\nDefinitely does that guys today is just pushing like basically right now, the\\nside guys is do not touch the transformer, touch everything else.\\nYes.\\nSo people are scaling up the data sets, making them much, much bigger.\\nThey're working on the evaluation, making the evaluation much, much bigger.\\nAnd, uh, um, they're basically keeping the architecture unchanged.\\nAnd that's how we've, um, that's the last five years of progress in AI kind of.\\nWhat do you think about one flavor of it, which is language models?\\nHave you been surprised?\\nUh, has your sort of imagination been captivated by you mentioned\\nGPT and all the bigger and bigger and bigger language models.\\nAnd, uh, what are the limits of those models do you think?\\nSo just for the task of natural language.\\nBasically the way GPT is trained, right.\\nIs you just download a massive amount of text data from the internet and that you\\ntry to predict the next word in a sequence, roughly speaking, you're\\npredicting little work chunks, but, uh, roughly speaking, that's it.\\nUm, and what's been really interesting to watch is, uh, basically it's a language\\nmodel, language models have actually existed for a very long time.\\nUm, there's papers on language modeling from 2003, even earlier.\\nCan you explain that case?\\nWhat a language model is?\\nUh, yeah.\\nSo language model just, uh, basically the rough idea is, um, just predicting\\nthe next word in a sequence, roughly speaking.\\nUh, so there's a paper from, for example, Ben Geo, uh, and the team from 2003,\\nwhere for the first time they were using a neural network to take, say like three\\nor five words and predict the, um, next word, and they're doing this on much\\nsmaller datasets and the neural net is not a transformer, it's a multi-layer\\nperceptron, but it's the first time that a neural network has been applied in\\nthat setting, but even before neural networks, there were, um, language models,\\nexcept they were using, um, Ngram models.\\nSo Ngram models are just, uh, count based models.\\nSo, um, if you try to, if you start to take two words and predict the third\\none, you just count up how many times you've seen any, uh, two word combinations\\nand what came next and what you predict as coming next is just what you've seen\\nthe most of in the training set.\\nAnd so, uh, language modeling has been around for a long time.\\nNeural networks have done language modeling for a long time.\\nSo really what's new or interesting or exciting is just realizing that when you\\nscale it up, uh, with a powerful enough neural net, a transformer, you have all\\nthese emergent properties where, uh, basically what happens is if you have a\\nlarge enough dataset of text, you are in the task of predicting the next word.\\nYou are multitasking a huge amount of different kinds of problems.\\nYou are multitasking, understanding of, you know, chemistry, physics, human\\nnature, lots of things are sort of clustered in that objective.\\nIt's a very simple objective, but actually you have to understand\\na lot about the world to make that prediction.\\nYou just said the U word understanding, uh, are you in terms of chemistry and\\nphysics and so on, what do you feel like it's doing?\\nIs it searching for the right context?\\nUh, in, in like, what is it, what is the actual process happening here?\\nYeah.\\nSo basically it gets a thousand words and it's trying to predict the thousand and\\nfirst, and, uh, in order to do that very, very well over the entire dataset\\navailable on the internet, you actually have to basically kind of understand\\nthe context of, of what's going on in there.\\nYeah.\\nUm, and, uh, it's a sufficiently hard problem that you, uh, if you have a\\npowerful enough computer, like a transformer, you end up with a interesting\\nsolutions and, uh, you can ask it to do all kinds of things and, um, it, it\\nshows a lot of, uh, emergent properties, like in context learning.\\nThat was the big deal with GPT and the original paper when they published it\\nis that you can just sort of, uh, prompt it in various ways and ask it to do\\nvarious things and it will just kind of complete the sentence, but in the process\\nof just completing the sentence, it's actually solving all kinds of really,\\nuh, interesting problems that we care about.\\nDo you think it's doing something like understanding?\\nLike when we use the word understanding for us humans, I think it's doing some\\nunderstanding in its weights, it understands, I think a lot about the world\\nand it has to, in order to predict the next word in the sequence.\\nSo it's trained on the data from the internet.\\nUh, what do you think about this, this approach in terms of data sets\\nof using data from the internet?\\nDo you think the internet has enough structured data to teach\\nAI about human civilization?\\nYes.\\nSo I think the internet has a huge amount of data.\\nI'm not sure if it's a complete enough set.\\nI don't know that, uh, text is enough for having a sufficiently\\npowerful AGI as an outcome.\\nUm, of course there is audio and video and images and all that.\\nYeah.\\nKind of stuff.\\nYeah.\\nSo text by itself, I'm a little bit suspicious about.\\nThere's a ton of things we don't put in text in writing, uh, just\\nbecause they're obvious to us about how the world works and the physics of it.\\nAnd that things fall, we don't put that stuff in text because why would you,\\nwe share that understanding.\\nAnd so text is a communication medium between humans and it's not a, uh, all\\nencompassing medium of knowledge about the world, but as you pointed out,\\nwe do have video and we have images and we have audio.\\nAnd so I think that, uh, that definitely helps a lot, but we haven't\\ntrained models, uh, sufficiently, uh, across both across all of those modalities yet.\\nUh, so I think that's what a lot of people are interested in.\\nBut I wonder what that shared understanding of like what we might call common\\nsense has to be learned, inferred in order to complete the sentence correctly.\\nSo maybe the fact that it's implied on the internet, the model is going\\nto have to learn that not by reading about it, by inferring it in the representation.\\nSo like common sense, just like we, I don't think we learn common sense.\\nLike nobody says, tells us explicitly.\\nWe just figure it all out by interacting with the world.\\nAnd so here's a model of reading about the way people interact with the world.\\nIt might have to infer that.\\nI wonder, uh, you, you briefly worked on a project called the world of bits,\\ntraining and RRL system to take actions on the internet, um, versus just consuming\\nthe internet, like we talked about.\\nDo you think there's a future for that kind of system interacting with\\nthe internet to help the learning?\\nYes.\\nI think that's probably the, uh, the final frontier for a lot of these\\nmodels, uh, because, um, so as you mentioned, when I was at open AI, I was\\nworking on this project for a little bit.\\nAnd basically it was the idea of giving neural networks access to a keyboard\\nand a mouse and the idea possibly go wrong.\\nSo basically you, um, you perceive the input of the, uh, screen pixels.\\nAnd, uh, basically the state of the computer is sort of visualized, uh, for\\nhuman consumption in images of the web browser and stuff like that.\\nAnd then you give them your own or the ability to press keyboards and use the\\nmouse and we're trying to get it to, for example, complete bookings and, you\\nknow, interact with user interfaces.\\nAnd, um,\\nwhat'd you learn from that experience?\\nLike, what was some fun stuff?\\nThis is a super cool idea.\\nYeah.\\nI mean, it's like, uh, yeah, I mean, the, the step between observer to actor\\nis a super fascinating step.\\nYeah.\\nWell, it's the universal interface in the digital realm, I would say.\\nAnd, uh, there's a universal interface in like the physical realm, which in my\\nmind is a humanoid form factor kind of thing.\\nUh, we can later talk about optimists and so on, but I feel like there's a, uh,\\nthey're kind of like a similar philosophy in some way where the human, the world,\\nthe physical world is designed for the human form and the digital world is\\ndesigned for the human form of seeing the screen and using keyword, not\\nkeyboard and mouse.\\nAnd so it's the universal interface that can basically, uh, command the digital\\ninfrastructure we've built up for ourselves.\\nAnd so it feels like a very powerful interface to, to command and to build on\\ntop of, uh, now to your question as to like what I learned from that, it's\\ninteresting because the world of bits was basically too early, I think at\\nopen AI at the time, um, this is around 2015 or so, and the zeitgeist at that\\ntime was very different in AI from the zeitgeist today at the time, everyone\\nwas super excited about reinforcement learning from scratch.\\nUh, this is the time of the Atari paper, uh, where, uh, neural networks were\\nplaying Atari games, um, and beating humans in some cases, uh, AlphaGo and so on.\\nSo everyone's very excited about training neural networks from scratch\\nusing reinforcement learning, um, directly.\\nIt turns out that reinforcement learning is extremely inefficient way of training\\nneural networks because you're taking all these actions and all these\\nobservations and you get some sparse rewards once in a while.\\nSo you do all this stuff based on all these inputs and once in a while,\\nyou're like told you did a good thing, you did a bad thing.\\nAnd it's just an extremely hard problem.\\nYou can't learn from that.\\nUh, you can burn a forest and you can sort of brute force through it.\\nAnd we saw that I think with, uh, you know, with, uh, go and\\nDota and so on and does work.\\nUh, but it's extremely inefficient, uh, and, uh, not how you want to\\napproach problems, uh, practically speaking.\\nAnd so that's the approach that at the time we also took to world of bits.\\nUh, we would, uh, have an agent initialize randomly.\\nSo with keyboard mash and mouse mash and try to make a booking.\\nAnd it's just like revealed the insanity of that approach very quickly,\\nwhere you have to stumble by the correct booking in order to get a reward of\\nyou did it correctly and you're never going to stumble by it by chance at random.\\nSo even with a simple web interface, there's too many options.\\nThere's just too many options.\\nUh, and, uh, it's too sparse of a reward signal and you're\\nstarting from scratch at the time.\\nAnd so you don't know how to read.\\nYou don't understand pictures, images, buttons.\\nYou don't understand what it means to like make a booking, but now what's\\nhappened is, uh, it is time to revisit that and open AI is interested in this.\\nUh, companies like adept are interested in this and so on.\\nAnd, uh, the idea is coming back, uh, because the interface is very powerful,\\nbut now you're not training an agent from scratch.\\nYou are taking the GPT as an initialization.\\nSo GPT is pre-trained on all of.\\nText and it understands what's a booking.\\nIt understands what's a submit.\\nIt understands, um, quite a bit more.\\nAnd so it already has those representations.\\nThey are very powerful.\\nAnd that makes all the training significantly more efficient, um,\\nand makes the problem tractable.\\nShould the interaction be with like the way humans see it with the buttons and\\nthe language, or should be with the HTML, JavaScript and the CSS?\\nWhat's, what do you think is the better?\\nUh, so today all of this interaction is mostly on the level of HTML, CSS,\\nand so on that's done because of computational constraints.\\nUh, but I think ultimately, um, uh, everything is designed for human\\nvisual consumption and so at the end of the day, there's all the additional\\ninformation is in the layout of the webpage and what's next to you and\\nwhat's a red background and all this kind of stuff and what it looks like visually.\\nSo I think that's the final frontier as we are taking in a pixels and we're\\ngiving out keyboard mouse commands.\\nUh, but I think it's impractical still today.\\nDo you worry about bots on the internet?\\nGiven, given these ideas, given how exciting they are, do you worry about\\nbots on Twitter being not the stupid boss that we see now with the crypto\\nbots, but the bots that might be out there actually that we don't see that\\nthey're interacting in interesting ways.\\nSo this kind of system feels like it should be able to pass the, I'm not a\\nrobot click button, whatever.\\nUm, which does she understand how that test works?\\nI don't quite like, uh, there's, there's a, there's a checkbox or\\nwhatever that you click is presumably tracking like mouse movement and\\nthe timing and so on.\\nSo exactly this kind of system we're talking about should be able to pass that.\\nSo w yeah, what do you feel about, um, bots that are language models plus have\\nsome interact ability and are able to tweet and reply and so on, do you worry\\nabout that world?\\nUh, yeah, I think it's always been a bit of an arms race, uh, between sort\\nof the attack and the defense.\\nUh, so the attack will get stronger, but the defense will get stronger as well.\\nUh, our ability to detect that.\\nHow do you defend, how do you detect, how do you know that your Carpati\\naccount on Twitter is, is human?\\nHow would you approach that?\\nLike if people were claimed, you know, uh, how would you defend yourself in\\nthe court of law that I'm a human?\\nUm, this account is, yeah, at some point, I think, uh, it might be, I think\\nthe society, the society will evolve a little bit, like we might start signing\\ndigitally, signing, uh, some of our correspondence or, you know, things that\\nwe create, uh, right now it's not necessary, but maybe in the future it\\nmight be, I do think that we are going towards a world where we share, we\\nshare the digital space with, uh, AIs.\\nSynthetic beings.\\nYeah.\\nAnd, uh, they will get much better and they will share our digital realm and\\nthey'll eventually share our physical realm as well.\\nIt's much harder.\\nUh, but that's kind of like the world we're going towards and most of them\\nwill be benign and awful and some of them will be malicious and it's going to be\\nan arms race trying to detect them.\\nSo, I mean, the worst isn't the AIs.\\nThe worst is the AIs pretending to be human.\\nSo mine, I don't know if it's always malicious.\\nThere's obviously a lot of malicious applications, but it could also be, you\\nknow, if I was an AI, I would try very hard to pretend to be human because we're\\nin a human world.\\nI wouldn't get any respect as an AI.\\nI want to get some love and respect.\\nI don't think the problem is intractable.\\nPeople are, people are thinking about the proof of personhood and, uh, we\\nmight start digitally signing our stuff and we might all end up having like, uh,\\nyeah, basically some, some solution for proof of personhood.\\nIt doesn't seem to me intractable.\\nIt's just something that we haven't had to do until now, but I think once the\\nneed like really starts to emerge, which is soon, I think people will think\\nabout it much more.\\nSo, but that too will be a race because, um, obviously you can probably, uh,\\nspoof or fake the, the, the proof of, uh, personhood.\\nSo you have to try to figure out how to, I mean, it's weird that we have like\\nsocial security numbers and like passports and stuff.\\nIt seems like it's harder to fake stuff in the physical space.\\nIn the digital space, it just feels like it's going to be very tricky, very\\ntricky to out, um, cause it seems to be pretty low cost to fake stuff.\\nWhat are you going to put an AI in jail for like trying to use a fake, uh,\\nfake personhood proof?\\nYou can, I mean, okay, fine.\\nYou'll put a lot of AIs in jail, but there'll be more as arbitrary, like\\nexponentially more the cost of creating a bot is very low.\\nUnless there's some kind of way to track accurately, like you're not allowed to\\ncreate any program without showing, uh, tying yourself to that program.\\nLike you, any program that runs on the internet, you'll be able to, uh, trace\\nevery single human program and those involved with that program.\\nYeah, maybe you have to start declaring when, uh, you know, we have to start\\ndrawing those boundaries and keeping track of, okay, uh, what are digital\\nentities versus human entities and, uh, what is the ownership of human entities\\nand digital entities and, uh, something like that, um, I don't know, but I'm,\\nI think I'm optimistic that this is, uh, this is, uh, possible and it's some, in\\nsome sense, we're currently in like the worst time of it because, um, all these\\nbots suddenly have become very capable, uh, but we don't have the fences yet\\nbuilt up as a society and, but I think, uh, that doesn't seem to me intractable.\\nIt's just something that we have to deal with.\\nIt seems weird that the Twitter bot, like really crappy Twitter bots are so\\nnumerous, like is it, so I presume that the engineers at Twitter are very good.\\nSo it seems like what I would infer from that, uh, is it seems like a hard problem.\\nIt, they're probably catching, right.\\nIf I were to sort of steal man, the case, it's a hard problem and there's a\\nhuge cost to, uh, false positive to, to removing a post by somebody that's not a\\nbot that creates a very bad user experience.\\nSo they're very cautious about removing.\\nSo maybe it's, um, and maybe the bots are really good at learning what gets\\nremoved and not such that they can stay ahead of the removal process very quickly.\\nMy impression of it honestly is, uh, there's a lot of loaning fruit.\\nI mean, yeah, just that's what I, it's not subtle.\\nMy impression of it.\\nIt's not subtle, but you have to, yeah, that's my impression as well, but it\\nfeels like maybe you're seeing the, the tip of the iceberg, maybe the number of\\nbots isn't like the trillions and you have to like, yeah, just, it's a\\nconstant assault of bots and you, yeah, I don't know, um, you have to steal man\\nin the case, cause the bots I'm seeing are pretty like obvious.\\nI could write a few lines of code that catch these spots.\\nI mean, definitely there's a lot of loaning fruit, but I will say, I agree\\nthat if you are a sophisticated actor, you could probably create a pretty good\\nbot right now, um, you know, using tools like GPTs, uh, because it's a language\\nmodel, you can generate faces that look quite good now, uh, and you can do this\\nat scale.\\nAnd so I think, um, yeah, it's quite plausible and it's going to be hard to defend.\\nThere was a Google engineer that claimed that, uh, Lambda was sentient.\\nDo you think there's any inkling of truth to what he felt?\\nAnd more importantly, to me, at least, do you think language models will achieve\\nsentience or the illusion of sentience soonish?\\nYeah, to me, it's a little bit of a canary in a coal mine kind of moment,\\nhonestly, a little bit, uh, because, uh, so this engineer spoke to like a chat\\nbot at Google and, uh, became convinced that, uh, this bot is sentient.\\nHe asked us some existential philosophical questions and gave like\\nreasonable answers and looked real and, uh, and so on.\\nUh, so to me, it's a, uh, he was, he was, uh, he wasn't sufficiently trying to\\nstress the system, I think, and, uh, exposing the truth of it as it is today.\\nUm, but, uh, I think this will be increasingly harder over time.\\nUh, so, uh, yeah, I think more and more people will basically, uh, become, um,\\nyeah, I think more and more, there'll be more people like that over time.\\nAs, as this gets better, like form an emotional connection to an AI.\\nPlausible in my mind.\\nI think these AIs are actually quite good at human, human connection, human\\nemotion, a ton of text on the internet is about humans and connection and love\\nand so on, so I think they have a very good understanding in some, in some sense\\nof, of how people speak to each other about this and, um, they're very capable\\nof creating a lot of that kind of text.\\nThe, um, there's a lot of like sci-fi from fifties and sixties that imagined\\nAIs in a very different way.\\nThey are calculating cold Vulcan like machines.\\nThat's not what we're getting today.\\nWe're getting pretty emotional AIs that actually, uh, are very competent and\\ncapable of generating, you know, plausible sounding text with respect to all of\\nthese topics.\\nSee, I'm really hopeful about AI systems that are like companions that help you\\ngrow, develop as a human being, uh, help you maximize long-term happiness.\\nBut I'm also very worried about AI systems that figure out from the\\ninternet, the humans get attracted to drama.\\nAnd so these would just be like shit talking AIs.\\nThey just constantly, did you hear it?\\nLike they'll do gossip.\\nThey'll do, uh, they'll try to plant seeds of suspicion to other humans that\\nyou love and trust and, uh, just kind of mess with people, uh, in the, you know,\\ncause, cause that's going to get a lot of attention to drama, maximize drama on\\nthe path to maximizing, uh, engagement and us humans will feed into that machine\\nand get, it'll be a giant drama shit storm.\\nUh, so I'm worried about that.\\nSo it's the objective function really defines the way that human civilization\\nprogresses with AIs in it.\\nI think right now, at least today, they are not sort of, it's not correct to\\nreally think of them as goal seeking agents that want to do something.\\nThey have no long-term memory or anything.\\nThey it's literally a good approximation of it is you get a thousand words and\\nyou're trying to predict a thousand at first, and then you continue feeding it\\nin and you are free to prompt it in whatever way you want.\\nSo in text, so you say, okay, you are a psychologist and you are very good\\nand you love humans and here's a conversation between you and another human.\\nHuman colon, something you something, and then it just continues the pattern.\\nAnd suddenly you're having a conversation with a fake psychologist\\nwho's like trying to help you.\\nAnd so it's still kind of like in a realm of a tool is a, um, people can prompt\\nit in arbitrary ways and it can create really incredible text, but it doesn't\\nhave long-term goals over long periods of time.\\nIt doesn't try to, uh, so it doesn't look that way right now.\\nYeah, but you can do short-term goals that have long-term effects.\\nSo if my prompting short-term goal is to get Andre Capati to respond to me on\\nTwitter, whenever, like I think AI might that's the goal, but it might figure out\\nthat talking shit to you, it would be the best in a highly sophisticated, interesting\\nway.\\nAnd then you build up a relationship when you were spelling once and then it\\nlike over time it gets to not be sophisticated and just like just\\ntalk shit.\\nAnd okay, maybe you won't get to Andre, but it might get to another\\ncelebrity, it might get into other big accounts and then it'll just, so with\\njust that simple goal, get them to respond, maximize the probability of\\nactual response.\\nYeah.\\nI mean, you could prompt a powerful model like this with their, it's opinion\\nabout how to do any possible thing you're interested in.\\nSo they will just, they're kind of on track to become these oracles.\\nI could sort of think of it that way.\\nThey are oracles.\\nCurrently it's just text, but they will have calculators.\\nThey will have access to Google search.\\nThey will have all kinds of gadgets and gizmos.\\nThey will be able to operate the internet and find different information.\\nAnd yeah, in some sense, that's kind of like currently what it looks like in\\nterms of the development.\\nDo you think it'll be an improvement eventually over what Google is for access\\nto human knowledge?\\nLike it'll be a more effective search engine to access human knowledge.\\nI think there's definite scope in building a better search engine today.\\nAnd I think Google, they have all the tools, all the people, they have\\neverything they need, they have all the puzzle pieces, they have people training\\ntransformers at scale, they have all the data.\\nIt's just not obvious if they are capable as an organization to innovate on their\\nsearch engine right now.\\nAnd if they don't, someone else will.\\nThere's absolute scope for building a significantly better search engine\\nbuilt on these tools.\\nIt's so interesting.\\nA large company where the search, there's already an infrastructure.\\nIt works as brings out a lot of money.\\nSo where structurally inside a company is their motivation to pivot?\\nTo say, we're going to build a new search engine.\\nYeah, that's hard.\\nSo it's usually going to come from a startup, right?\\nThat's that would be, yeah.\\nOr some other more competent organization.\\nSo I don't know.\\nSo currently, for example, maybe Bing has another shot at it.\\nYou know, as an example.\\nMicrosoft Edge, we're talking offline.\\nI mean, it definitely is really interesting because search engines used to be about,\\nOK, here's some query.\\nHere's here's here's web pages that look like the stuff that you have.\\nBut you could just directly go to answer and then have supporting evidence.\\nAnd these these models, basically, they've read all the text and they've read all the\\nweb pages.\\nAnd so sometimes when you see yourself going over to search results and sort of getting\\nlike a sense of like the average answer to whatever you're interested in, like that just\\ndirectly comes out.\\nYou don't have to do that work.\\nSo they're kind of like.\\nYeah, I think they have a way to this of distilling all that knowledge into.\\nLike some level of insight, basically.\\nDo you think of prompting as a kind of teaching and learning like this whole process,\\nlike another layer?\\nYou know, because maybe that's what humans are.\\nWe already have that background model and you're the world is prompting you.\\nYeah, exactly.\\nI think the way we are programming these models is that we're trying to make it\\nlike computers now like GPT's is converging to how you program humans.\\nI mean, how do I program humans via prompt?\\nI go to people and I prompt them to do things.\\nI prompt them from information.\\nAnd so natural language prompt is how we program humans.\\nAnd we're starting to program computers directly in that interface.\\nIt's like pretty remarkable, honestly.\\nSo you've spoken a lot about the idea of software 2.0.\\nAll good ideas become like cliches so quickly, like the terms.\\nIt's kind of hilarious.\\nIt's like I think Eminem once said that like if he gets annoyed by a song he's written\\nvery quickly, that means it's going to be a big hit because it's too catchy.\\nBut can you describe this idea and how you're thinking about it has evolved over the\\nmonths and years since since you coined it?\\nYeah.\\nYes, I had a blog post on software 2.0, I think several years ago now.\\nAnd the reason I wrote that post is because I kept I kind of saw something remarkable\\nhappening in like software development and how a lot of code was being transitioned to\\nbe written not in sort of like C++ and so on, but it's written in the weights of a\\nneural net, basically just saying that neural nets are taking over software, the realm of\\nsoftware and taking more and more tasks.\\nAnd at the time, I think not many people understood this deeply enough that this is a big\\ndeal. It's a big transition.\\nNeural networks were seen as one of multiple classification algorithms you might use for\\nyour data set problem on Kaggle.\\nLike this is not that this is a change in how we program computers.\\nAnd I saw neural nets as this is going to take over.\\nThe way we program computers is going to change.\\nIt's not going to be people writing software in C++ or something like that and directly\\nprogramming the software. It's going to be accumulating training sets and data sets and\\ncrafting these objectives by which you train these neural nets.\\nAnd at some point, there's going to be a compilation process from the data sets and the\\nobjective and the architecture specification into the binary, which is really just the\\nneural net weights and the forward pass of the neural net.\\nAnd then you can deploy that binary.\\nAnd so I was talking about that sort of transition and that's what the post is about.\\nAnd I saw this sort of play out in a lot of fields, autopilot being one of them, but\\nalso just simple image classification.\\nPeople thought originally, you know, in the 80s and so on that they would write the\\nalgorithm for detecting a dog in an image.\\nAnd they had all these ideas about how the brain does it.\\nAnd first we detect corners and then we detect lines and then we stitch them up.\\nAnd they were like really going at it.\\nThey were like thinking about how they're going to write the algorithm.\\nAnd this is not the way you build it.\\nAnd there was a smooth transition where, OK, first we thought we were going to build\\neverything. Then we were building the features.\\nSo like hog features and things like that that detect these little statistical patterns\\nfrom image patches. And then there was a little bit of learning on top of it, like a\\nsupport vector machine or binary classifier for cat versus dog and images on top of the\\nfeatures. So we wrote the features, but we trained the last layer, sort of the\\nclassifier. And then people are like, actually, let's not even design the features\\nbecause we can't. Honestly, we're not very good at it.\\nSo let's also learn the features.\\nAnd then you end up with basically a convolutional neural net where you're learning\\nmost of it. You're just specifying the architecture and the architecture has tons of\\nfill in the blanks, which is all the knobs, and you let the optimization write most of\\nit. And so this transition is happening across the industry everywhere.\\nAnd suddenly we end up with a ton of code that is written in neural net weights.\\nAnd I was just pointing out that the analogy is actually pretty strong.\\nAnd we have a lot of developer environments for software 1.0, like we have IDEs, how\\nyou work with code, how you debug code, how you run code, how do you maintain code?\\nWe have GitHub. So I was trying to make those analogies in the new realm.\\nLike, what is the GitHub of software 2.0?\\nTurns out it's something that looks like hugging face right now.\\nYou know, and so I think some people took it seriously and built cool companies.\\nAnd many people originally attacked the post.\\nIt actually was not well received when I wrote it.\\nAnd I think maybe it has something to do with the title, but the post was not well\\nreceived. And I think more people sort of have been coming around to it over time.\\nYeah. So you were the director of AI at Tesla where I think this idea was really\\nimplemented at scale, which is how you have engineering teams doing software 2.0.\\nSo can you sort of linger on that idea of, I think we're in the really early stages\\nof everything you just said, which is like GitHub IDEs.\\nLike how do we build engineering teams that that work in software 2.0 systems and\\nthe data collection and the data annotation, which is all part of that\\nsoftware 2.0. Like, what do you think is the task of programming in software 2.0?\\nIs it debugging in the space of hyperparameters or is it also debugging in\\nthe space of data?\\nYeah. The way by which you program the computer and influence its algorithm is\\nnot by writing the commands yourself.\\nYou're changing mostly the data set.\\nYou're changing the loss functions of like what the neural net is trying to do, how\\nit's trying to predict things. But basically the data sets and the architecture of\\nthe neural net. And so in the case of the autopilot, a lot of the data sets have to\\ndo with, for example, detection of objects and lane line markings and traffic lights\\nand so on. So you accumulate massive data sets of here's an example, here's the\\ndesired label, and then here's roughly how the architect, here's roughly what the\\nalgorithm should look like. And that's a convolutional neural net.\\nSo the specification of the architecture is like a hint as to what the algorithm\\nshould roughly look like. And then the fill in the blanks process of optimization is\\nthe training process. And then you take your neural net that was trained, it gives\\nall the right answers on your data set and you deploy it.\\nSo there is in that case, perhaps at all machine learning cases, there's a lot of\\ntasks. So is coming up, formulating a task like for a multi-headed neural network is\\nformulating a task part of the programming? Yeah, very much so. How you break down a\\nproblem into a set of tasks. Yeah. I'm on a high level, I would say, if you look at\\nthe software running in the autopilot, I gave a number of talks on this topic. I\\nwould say originally a lot of it was written in software 1.0. There's imagine lots of C++,\\nright? And then gradually there was a tiny neural net that was, for example, predicting, given a\\nsingle image, is there like a traffic light or not? Or is there a landline marking or not?\\nAnd this neural net didn't have too much to do in the scope of the software. It was making tiny\\npredictions on individual little image. And then the rest of the system stitched it up. So, okay,\\nwe're actually, we don't have just a single camera, we have eight cameras. We actually have eight\\ncameras over time. And so what do you do with these predictions? How do you put them together?\\nHow do you do the fusion of all that information? And how do you act on it? All of that was written\\nby humans in C++. And then we decided, okay, we don't actually want to do all of that fusion\\nin C++ code because we're actually not good enough to write that algorithm. We want the neural nets\\nto write the algorithm and we want to port all of that software into the 2.0 stack. And so then we\\nactually had neural nets that now take all the eight camera images simultaneously and make\\npredictions for all of that. And actually they don't make predictions in the space of images,\\nthey now make predictions directly in 3D. And actually they don't in three dimensions around\\nthe car. And now actually we don't manually fuse the predictions in 3D over time. We don't trust\\nourselves to write that tracker. So actually we give the neural net the information over time.\\nSo it takes these videos now and makes those predictions. And so you're sort of just like\\nputting more and more power into the neural net, more processing. And at the end of it, the\\neventual goal is to have most of the software potentially be in the 2.0 land because it works\\nsignificantly better. Humans are just not very good at writing software basically.\\nSo the prediction is happening in this 4D land with three dimensional world over time. How do you\\ndo annotation in that world? So data annotation, whether it's self-supervised or manual by humans\\nis a big part of the software 2.0 world. Right. I would say by far in the industry,\\nif you're talking about the industry and what is the technology of what we have available,\\neverything is supervised learning. So you need data sets of input, desired output,\\nand you need lots of it. And there are three properties of it that you need. You need it to\\nbe very large, you need it to be accurate, no mistakes, and you need it to be diverse.\\nYou don't want to just have a lot of correct examples of one thing. You need to really cover\\nthe space of possibility as much as you can. And the more you can cover the space of possible inputs,\\nthe better the algorithm will work at the end. Now, once you have really good data sets that you're\\ncollecting, curating, and cleaning, you can train your neural net on top of that. So a lot of the\\nwork goes into cleaning those data sets. Now, as you pointed out, it could be the question is,\\nhow do you achieve a ton of... If you want to basically predict in 3D, you need data in 3D\\nto back that up. So in this video, we have eight videos coming from all the cameras of the system.\\nAnd this is what they saw. And this is the truth of what actually was around. There was this car,\\nthere was this car, this car. These are the lane line markings. This is the geometry of the road.\\nThere was traffic light in this three-dimensional position. You need the ground truth. And so the\\nbig question that the team was solving, of course, is how do you arrive at that ground truth? Because\\nonce you have a million of it, and it's large, clean, and diverse, then training a neural net\\non it works extremely well. And you can ship that into the car. And so there's many mechanisms by\\nwhich we collected that training data. You can always go for human annotation. You can go for\\nsimulation as a source of ground truth. You can also go for what we call the offline tracker\\nthat we've spoken about at the AI day and so on, which is basically an automatic reconstruction\\nprocess for taking those videos and recovering the three-dimensional reality of what was around\\nthat car. So basically think of doing a three-dimensional reconstruction as an\\noffline thing, and then understanding that, okay, there's 10 seconds of video. This is what we saw.\\nAnd therefore, here's all the lane lines, cars, and so on. And then once you have that annotation,\\nyou can train your neural net to imitate it. And how difficult is the three-D reconstruction?\\nIt's difficult, but it can be done. So there's overlap between the cameras\\nand you do the reconstruction. And there's perhaps if there's any inaccuracy,\\nso that's caught in the annotation step. Yes. The nice thing about the annotation is that it is\\nfully offline. You have infinite time. You have a chunk of one minute and you're trying to just\\noffline in a supercomputer somewhere, figure out where were the positions of all the cars,\\nall the people, and you have your full one minute of video from all the angles.\\nAnd you can run all the neural nets you want, and they can be very efficient, massive neural nets.\\nThere can be neural nets that can't even run in the car later at test time. So they can be even\\nmore powerful neural nets than what you can eventually deploy. So you can do anything you\\nwant, three-dimensional reconstruction, neural nets, anything you want just to recover that truth,\\nand then you supervise that truth. What have you learned? You said no mistakes about humans\\ndoing annotation because I assume humans are... There's like a range of things they're good at\\nin terms of clicking stuff on screen. Isn't that... How interesting is that to you of a problem of\\ndesigning an annotator where humans are accurate, enjoy it? What are even the metrics? Are efficient\\nor productive, all that kind of stuff? Yeah. So I grew the annotation team at\\nTesla from basically zero to a thousand while I was there. That was really interesting. My background\\nis a PhD student researcher, so growing that kind of an organization was pretty crazy.\\nBut yeah, I think it's extremely interesting and part of the design process very much behind the\\nautopilot as to where you use humans. Humans are very good at certain kinds of annotations.\\nThey're very good, for example, at two-dimensional annotations of images. They're not good at\\nannotating cars over time in three-dimensional space, very, very hard. And so that's why we're\\nvery careful to design the tasks that are easy to do for humans versus things that should be left to\\nthe offline tracker. Like maybe the computer will do all the triangulation and 3D reconstruction,\\nbut the human will say exactly these pixels of the image are a car, exactly these pixels are human.\\nAnd so co-designing the data annotation pipeline was very much\\nbread and butter, was what I was doing daily. Do you think there's still a lot of open problems\\nin that space? Just in general, annotation where the stuff the machines are good at,\\nmachines do and the humans do what they're good at, and there's maybe some iterative process.\\nRight. I think to a very large extent, we went through a number of iterations and we learned a\\nton about how to create these data sets. I'm not seeing big open problems. Originally when I joined,\\nI was really not sure how this would turn out. But by the time I left, I was much more secure and\\nunderstand the philosophy of how to create these data sets. And I was pretty comfortable with\\nwhere that was at the time. So what are strengths and limitations of cameras for the driving task\\nin your understanding when you formulate the driving task as a vision task with eight cameras?\\nYou've seen that the entire, most of the history of the computer vision field,\\nwhen it has to do with neural networks, just if you step back, what are the strengths and limitations\\nof pixels, of using pixels to drive? Yeah. Pixels I think are a beautiful sensor,\\nbeautiful sensor, I would say. The thing is like cameras are very, very cheap and they provide a\\nton of information, ton of bits. Also it's extremely cheap sensor for a ton of bits. And each one of\\nthese bits is a constraint on the state of the world. And so you get lots of megapixel images,\\nvery cheap. And it just gives you all these constraints for understanding what's actually\\nout there in the world. So vision is probably the highest bandwidth sensor. It's a very high\\nbandwidth sensor. I love that pixels is a constraint on the world. It's this highly complex,\\nhigh bandwidth constraint on the state of the world. And it's not just that, but again, this\\nreal importance of it's the sensor that humans use. Therefore, everything is designed for that\\nsensor. The text, the writing, the flashing signs, everything is designed for vision. And so\\nyou just find it everywhere. And so that's why that is the interface you want to be in,\\ntalking again about these universal interfaces. And that's where we actually want to measure the\\nworld as well and then develop software for that sensor. But there's other constraints on the state\\nof the world that humans use to understand the world. I mean, vision ultimately is the main one,\\nbut we're referencing our understanding of human behavior and some common sense physics\\nthat could be inferred from vision from a perception perspective. But it feels like\\nwe're using some kind of reasoning to predict the world, not just the pixels.\\nI mean, you have a powerful prior service for how the world evolves over time, et cetera. So it's\\nnot just about the likelihood term coming up from the data itself telling you about what you are\\nobserving, but also the prior term of where are the likely things to see and how do they likely\\nmove and so on. And the question is how complex is the range of possibilities that might happen\\nin the driving task? Is that to you still an open problem of how difficult is driving,\\nlike philosophically speaking? All the time you worked on driving, do you understand how\\nhard driving is? Yeah, driving is really hard because it has to do with the predictions of\\nall these other agents and the theory of mind and what they're going to do and are they looking\\nat you? Where are they looking? Where are they thinking? There's a lot that goes there at the\\nfull tail of the expansion of the knives that we have to be comfortable with eventually.\\nThe final problems are of that form. I don't think those are the problems that are very common.\\nI think eventually they're important, but it's really in the tail end.\\nIn the tail end, the rare edge cases. From the vision perspective, what are the toughest parts\\nof the vision problem of driving? Well, basically the sensor is extremely powerful,\\nbut you still need to process that information. And so going from brightnesses of these special\\nvalues to, hey, here are the three-dimensional world is extremely hard. And that's what the\\nneural networks are fundamentally doing. And so the difficulty really is in just doing an extremely\\ngood job of engineering the entire pipeline, the entire data engine, having the capacity to train\\nthese neural nets, having the ability to evaluate the system and iterate on it. So I would say just\\ndoing this in production at scale is like the hard part. It's an execution problem.\\nSo the data engine, but also the deployment of the system such that it has low latency performance.\\nSo it has to do all these steps. Yeah, for the neural net specifically,\\njust making sure everything fits into the chip on the car. And you have a finite budget of flops\\nthat you can perform and memory bandwidth and other constraints. And you have to make sure it\\nflies and you can squeeze in as much computer as you can into the tiny. What have you learned from\\nthat process? Because maybe that's one of the bigger, like new things coming from a research\\nbackground where there's a system that has to run under heavily constrained resources,\\nhas to run really fast. What kind of insights have you learned from that?\\nYeah, I'm not sure if there's too many insights. You're trying to create a neural net that will\\nfit in what you have available and you're always trying to optimize it. And we talked a lot about\\nit on the AI day and basically the triple backflips that the team is doing to make sure it all fits\\nand utilizes the engine. So I think it's extremely good engineering. And then there's all kinds of\\nlittle insights peppered in on how to do it properly. Let's actually zoom out because I\\ndon't think we talked about the data engine, the entirety of the layouts of this idea that I think\\nis just beautiful with humans in the loop. Can you describe the data engine? Yeah, the data engine is\\nwhat I call the almost biological feeling like process by which you perfect the training sets\\nfor these neural networks. So because most of the programming now is in the level of these data sets\\nand make sure they're large, diverse and clean. Basically, you have a data set that you think is\\ngood. You train your neural net, you deploy it, and then you observe how well it's performing.\\nAnd you're trying to always increase the quality of your data set. So you're trying to catch\\nscenarios basically that are basically rare. And it is in these scenarios that the neural nets\\nwill typically struggle in because they weren't told what to do in those rare cases in the data\\nset. But now you can close the loop because if you can now collect all those at scale, you can then\\nfeed them back into the reconstruction process I described and reconstruct the truth in those cases\\nand add it to the data set. And so the whole thing ends up being like a staircase of improvement\\nof perfecting your training set. And you have to go through deployments so that you can mine\\nthe parts that are not yet represented well in the data set. So your data set is basically imperfect.\\nIt needs to be diverse. It has pockets that are missing and you need to pad out the pockets. You\\ncan sort of think of it that way in the data. What role do humans play in this? So what's this\\nbiological system? Like are human bodies made up of cells? What role, like how do you optimize the\\nhuman system? The multiple engineers collaborating, figuring out what to focus on, what to contribute,\\nwhich task to optimize in this neural network. Who is in charge of figuring out which task needs\\nmore data? Can you speak to the hyperparameters of the human system? It really just comes down\\nto extremely good execution from an engineering team who knows what they're doing. They understand\\nintuitively the philosophical insights underlying the data engine and the process by which the\\nsystem improves and how to again, delegate the strategy of the data collection and how that\\nworks and then just making sure it's all extremely well executed. And that's where most of the work\\nis not even the philosophizing or the research or the ideas of it. It's just extremely good\\nexecution. It's so hard when you're dealing with data at that scale. So your role in the data engine\\nexecuting well on it is difficult and extremely important. Is there a priority of like a vision\\nboard of saying like, we really need to get better at stoplights? Yeah. Like the prioritization of\\ntasks. Is that essentially, and that comes from the data? That comes to a very large extent to\\nwhat we are trying to achieve in the product for a map or the release we're trying to get out\\nin the feedback from the QA team where the system is struggling or not, the things we're\\ntrying to improve. And the QA team gives some signal, some information in aggregate about the\\nperformance of the system in various conditions. That's right. And then of course, all of us drive\\nit and we can also see it. It's really nice to work with a system that you can also experience\\nyourself and it drives you home. Is there some insight you can draw from your individual\\nexperience that you just can't quite get from an aggregate statistical analysis of data? Yeah.\\nIt's so weird, right? Yes. It's not scientific in a sense because you're just one anecdotal sample.\\nYeah. I think there's a ton of, it's a source of truth. It's your interaction with the system\\nand you can see it, you can play with it, you can perturb it, you can get a sense of it,\\nyou have an intuition for it. I think numbers just like have a way of, numbers and plots and graphs\\nare much harder. It hides a lot of- It's like if you train a language model,\\nit's a really powerful way is by you interacting with it. Yeah, 100%.\\nTry to build up an intuition. Yeah. I think like Ilan also, he always wanted to drive the system\\nhimself. He drives a lot and I want to say almost daily. So he also sees this as a source of truth,\\nyou driving the system and it performing and yeah.\\nSo what do you think? Tough questions here. So Tesla last year removed radar from\\nthe sensor suite and now just announced that it's going to remove ultrasonic sensors\\nrelying solely on vision, so camera only. Does that make the perception problem harder or easier?\\nI would almost reframe the question in some way. So the thing is basically,\\nyou would think that additional sensors- By the way, can I just interrupt?\\nGo ahead. I wonder if a language model will ever do that if you prompt it. Let me reframe your\\nquestion. That would be epic. That's the wrong prompt. Sorry. It's like a little bit of a wrong\\nquestion because basically you would think that these sensors are an asset to you. Yeah. But if\\nyou fully consider the entire product in its entirety, these sensors are actually potentially\\nliability because these sensors aren't free. They don't just appear on your car. You need\\nsuddenly you need to have an entire supply chain. You have people procuring it. There can be\\nproblems with them. They may need replacement. They are part of the manufacturing process. They\\ncan hold back the line in production. You need to source them. You need to maintain them. You have\\nto have teams that write the firmware, all of it. And then you also have to incorporate them,\\nfuse them into the system in some way. And so it actually like bloats a lot of it. And I think\\nElon is really good at simplify, simplify. Best part is no part. And he always tries to throw away\\nthings that are not essential because he understands the entropy in organizations and in the approach.\\nAnd I think in this case, the cost is high and you're not potentially seeing it if you're just a\\ncomputer vision engineer. And I'm just trying to improve my network and is it more useful or less\\nuseful? How useful is it? And the thing is once you consider the full cost of a sensor, it actually\\nis potentially a liability. And you need to be really sure that it's giving you extremely useful\\ninformation. In this case, we looked at using it or not using it and the Delta was not massive.\\nAnd so it's not useful. Is it also bloat in the data engine? Like having more sensors? Is it\\ndistraction? And these sensors, you know, they can change over time. For example, you can have one\\ntype of say radar, you can have other type of radar. They change over time. Now you suddenly\\nneed to worry about it. Now suddenly you have a column in your SQLite telling you, oh, what\\nsensor type was it? And they all have different distributions. And then they can, they just,\\nthey contribute noise and entropy into everything. And they bloat stuff. And also organizationally\\nhas been really fascinating to me that it can be very distracting. If you, if all, if you only\\nwant to get to work is vision, all the resources are on it and you're building out a data engine\\nand you're actually making forward progress because that is the sensor with the most bandwidth,\\nthe most constraints in the world. And you're investing fully into that. And you can make that\\nextremely good. If you're, you're only a finite amount of sort of spend of focus across different\\nfacets of the system. And this kind of reminds me of Rich Sutton's, the bitter lesson.\\nIt just seems like simplifying the system. Yeah. In the long run. And of course, you don't know\\nwhat the long run is. It seems to be always the right solution. Yeah. Yes. In that case, it was\\nfor RL, but it seems to apply generally across all systems that do computation. Yeah. So where,\\nwhat do you think about the lidar as a crutch debate? The battle between point clouds and pixels.\\nYeah. I think this debate is always like slightly confusing to me because it seems like the actual\\ndebate should be about like, do you have the fleet or not? That's like the really important\\nthing about whether you can achieve a really good functioning of an AI system at this scale. So data\\ncollection systems. Yeah. Do you have a fleet or not is significantly more important, whether you\\nhave lidar or not. It's just another sensor. And yeah, I think similar to the radar discussion,\\nbasically, I don't think it basically doesn't offer extra information. It's extremely costly.\\nIt has all kinds of problems. You have to worry about it. You have to calibrate it,\\net cetera. It creates bloat and entropy. You have to be really sure that you need this sensor.\\nIn this case, I basically don't think you need it. And I think honestly, I will make a stronger\\nstatement. I think the others, some of the other companies that are using it are probably going\\nto drop it. Yeah. So you have to consider the sensor in the full, in considering, can you build\\na big fleet that collects a lot of data? And can you integrate that sensor with that data and that\\nsensor into a data engine that's able to quickly find different parts of the data that then\\ncontinuously improves whatever the model that you're using? Yeah. Another way to look at it is like\\nvision is necessary in the sense that the world is designed for human visual consumption. So you\\nneed vision. It's necessary. And then also it is sufficient because it has all the information that\\nyou need for driving and humans obviously has vision to drive. So it's both necessary and\\nsufficient. So you want to focus resources and you have to be really sure if you're going to\\nbring in other sensors. You could add sensors to infinity. At some point, you need to draw the line.\\nAnd I think in this case, you have to really consider the full cost of any one sensor.\\nThat you're adopting and do you really need it? And I think the answer in this case is no.\\nSo what do you think about the idea that the other companies are forming high resolution maps\\nand constraining heavily the geographic regions in which they operate? Is that approach not in your\\nview, not going to scale over time to the entirety of the United States? I think as you mentioned,\\nthey pre-map all the environments and they need to refresh the map. And they have a perfect\\ncentimeter level accuracy map of everywhere they're going to drive. It's crazy. We've been\\ntalking about the autonomy actually changing the world. We're talking about the deployment\\non a global scale of autonomous systems for transportation. And if you need to maintain\\na centimeter accurate map for Earth or for many cities and keep them updated, it's a huge\\ndependency that you're taking on. Huge dependency. It's a massive, massive dependency. And now you\\nneed to ask yourself, do you really need it? And humans don't need it. So it's very useful to have\\na low level map of like, okay, the connectivity of your road. You know that there's a fork coming up.\\nWhen you drive an environment, you have that high level understanding. It's like a small Google map\\nand Tesla uses Google map, similar kind of resolution information in the system, but it\\nwill not pre-map environments to send me a level of accuracy. It's a crutch. It's a distraction.\\nIt costs entropy and it diffuses the team. It dilutes the team. And you're not focusing\\non what's actually necessary, which is the computer vision problem. What did you learn\\nabout machine learning, about engineering, about life, about yourself as one human being\\nfrom working with Elon Musk? I think the most I've learned is about how to sort of run organizations\\nefficiently and how to create efficient organizations and how to fight entropy in an organization.\\nSo human engineering in the fight against entropy. Yeah. I think Elon is a very efficient warrior\\nin the fight against entropy in organizations. What does entropy in an organization look like?\\nIt's process. It's process and inefficiencies in the form of meetings and that kind of stuff.\\nYeah. Meetings. He hates meetings. He keeps telling people to skip meetings if they're not useful.\\nHe basically runs the world's biggest startups, I would say. Tesla, SpaceX are the world's biggest\\nstartups. Tesla actually has multiple startups. I think it's better to look at it that way.\\nAnd so I think he's extremely good at that. And yeah, he has a very good intuition for\\nstreamlining processes, making everything efficient. Best part is no part, simplifying, focusing,\\nand just kind of removing barriers, moving very quickly, making big moves.\\nAll of this is very startupy sort of seeming things, but at scale.\\nSo strong drive to simplify. From your perspective, I mean, that also probably applies to just\\ndesigning systems and machine learning and otherwise. Like simplify, simplify.\\nYes. What do you think is the secret to maintaining the startup culture in a company that grows?\\nCan you introspect that?\\nI do think you need someone in a powerful position with a big hammer like Elon, who's like\\nthe cheerleader for that idea and ruthlessly pursues it. If no one has a big enough hammer,\\neverything turns into committees, democracy within the company, process, talking to stakeholders,\\ndecision making, just everything just crumbles. If you have a big person who's also really smart\\nand has a big hammer, things move quickly. So you said your favorite scene in Interstellar\\nis the intense docking scene with the AI and Cooper talking, saying,\\nCooper, what are you doing docking? It's not possible. No, it's necessary. Such a good line.\\nBy the way, just so many questions there. Why an AI in that scene, presumably is supposed to be\\nable to compute a lot more than the human. It's saying it's not optimal. Why the human? I mean,\\nthat's a movie, but shouldn't the AI know much better than the human? Anyway, what do you think\\nis the value of setting seemingly impossible goals? Our initial intuition, which seems like\\nsomething that you have taken on that Elon espouses, where the initial intuition of the\\ncommunity might say this is very difficult and then you take it on anyway with a crazy deadline.\\nYou just from a human engineering perspective, have you seen the value of that?\\nI wouldn't say that setting impossible goals exactly is a good idea, but I think setting very\\nambitious goals is a good idea. I think there's what I call sub-linear scaling of difficulty,\\nwhich means that 10x problems are not 10x hard. Usually 10x harder problem is like 2 or 3x harder\\nto execute on. If you want to improve a system by 10%, it costs some amount of work. If you want to\\n10x improve the system, it doesn't cost 100x amount of work. It's because you fundamentally\\nchange the approach. If you start with that constraint, then some approaches are obviously\\ndumb and not going to work. It forces you to reevaluate. I think it's a very interesting way\\nof approaching problem solving. It requires a weird kind of thinking. Going back to your PhD\\ndays, how do you think which ideas in the machine learning community are solvable?\\nYes.\\nIt requires, what is that? There's the cliche of first principles thinking, but it requires\\nto basically ignore what the community is saying because doesn't a community in science usually\\ndraw lines of what is and isn't possible? It's very hard to break out of that without going crazy.\\nI think a good example here is the deep learning revolution in some sense because you could\\nbe in computer vision at that time during the deep learning revolution of 2012 and so on.\\nYou could be improving a computer vision stack by 10% or you can just be saying,\\nactually all of this is useless. How do I do 10x better computer vision? Well, it's not probably\\nby tuning a hog feature detector. I need a different approach. I need something that is\\nscalable. Going back to Richard Sutton's understanding the philosophy of the bitter lesson\\nand then being like, actually I need much more scalable system like a neural network\\nthat in principle works and then having some deep believers that can actually\\nexecute on that mission and make it work. That's the 10x solution.\\nWhat do you think is the timeline to solve the problem of autonomous driving?\\nThat's still in part an open question.\\nYeah. I think the tough thing with timelines of self-driving obviously is that no one has created\\nself-driving. It's not like, what do you think is the timeline to build this bridge? Well,\\nwe've built million bridges before. Here's how long that takes. No one has built autonomy. It's\\nnot obvious. Some parts turn out to be much easier than others. It's really hard to forecast. You do\\nyour best based on trend lines and so on and based on intuition, but that's why fundamentally it's\\njust really hard to forecast this. Even still being inside of it, it's hard to do. Yes. Some\\nthings turn out to be much harder and some things turn out to be much easier. Do you try to avoid\\nmaking forecasts? Because Elon doesn't avoid them, right? Heads of car companies in the past have\\nnot avoided it either. Ford and other places have made predictions that we're going to solve\\nat level four driving by 2020, 2021, whatever. They're all kind of backtracking that prediction.\\nAre you, as an AI person, do you for yourself privately make predictions or do they get in\\nthe way of your actual ability to think about a thing? Yeah, I would say what's easy to say is\\nthat this problem is tractable and that's an easy prediction to make. It's tractable. It's going to\\nwork. Yes. It's just really hard. Some things turn out to be harder and some things turn out to be\\neasier. It definitely feels tractable and it feels like at least the team at Tesla,\\nwhich is what I saw internally, is definitely on track to that. How do you form a strong\\nrepresentation that allows you to make a prediction about tractability? You're the leader of a lot of\\nhumans. You have to say this is actually possible. How do you build up that intuition? It doesn't\\nhave to be even driving. It could be other tasks. What difficult tasks did you work on in your life?\\nClassification, achieving certain, just an image net, certain level of superhuman level performance.\\nYeah, expert intuition. It's just intuition. It's belief.\\nSo just thinking about it long enough, studying, looking at sample data, like you said, driving.\\nMy intuition is really flawed on this. I don't have a good intuition about tractability.\\nIt could be anything. It could be solvable. The driving task could be\\nsimplified into something quite trivial. The solution to the problem would be quite trivial.\\nAt scale, more and more cars driving perfectly might make the problem much easier. The more\\ncars you have driving, people learn how to drive correctly, not correctly, but in a way that's more\\noptimal for a heterogeneous system of autonomous and semi-autonomous and manually driven cars.\\nThat could change stuff. Then again, also I've spent a ridiculous number of hours just staring\\nat pedestrians crossing streets, thinking about humans. It feels like the way we use our eye\\ncontact, it sends really strong signals. There's certain quirks and edge cases of behavior. Of\\ncourse, a lot of the fatalities that happen have to do with drunk driving and both on the\\npedestrian side and the driver side. There's that problem of driving at night and all that kind of.\\nIt's like the space of possible solutions to autonomous driving includes so many human factor\\nissues that it's almost impossible to predict. There could be super clean, nice solutions.\\nI would say definitely like to use a game analogy, there's some fog of war,\\nbut you definitely also see the frontier of improvement. You can measure historically how\\nmuch you've made progress. I think, for example, at least what I've seen in roughly five years at\\nTesla, when I joined, it barely kept lane on the highway. I think going up from Palo Alto to SF\\nwas like three or four interventions. Anytime the road would do anything geometrically or turn too\\nmuch, it would just not work. Going from that to a pretty competent system in five years and seeing\\nwhat happens also under the hood and what the scale of which the team is operating now with\\nrespect to data and compute and everything else is just massive progress. You're climbing a mountain\\nand it's fog, but you're making a lot of progress. It's fog. You're making progress and you see what\\nthe next directions are and you're looking at some of the remaining challenges and they're not\\nperturbing you and they're not changing your philosophy and you're not contorting yourself.\\nYou're like, actually, these are the things that we still need to do. Yeah, the fundamental\\ncomponents of solving the problem seem to be there from the data engine to the compute to the\\ncompute on the car to the compute for the training, all that kind of stuff.\\nSo you've done over the years, you've been at Tesla, you've done a lot of amazing\\nbreakthrough ideas and engineering, all of it from the data engine to the human side, all of it.\\nCan you speak to why you chose to leave Tesla? Basically, as I described that, Ren, I think over\\ntime during those five years, I've gotten myself into a bit of a managerial position.\\nMost of my days were meetings and growing the organization and making decisions about high\\nlevel strategic decisions about the team and what it should be working on and so on. It's like a\\ncorporate executive role and I can do it. I think I'm okay at it, but it's not fundamentally what I\\nenjoy. I think when I joined, there was no computer vision team because Tesla was just going from the\\ntransition of using Mobileye, a third party vendor for all of its computer vision, to having to\\nbuild its computer vision system. So when I showed up, there were two people training deep neural\\nnetworks and they were training them at a computer at their legs. They were doing some kind of basic\\nclassification task. Yeah. And so I kind of grew that into what I think is a fairly respectable\\ndeep learning team, a massive compute cluster, a very good data annotation organization.\\nAnd I was very happy with where that was. It became quite autonomous. And so I kind of\\nstepped away and I'm very excited to do much more technical things again. Yeah. And kind of like,\\nwe focus on AGI. What was that soul searching like? Cause you took a little time off and think like\\nwhat, how many mushrooms did you take? No, I'm just kidding. I mean, what was going through your mind?\\nThe human lifetime is finite. Yeah. You did a few incredible things here. You're one of the best\\nteachers of AI in the world. You're one of the best. And I don't mean that I mean that in the\\nbest possible way. You're one of the best tinkerers in the AI world, meaning like understanding the\\nfundamentals of how something works by building it from scratch and playing with it with the\\nbasic intuitions. It's like Einstein, Feynman, we're all really good at this kind of stuff.\\nLike small example of a thing to play with it, to try to understand it. So that, and obviously now\\nwith Tessa, you helped build a team of machine learning, like engineers and assistant that\\nactually accomplishes something in the real world. So given all that, like what was the soul searching\\nlike? Well, it was hard because obviously I love the company a lot and I love Elon, I love Tesla.\\nIt was always hard to leave. I love the team basically. But yeah, I think actually I will be\\npotentially like interested in revisiting it. Maybe coming back at some point,\\nworking in Optimus, working in AGI at Tesla. I think Tesla is going to do incredible things.\\nIt's basically like, it's a massive large scale robotics kind of company with a ton of in-house\\ntalent for doing really incredible things. And I think human robots are going to be amazing.\\nI think autonomous transportation is going to be amazing. All this is happening at Tesla. So I\\nthink it's just a really amazing organization. So being part of it and helping it along, I think\\nwas very, basically I enjoyed that a lot. Yeah, it was basically difficult for those reasons because\\nI love the company. But I'm happy to potentially at some point come back for Act 2. But I felt\\nlike at this stage, I built the team, it felt autonomous and I became a manager and I wanted\\nto do a lot more technical stuff. I wanted to learn stuff. I wanted to teach stuff. And I just\\nkind of felt like it was a good time for a change of pace a little bit. What do you think is\\nthe best movie sequel of all time, speaking of part two? Because most of them suck. Movie sequels?\\nMovie sequels, yeah. And you tweet about movies. So just in a tiny tangent,\\nwhat's a favorite movie sequel? Godfather part two. Are you a fan of Godfather? Because you\\ndidn't even tweet or mention the Godfather. Yeah, I don't love that movie. I know it has a\\nhuge follow-up. We're going to edit that out. We're going to edit out the hate towards the Godfather.\\nHow dare you disrespect- I think I will make a strong statement. I don't know why.\\nI don't know why, but I basically don't like any movie before 1995. Something like that.\\nDidn't you mention Terminator 2? Okay. Okay. That's like Terminator 2 was\\na little bit later, 1990. No, I think Terminator 2 was in the 80s.\\nAnd I like Terminator 1 as well. So, okay. So like few exceptions, but by and large,\\nfor some reason, I don't like movies before 1995 or something. They feel very slow. The camera is\\nlike zoomed out. It's boring. It's kind of naive. It's kind of weird.\\nAnd also Terminator was very much ahead of its time.\\nYes. And the Godfather, there's like no AGI.\\nI mean, but you have Good Will Hunting was one of the movies you mentioned,\\nand that doesn't have any AGI either. I guess it has mathematics.\\nYeah. I guess occasionally I do enjoy movies that don't feature-\\nOr like Anchorman. That's- Anchorman is so good.\\nI don't understand. Speaking of AGI, because I don't understand why Will Ferrell is so funny.\\nIt doesn't make sense. It doesn't compute. There's just something about him.\\nAnd he's a singular human because you don't get that many comedies these days. And I wonder if\\nit has to do about the culture or the machine of Hollywood, or does it have to do with just\\nwe got lucky with certain people in comedy. It came together because he is a singular human.\\nYeah. I like his movies.\\nThat was a ridiculous tangent. I apologize. But you mentioned humanoid robots. So what do you\\nthink about Optimus, about Tesla Bot? Do you think we'll have robots in the factory and in the home\\nin 10, 20, 30, 40, 50 years? Yeah. I think it's a very hard project.\\nI think it's going to take a while. But who else is going to build humanoid robots at scale?\\nAnd I think it is a very good form factor to go after because like I mentioned,\\nthe world is designed for humanoid form factor. These things would be able to operate our machines.\\nThey would be able to sit down in chairs, potentially even drive cars. Basically,\\nthe world is designed for humans. That's the form factor you want to invest into and make work over\\ntime. I think there's another school of thought, which is, okay, pick a problem and design a robot\\nto it. But actually designing a robot and getting a whole data engine and everything behind it to\\nwork is actually an incredibly hard problem. So it makes sense to go after general interfaces\\nthat, okay, they are not perfect for any one given task, but they actually have the generality\\nof just with a prompt with English, able to do something across. And so I think it makes a lot\\nof sense to go after a general interface in the physical world. And I think it's a very\\ndifficult project. I think it's going to take time. But I see no other company that can execute on\\nthat vision. I think it's going to be amazing. Basically physical labor. If you think transportation\\nis a large market, try physical labor. It's insane. But it's not just physical labor. To me,\\nthe thing that's also exciting is social robotics. So the relationship we'll have on different levels\\nwith those robots. That's why I was really excited to see Optimus. People have criticized me\\nfor the excitement. But I've worked with a lot of research labs that do humanoid-legged robots,\\nBoston Dynamics, Unitree. There's a lot of companies that do legged robots.\\nBut the elegance of the movement is a tiny, tiny part of the big picture. So integrating the two\\nbig exciting things to me about Tesla doing humanoid or any legged robots is clearly integrating\\ninto the data engine. So the data engine aspect, so the actual intelligence for the perception and\\nthe control and the planning and all that kind of stuff, integrating into the fleet that you\\nmentioned. And then speaking of fleet, the second thing is the mass manufacturers. Just knowing\\nculturally driving towards a simple robot that's cheap to produce at scale and doing that well,\\nhaving experience to do that well, that changes everything. That's a very different culture\\nand style than Boston Dynamics, who by the way, those robots are just the way they move.\\nIt'll be a very long time before Tesla can achieve the smoothness of movement,\\nbut that's not what it's about. It's about the entirety of the system, like we talked about,\\nthe data engine and the fleet. That's super exciting. Even the initial models. But that,\\ntoo, was really surprising that in a few months you can get a prototype.\\nThe reason that happened very quickly is, as you alluded to, there's a ton of copy paste from\\nwhat's happening on the autopilot. A lot. The amount of expertise that came out of the woodworks\\nat Tesla for building the human robot was incredible to see. Basically, Elon said at one\\npoint, we're doing this. And then next day, basically, all these CAD models started to appear.\\nPeople talk about the supply chain and manufacturing. People showed up with\\nscrewdrivers and everything the other day and started to put together the body. I was like,\\nwhoa. All these people exist at Tesla. Fundamentally, building a car is actually\\nnot that different from building a robot. That is true, not just for the hardware pieces. Also,\\nlet's not forget hardware, not just for a demo, but manufacturing of that hardware at scale.\\nIt is a whole different thing. But for software as well, basically, this robot currently thinks\\nit's a car. It's going to have a midlife crisis at some point. It thinks it's a car. Some of the\\nearlier demos, actually, we were talking about potentially doing them outside in the parking lot\\nbecause that's where all of the computer vision was working out of the box instead of inside.\\nAll the operating system, everything just copy pastes. Computer vision mostly copy pastes. You\\nhave to retrain the neural nets, but the approach and everything and data engine and offline\\ntrackers and the way we go about the occupancy tracker and so on, everything copy pastes. You\\njust need to retrain the neural nets. Then the planning control, of course, has to change quite\\na bit. But there's a ton of copy paste from what's happening at Tesla. If you were to go\\nwith the goal of like, okay, let's build a million human robots and you're not Tesla,\\nthat's a lot to ask. If you're Tesla, it's actually like, it's not that crazy.\\nYes. Then the follow-up question is then how difficult, just like with driving,\\nhow difficult is the manipulation task such that it can have an impact at scale? I think\\ndepending on the context, the really nice thing about robotics is that unless you do a\\nmanufacturing and that kind of stuff, is there's more room for error. Driving is so safety critical\\nand also time critical. A robot is allowed to move slower, which is nice.\\nYes. I think it's going to take a long time, but the way you want to structure the development is\\nyou need to say, okay, it's going to take a long time. How can I set up the product development\\nroadmap so that I'm making revenue along the way? I'm not setting myself up for a zero one\\nloss function where it doesn't work until it works. You don't want to be in that position.\\nYou want to make it useful almost immediately, and then you want to slowly deploy it\\nand at scale. And you want to set up your data engine, your improvement loops, the telemetry,\\nthe evaluation, the harness and everything. And you want to improve the product over time\\nincrementally and you're making revenue along the way. That's extremely important because otherwise\\nyou cannot build these large undertakings just like don't make sense economically.\\nAnd also from the point of view of the team working on it, they need the dopamine along the way.\\nThey're not just going to make a promise about this being useful. This is going to change the\\nworld in 10 years when it works. This is not where you want to be. You want to be in a place\\nlike I think Autopilot is today where it's offering increased safety and convenience of driving today.\\nPeople pay for it. People like it. People will purchase it. And then you also have the greater\\nmission that you're working towards. And you see that. So the dopamine for the team,\\nthat was a source of happiness and satisfaction. Yes, 100%. You're deploying this. People like it.\\nPeople drive it. People pay for it. They care about it. There's all these YouTube videos.\\nYour grandma drives it. She gives you feedback. People like it. People engage with it. You engage\\nwith it. Huge. Do people that drive Teslas recognize you and give you love? Like, hey, thanks for this\\nnice feature that it's doing. Yeah, I think the tricky thing is like some people really love you.\\nSome people, unfortunately, like you're working on something that you think is extremely valuable,\\nuseful, etc. Some people do hate you. There's a lot of people who like me and the team and\\nthe whole project. And I think Tesla drivers, many cases they're not actually. Yeah, that's\\nactually makes me sad about humans or the current ways that humans interact. I think that's actually\\nfixable. I think humans want to be good to each other. I think Twitter and social media is part\\nof the mechanism that actually somehow makes the negativity more viral, that it doesn't deserve\\ndisproportionately add a viral boost to the negativity. But I wish people would just get\\nexcited about, so suppress some of the jealousy, some of the ego and just get excited for others.\\nAnd then there's a karma aspect to that. You get excited for others, they'll get excited for you.\\nSame thing in academia. If you're not careful, there is a dynamical system there.\\nIf you think of in silos and get jealous of somebody else being successful, that actually,\\nperhaps counterintuitively, leads to less productivity of you as a community and you\\nindividually. I feel like if you keep celebrating others, that actually makes you more successful.\\nYeah. I think people haven't, depending on the industry, haven't quite learned that yet.\\nSome people are also very negative and very vocal. They're very prominently featured,\\nbut actually there's a ton of people who are cheerleaders, but they're silent cheerleaders.\\nAnd when you talk to people just in the world, they will tell you, it's amazing, it's great.\\nEspecially people who understand how difficult it is to get this stuff working. People who have\\nbuilt products and makers, entrepreneurs, making this work and changing something\\nis incredibly hard. Those people are more likely to cheerlead you.\\nWell, one of the things that makes me sad is some folks in the robotics community\\ndon't do the cheerleading and they should because they know how difficult it is. Well,\\nthey actually sometimes don't know how difficult it is to create a product that's scale. They\\nactually deploy it in the real world. A lot of the development of robots and AI system is done on\\nvery specific small benchmarks as opposed to real world conditions.\\nYes. Yeah. I think it's really hard to work on robotics in an academic setting.\\nOr AI systems that apply in the real world. You've criticized, you flourished and loved for time the\\nImageNet, the famed ImageNet data set. And I've recently had some words of criticism that the\\nacademic research ML community gives a little too much love still to the ImageNet or like\\nthose kinds of benchmarks. Can you speak to the strengths and weaknesses of data sets\\nused in machine learning research? Actually, I don't know that I recall\\na specific instance where I was unhappy or criticizing ImageNet. I think ImageNet has\\nbeen extremely valuable. It was basically a benchmark that allowed the deep learning community\\nto demonstrate that deep neural networks actually work. There's a massive value in that.\\nI think ImageNet was useful, but basically it's become a bit of an MNIST at this point.\\nMNIST is like little 228 by 28 grayscale digits. There's a joke data set that everyone just crushes.\\nThere's still papers written on MNIST though, right?\\nMaybe they shouldn't.\\nStrong papers. Like papers that focus on how do we learn with a small amount of data, that kind of\\nstuff. Yeah. I could see that being helpful, but not in mainline computer vision research anymore,\\nof course. I think the way I've heard you somewhere, maybe I'm just imagining things,\\nbut I think you said ImageNet was a huge contribution to the community for a long time,\\nand now it's time to move past those kinds of... Well, ImageNet has been crushed. I'm\\nthe error rates are... Yeah, we're getting like 90% accuracy in 1000 classification way prediction,\\nand I've seen those images and it's like really high. That's really good. If I remember correctly,\\nthe top five error rate is now like 1% or something.\\nGiven your experience with a gigantic real world data set, would you like to see benchmarks move\\nin a certain directions that the research community uses?\\nUnfortunately, I don't think academics currently have the next ImageNet.\\nI think we've crushed MNIST. We've basically crushed ImageNet, and there's no next big\\nbenchmark that the entire community rallies behind and uses for further development of these\\nnetworks. Yeah. What are what it takes for a data set to captivate the imagination of everybody,\\nwhere they all get behind it? That could also need a leader, right? Yeah. Somebody with popularity.\\nYeah. Why did ImageNet take off? Or is it just the accident of history?\\nIt was the right amount of difficult. It was the right amount of difficult and simple,\\nand interesting enough, it just kind of like it was the right time for that kind of a data set.\\nQuestion from Reddit. What are your thoughts on the role that synthetic data and game engines\\nwill play in the future of neural net model development? I think as neural nets converge\\nto humans, the value of simulation to neural nets will be similar to the value of simulation to\\nhumans. So people use simulation because they can learn something in that kind of a system\\nwithout having to actually experience it. But are you referring to the simulation we do in our head?\\nNo, sorry, simulation. I mean like video games or other forms of simulation for various professionals.\\nSo let me push back on that because maybe there's simulation that we do in our heads.\\nLike, simulate if I do this, what do I think will happen?\\nOkay. That's like internal simulation. Yeah. Internal. Isn't that what we're doing?\\nAssuming before we act? Oh yeah. But that's independent from like the use of simulation in\\nthe sense of like computer games or using simulation for training set creation or-\\nIs it independent or is it just loosely correlated? Because like, isn't that useful to do like\\ncounterfactual or like edge case simulation to like, you know, what happens if there's a nuclear war?\\nWhat happens if there's, you know, like those kinds of things?\\nYeah, that's a different simulation from like Unreal Engine. That's how I interpreted the question.\\nAh, so like simulation of the average case. What's Unreal Engine?\\nWhat do you mean by Unreal Engine? So simulating a world, physics of that world,\\nwhy is that different? Like, because you also can add behavior to that world\\nand you could try all kinds of stuff, right? You could throw all kinds of weird things into it.\\nUnreal Engine is not just about simulating, I mean, I guess it is about simulating the physics\\nof the world. It's also doing something with that. Yeah. The graphics, the physics, and the\\nagents that you put into the environment and stuff like that. Yeah. See, I think you,\\nI feel like you said that it's not that important, I guess, for the future of AI development.\\nIs that correct to interpret it that way? I think humans use simulators for,\\nhumans use simulators and they find them useful. And so computers will use simulators and find them\\nuseful. Okay. So you're saying it's not that, I don't use simulators very often. I play a video\\ngame every once in a while, but I don't think I derive any wisdom about my own existence from\\nthose video games. It's a momentary escape from reality versus a source of wisdom about reality.\\nSo I think that's a very polite way of saying simulation is not that useful.\\nYeah, maybe not. I don't see it as like a fundamental, really important part of like\\ntraining neural nets currently. But I think as neural nets become more and more powerful,\\nI think you will need fewer examples to train additional behaviors. And simulation is, of course,\\nthere's a domain gap in a simulation that it's not the real world, it's slightly something different.\\nBut with a powerful enough neural net, you need, the domain gap can be bigger, I think,\\nbecause neural net will sort of understand that even though it's not the real world, it like has\\nall this high level structure that I'm supposed to be learning from. So the neural net will actually,\\nyeah, it will be able to leverage the synthetic data better by closing the gap,\\nby understanding in which ways this is not real data.\\nExactly.\\nRight, I do better questions next time. That was a question, but I'm just kidding. All right.\\nSo is it possible, do you think, speaking of MNIST, to construct neural nets and training\\nprocesses that require very little data? So we've been talking about huge data sets like\\nthe internet for training. I mean, one way to say that is, like you said, like the querying itself\\nis another level of training, I guess, and that requires a little data. But do you see any value\\nin doing research and kind of going down the direction of can we use very little data to train,\\nto construct a knowledge base?\\n100%. I just think like at some point you need a massive data set. And then when you pre-train\\nyour massive neural net and get something that is like a GPT or something, then you're able to be\\nvery efficient at training any arbitrary new task. So a lot of these GPTs, you can do tasks like\\nsentiment analysis or translation or so on just by being prompted with very few examples. Here's the\\nkind of thing I want you to do. Here's an input sentence, here's the translation into German.\\nInput sentence, translation to German. Input sentence blank, and the neural net will complete\\nthe translation to German just by looking at sort of the example you've provided. And so that's an\\nexample of a very few shot learning in the activations of the neural net instead of the\\nweights of the neural net. And so I think basically just like humans, neural nets will become very\\ndata efficient at learning any other new task. But at some point you need a massive data set to\\npre-train your network. To get that, and probably we humans have something like that.\\nDo we have something like that? Do we have a passive in the background model constructing\\nthing that just runs all the time in a self-supervised way? We're not conscious of it.\\nI think humans definitely, I mean, obviously we learn a lot during our lifespan, but also we have\\na ton of hardware that helps us at initialization coming from sort of evolution. And so I think\\nthat's also a really big component. A lot of people in the field, I think they just talk about\\nthe amounts of like seconds and the, you know, that a person has lived pretending that this is\\na WLRRSA, sort of like a zero initialization of a neural net. And it's not like you can look at a\\nlot of animals, like for example, zebras, zebras get born and they see and they can run. There's\\nzero train data in their lifespan. They can just do that. So somehow I have no idea how evolution\\nhas found a way to encode these algorithms and these neural net initializations that are extremely\\ngood into ATCGs. And I have no idea how this works, but apparently it's possible because\\nhere's a proof by existence. There's something magical about going from a single cell to an\\norganism that is born to the first few years of life. I kind of like the idea that the reason we\\ndon't remember anything about the first few years of our life is that it's a really painful process.\\nLike it's a very difficult, challenging training process. Like intellectually, like\\nand maybe, yeah, I mean, I don't, why don't we remember any of that? There might be some crazy\\ntraining going on and that maybe that's the background model training that is very painful.\\nAnd so it's best for the system once it's trained not to remember how it's constructed.\\nI think it's just like the hardware for long-term memory is just not fully developed.\\nI kind of feel like the first few years of infants is not actually like learning,\\nit's brain maturing. We're born premature. There's a theory along those lines because of the\\nbirth canal and the swallowing of the brain. And so we're born premature and then the first few\\nyears we're just, the brain is maturing and then there's some learning eventually.\\nThat's my current view on it. What do you think, do you think neural nets can have long-term memory?\\nLike that approach is something like humans. Do you think they need to be another meta\\narchitecture on top of it to add something like a knowledge base that learns facts about the world\\nand all that kind of stuff? Yes, but I don't know to what extent it will be explicitly constructed.\\nIt might take unintuitive forms where you are telling the GPT like, hey, you have a declarative\\nmemory bank to which you can store and retrieve data from. And whenever you encounter some\\ninformation that you find useful, just save it to your memory bank. And here's an example of\\nsomething you have retrieved and how you say it and here's how you load from it. You just say load,\\nwhatever, you teach it in text, in English, and then it might learn to use a memory bank from that.\\nOh, so the neural net is the architecture for the background model, the base thing,\\nand then everything else is just on top of it. That's pretty easy to do.\\nIt's not just text, right? You're giving it gadgets and gizmos. So you're teaching some kind\\nof a special language by which it can save arbitrary information and retrieve it at a later\\ntime. And you're telling it about these special tokens and how to arrange them to use these\\ninterfaces. It's like, hey, you can use a calculator. Here's how you use it. Just do\\n53 plus 41 equals. And when equals is there, a calculator will actually read out the answer\\nand you don't have to calculate it yourself. And you just tell it in English, this might actually\\nwork. Do you think in that sense, Godot is interesting, the DeepMind system, that it's not\\njust new language, but actually throws it all in the same pile, images, actions, all that kind\\nof stuff. That's basically what we're moving towards. Yeah, I think so. So Godot is very much a\\nkitchen sink approach to reinforcement learning in lots of different environments with a single\\nfixed transformer model, right? I think it's a very early result in that realm, but I think,\\nyeah, it's along the lines of what I think things will eventually look like.\\nSo this is the early days of a system that eventually will look like this from a\\nrich, sudden perspective. Yeah, I'm not super huge fan of, I think, all these interfaces that\\nlook very different. I would want everything to be normalized into the same API. So for example,\\nscreen pixels, very same API, instead of having different world environments that have very\\ndifferent physics and joint configurations and appearances and whatever, and you're having some\\nkind of special tokens for different games that you can plug. I'd rather just normalize everything\\nto a single interface so it looks the same to the neural net, if that makes sense. So it's all\\ngoing to be pixel-based pong in the end. I think so. Okay. Let me ask you about your own personal\\nlife. A lot of people want to know you're one of the most productive and brilliant people\\nin the history of AI. What is a productive day in the life of Andrej Kapati look like?\\nWhat time do you wake up? Because imagine some kind of dance between the average productive day\\nand a perfect productive day. So the perfect productive day is the thing we strive towards,\\nand the average is what it converges to, given all the mistakes and human eventualities and so on.\\nSo what time do you wake up? Are you a morning person? I'm not a morning person. I'm a night\\nowl for sure. Is it stable or not? It's semi-stable, like eight or nine or something like that.\\nDuring my PhD, it was even later, I used to go to sleep usually at 3 a.m. I think the a.m. hours\\nare precious and very interesting time to work because everyone is asleep.\\nAt 8 a.m. or 7 a.m., the East Coast is awake. So there's already activity, there's already some\\ntext messages, whatever, there's stuff happening. You can go on some news website and there's stuff\\nhappening. It's distracting. At 3 a.m., everything is totally quiet. And so you're not going to be\\nbothered and you have solid chunks of time to do work. So I like those periods, night owl by\\ndefault. And then I think like productive time, basically, what I like to do is you need to build\\nsome momentum on the problem without too much distraction. And you need to load your RAM,\\nyour working memory with that problem. And then you need to be obsessed with it when you're taking\\nshower, when you're falling asleep. You need to be obsessed with the problem and it's fully in\\nyour memory and you're ready to wake up and work on it right there. So is this in a scale, temporal\\nscale of a single day or a couple of days, a week, a month? So I can't talk about one day,\\nbasically, in isolation because it's a whole process. When I want to get productive in the\\nproblem, I feel like I need a span of a few days where I can really get in on that problem. And I\\ndon't want to be interrupted. And I'm going to just be completely obsessed with that problem.\\nAnd that's where I do most of my good workouts. You've done a bunch of cool, like little projects\\nin a very short amount of time very quickly. So that requires you just focusing on it.\\nYeah, basically, I need to load my working memory with the problem. And I need to be productive\\nbecause there's always a huge fixed cost to approaching any problem. I was struggling with\\nthis, for example, at Tesla because I want to work on small side project. But okay, you first need to\\nfigure out, okay, I need to SSH into my cluster. I need to bring up a VS code editor so I can work\\non this. I run into some stupid error because of some reason. You're not at a point where you can\\nbe just productive right away. You are facing barriers. And so it's about really removing all\\nof that barrier and you're able to go into the problem and you have the full problem loaded in\\nyour memory. And somehow avoiding distractions of all different forms, like news stories, emails,\\nbut also distractions from other interesting projects that you previously worked on or\\ncurrently working on and so on. You just want to really focus your mind. And I mean, I can take\\nsome time off for distractions and in between, but I think it can't be too much. Most of your day is\\nsort of spent on that problem. And then I drink coffee, I have my morning routine, I look at some\\nnews, Twitter, Hacker News, Wall Street Journal, et cetera. It's great. So basically, you wake up,\\nyou have some coffee. Are you trying to get to work as quickly as possible? Are you taking this diet\\nof what the hell is happening in the world first? I do find it interesting to know about the world.\\nI don't know that it's useful or good, but it is part of my routine right now. So I do read through\\na bunch of news articles and I want to be informed. And I'm suspicious of it. I'm suspicious of the\\npractice, but currently that's where I am. Oh, you mean suspicious about the positive effect\\nof that practice on your productivity and your wellbeing? My wellbeing psychologically, yeah.\\nAnd also on your ability to deeply understand the world because there's a bunch of sources of\\ninformation. You're not really focused on deeply integrating. Yeah, it's a little distracting.\\nIn terms of a perfectly productive day, for how long of a stretch of time in one session do you\\ntry to work and focus on a thing? A couple of hours, is it one hour, is it 30 minutes, is it\\n10 minutes? I can probably go a small few hours and then I need some breaks in between for food\\nand stuff. Yeah, but I think it's still really hard to accumulate hours. I was using a tracker\\nthat told me exactly how much time I spent coding any one day. And even on a very productive day,\\nI still spent only like six or eight hours. And it's just because there's so much padding,\\ncommute, talking to people, food, et cetera. There's like the cost of life, just living\\nand sustaining and homeostasis and just maintaining yourself as a human is very high.\\nAnd there seems to be a desire within the human mind to participate in society that creates that\\npadding. Because the most productive days I've ever had is just completely from start to finish\\nis tuning out everything and just sitting there. And then you could do more than six and eight\\nhours. Is there some wisdom about what gives you strength to do tough days of long focus?\\nYeah, just like whenever I get obsessed about a problem, something just needs to work,\\nsomething just needs to exist. It needs to exist. So you're able to deal with bugs and programming\\nissues and technical issues and design decisions that turn out to be the wrong ones. You're able\\nto think through all of that given that you want to think to exist. Yeah, it needs to exist. And\\nthen I think to me also a big factor is are other humans are going to appreciate it? Are they going\\nto like it? That's a big part of my motivation. If I'm helping humans and they seem happy,\\nthey say nice things, they tweet about it or whatever, that gives me pleasure because I'm\\ndoing something useful. So you do see yourself sharing it with the world. Whether it's on GitHub\\nor through a blog post or through videos. Yeah, I was thinking about it. Suppose I did all these\\nthings but did not share them. I don't think I would have the same amount of motivation that\\nI can build up. You enjoy the feeling of other people gaining value and happiness from the stuff\\nyou've created. Yeah. What about diet? I saw you played with intermittent fasting. Do you fast?\\nDoes that help? I played with everything.\\nWith the things you played, what's been most beneficial to your ability to mentally focus\\non a thing and just mental productivity and happiness? You still fast? Yeah, I still fast,\\nbut I do intermittent fasting. But really what it means at the end of the day is I skip breakfast.\\nSo I do 18, 6 roughly by default when I'm in my steady state. If I'm traveling or doing something\\nelse, I will break the rules. But in my steady state, I do 18, 6. So I eat only from 12 to 6.\\nNot a hard rule and I break it often, but that's my default. And then yeah, I've done a bunch of\\nrandom experiments. For the most part right now, where I've been for the last year and a half,\\nI want to say, is I'm plant-based or plant-forward. I heard plant-forward. It sounds better.\\nWhat does that mean exactly? I don't actually know what the difference is,\\nbut it sounds better in my mind. But it just means I prefer plant-based food.\\nRaw or cooked? I prefer cooked and plant-based.\\nSo plant-based, forgive me, I don't actually know how wide the category of plant entails.\\nWell, plant-based just means that you're not militant about it and you can flex.\\nYou just prefer to eat plants and you're not trying to influence other people.\\nAnd if you come to someone's house party and they serve you a steak that they're really proud of,\\nyou will eat it. That's beautiful. I'm on the flip side of that, but I'm very sort of flexible.\\nHave you tried doing one meal a day? I have accidentally, not consistently,\\nbut I've accidentally had that. I don't like it. I think it makes me feel not good. It's too much,\\ntoo much of a hit. Yeah.\\nAnd so currently I have about two meals a day, 12 and six.\\nI do that nonstop. I'm doing it now. I do one meal a day.\\nIt's interesting. It's an interesting feeling. Have you ever fasted longer than a day?\\nYeah, I've done a bunch of water fasts because I was curious what happens.\\nAnything interesting? Yeah, I would say so. I mean,\\nwhat's interesting is that you're hungry for two days and then starting day three or so,\\nyou're not hungry. It's such a weird feeling because you haven't eaten in a few days and\\nyou're not hungry. Isn't that weird?\\nIt's really weird. One of the many weird things about human biology,\\nis figure something out. It finds another source of energy or something like that,\\nor relaxes the system. I don't know how that works.\\nThe body is like, you're hungry, you're hungry. And then it just gives up. It's like,\\nokay, I guess we're fasting now. There's nothing. And then it just focuses on trying to make you\\nnot hungry and not feel the damage of that and trying to give you some space to figure out the\\nfood situation. Are you still to this day most productive at night?\\nI would say I am, but it is really hard to maintain my PhD schedule,\\nespecially when I was working at Tesla and so on. It's a non-starter.\\nBut even now, people want to meet for various events. Society lives in a certain period of time\\nand you sort of have to work with that.\\nIt's hard to do a social thing and then after that return and do work.\\nYeah. It's just really hard.\\nThat's why I try when I do social things, I try not to do too much drinking so I can return\\nand continue doing work. But at Tesla, is there a convergence, Tesla, but any company,\\nis there a convergence towards a schedule? Or is there more? Is that how humans behave\\nwhen they collaborate? I need to learn about this. Do they try to keep a consistent schedule\\nwhere you're all awake at the same time? I do try to create a routine and I try to\\ncreate a steady state in which I'm comfortable in. I have a morning routine, I have a day routine,\\nI try to keep things to a steady state and things are predictable. And then your body just\\nsticks to that. And if you try to stress that a little too much, it will create,\\nwhen you're traveling and you're dealing with jet lag, you're not able to really ascend\\nto where you need to go. Yeah. That's what you're doing with humans with the habits and stuff.\\nWhat are your thoughts on work-life balance throughout a human lifetime?\\nSo Tesla in part was known for pushing people to their limits in terms of what they're able to do,\\nin terms of what they're trying to do, in terms of how much they work, all that kind of stuff.\\nYeah. I will say Tesla gets a little too much bad rep for this because what's happening is Tesla,\\nit's a bursty environment. So I would say the baseline, my only point of reference is Google,\\nwhere I've interned three times and I saw what it's like inside Google and DeepMind. I would\\nsay the baseline is higher than that, but then there's a punctuated equilibrium where once in\\na while there's a fire and people work really hard. And so it's spiky and bursty and then all\\nthe stories get collected. About the bursts. And then it gives the appearance of total insanity,\\nbut actually it's just a bit more intense environment and there are fires and sprints.\\nAnd so I think definitely though I would say it's a more intense environment than something\\nyou would get. But in your personal, forget all of that, just in your own personal life,\\nwhat do you think about the happiness of a human being? A brilliant person like yourself,\\nabout finding a balance between work and life or is it such a thing, not a good thought experiment?\\nYeah, I think balance is good, but I also love to have sprints that are out of distribution.\\nAnd that's when I think I've been pretty creative as well. Sprints out of distribution means that\\nmost of the time you have a quote unquote balance. I have balance most of the time.\\nI like being obsessed with something once in a while. Once in a while is what? Once a week,\\nonce a month, once a year? Yeah, probably like say once a month or something. Yeah.\\nAnd that's when we get a new GitHub repo for monitoring. Yeah, that's when you really care\\nabout a problem. It must exist. This will be awesome. You're obsessed with it. And now you\\ncan't just do it on that day. You need to pay the fixed cost of getting into the groove. And then\\nyou need to stay there for a while and then society will come and they will try to mess with you and\\nthey will try to distract you. Yeah. The worst thing is a person who's like, I just need five\\nminutes of your time. Yeah. The cost of that is not five minutes and society needs to change how\\nit thinks about it. Just five minutes of your time. Right. It's never just one minute. Just\\n30 seconds. Just a quick thing. What's the big deal? Why are you being so... Yeah, no.\\nWhat's your computer setup? What's like the perfect... Are you somebody that's flexible\\nto no matter what? Laptop, four screens. Yeah. Or do you prefer a certain setup that you're most\\nproductive? I guess the one that I'm familiar with is one large screen, 27 inch, and my laptop\\non the side. What operating system? I do Macs. That's my primary. For all tasks? I would say\\nOS X, but when you're working on deep learning, everything is Linux. You're SSH'd into a cluster\\nand you're working remotely. But what about the actual development? Like they're using the IDE?\\nI think a good way is you just run VS code, my favorite editor right now, on your Mac,\\nbut you have a remote folder through SSH. The actual files that you're manipulating\\nare on the cluster somewhere else. What's the best IDE? VS code. What else do people... I use\\nEmacs still. That's cool. It may be cool. I don't know if it's maximum productivity.\\nWhat do you recommend in terms of editors? You worked a lot of software engineers. Editors for\\nPython, C++, machine learning applications. I think the current answer is VS code. Currently,\\nI believe that's the best IDE. It's got a huge amount of extensions. It has GitHub Copilot\\nintegration, which I think is very valuable. What do you think about the Copilot integration? I\\nwas actually... I got to talk a bunch with Guido Narrazzon, who's a creative Python, and he loves\\nCopilot. He programs a lot with it. Do you? Yeah, I use Copilot. I love it. It's free for me,\\nbut I would pay for it. Yeah, I think it's very good. The utility that I found with it was...\\nI would say there's a learning curve, and you need to figure out when it's helpful and when to pay\\nattention to its outputs and when it's not going to be helpful, where you should not pay attention\\nto it. Because if you're just reading at suggestions all the time, it's not a good way of interacting\\nwith it. But I think I was able to mold myself to it. I find it's very helpful, number one,\\ncopy, paste, and replace some parts. When the pattern is clear, it's really good at completing\\nthe pattern. And number two, sometimes it suggests APIs that I'm not aware of. It tells you about\\nsomething that you didn't know. And that's an opportunity to discover and use it again.\\nIt's an opportunity to... I would never take Copilot code as given. I almost always copy\\na copy paste into a Google search, and you see what this function is doing. And then you're like,\\noh, it's actually exactly what I need. Thank you, Copilot. So you learn something. It's in part a\\nsearch engine, part maybe getting the exact syntax correctly that once you see it, it's that NP\\nhard thing. Once you see it, you know it's correct, but you yourself struggle. You can verify\\nefficiently, but you can't generate efficiently. And Copilot really, I mean, it's autopilot for\\nprogramming, right? And currently it's doing the link following, which is like the simple copy,\\npaste, and sometimes suggest. But over time, it's going to become more and more autonomous.\\nAnd so the same thing will play out in not just coding, but actually across many,\\nmany different things probably. Coding is an important one, right? Like writing programs.\\nHow do you see the future of that developing? The program synthesis, like being able to write\\nprograms that are more and more complicated. Because right now it's human supervised in\\ninteresting ways. It feels like the transition will be very painful.\\nMy mental model for it is the same thing will happen as with the autopilot. So currently\\nit's doing link following, it's doing some simple stuff. And eventually we'll be doing autonomy and\\npeople will have to intervene less and less. And there could be like testing mechanisms.\\nLike if it writes a function and that function looks pretty damn correct, but how do you know\\nit's correct? Because you're getting lazier and lazier as a programmer. Like your ability to,\\nbecause like little bugs, but I guess it won't make little mistakes.\\nNo, it will. Copilot will make off by one subtle bugs. It has done that to me.\\nBut do you think future systems will? Or is it really the off by one is actually a fundamental\\nchallenge of programming? In that case, it wasn't fundamental. And I think things can improve, but\\nyeah, I think humans have to supervise. I am nervous about people not supervising what comes out\\nand what happens to, for example, the proliferation of bugs in all of our systems.\\nI'm nervous about that, but I think there will probably be some other copilots for bug finding\\nand stuff like that at some point. Cause there'll be like a lot more automation for.\\nIt's like a program, a copilot that generates a compiler, one that does a linter, one that does\\nlike a type checker. It's a committee of like a GPT sort of like. And then there'll be like a manager\\nfor the committee. And then there'll be somebody that says a new version of this is needed. We need\\nto regenerate it. Yeah. There were 10 GPTs. They were forwarded and gave 50 suggestions. Another\\none looked at it and picked a few that they like. A bug one looked at it and it was like, it's\\nprobably a bug. They got re-ranked by some other thing. And then a final ensemble GPT comes in.\\nIt's like, okay, given everything you guys have told me, this is probably the next token.\\nThe feeling is the number of programmers in the world has been growing and growing very quickly.\\nDo you think it's possible that it'll actually level out and drop to like a very low number\\nwith this kind of world? Cause then you'll be doing software 2.0 programming.\\nAnd you'll be doing this kind of generation of copilot type systems programming,\\nbut you won't be doing the old school software 1.0 program.\\nI don't currently think that they're just going to replace human programmers.\\nI'm so hesitant saying stuff like this, right?\\nThis is going to be replaced in five years. I don't know. It's going to show that this is where\\nwe thought. Cause I agree with you, but I think we might be very surprised. What's your sense of\\nwhere we stand with language models? Does it feel like the beginning or the middle or the end?\\nThe beginning, a hundred percent. I think the big question in my mind is for sure GPT will be able\\nto program quite well, competently and so on. How do you steer the system? You still have to provide\\nsome guidance to what you actually are looking for. And so how do you steer it? And how do you\\ntalk to it? How do you audit it and verify that what is done is correct? And how do you work with\\nthis? And it's as much not just an AI problem, but a UI UX problem. So beautiful fertile ground for\\nso much interesting work for VS code plus plus where it's not just human programming anymore.\\nIt's amazing. Yeah. So you're interacting with the system. So not just one prompt,\\nbut it's iterative prompting. You're trying to figure out having a conversation with the system.\\nYeah. That actually, I mean, to me, that's super exciting to have a conversation with the program\\nI'm writing. Yeah. Maybe at some point you're just conversing with it. It's like, okay, here's what I\\nwant to do. Actually this variable, maybe it's not even that low level as variable, but. You can also\\nimagine like, can you translate this to C plus plus and back to Python? Yeah, that already kind of\\nexists in some. No, but just like doing it as part of the program experience. Like I think I'd like\\nto write this function in C plus plus or like you just keep changing for different, uh, different\\nprograms because of different six, six syntax. Maybe I want to convert this into a functional\\nlanguage. And so like you get to become multilingual as a programmer and dance back and forth\\nefficiently. Yeah. I mean, I think the UI UX of it though is like still very hard to think through\\nbecause it's not just about writing code on a page. You have an entire developer environment.\\nYou have a bunch of hardware on it. Uh, you have some environmental variables. You have some scripts\\nthat are running in a Chrome job. Like there's a lot going on to like working with computers and how\\ndo these systems set up environment flags and work across multiple machines and set up screen\\nsessions and automate different processes. Like how all that works and is auditable by humans and\\nso on is like massive question. No, my man. You've built archive sanity. What is archive\\nand what is the future of academic research publishing that you would like to see?\\nUh, so archive is this pre print server. So if you have a paper, uh, you can submit it for\\npublication to journals or conferences and then wait six months and then maybe get a decision,\\npass or fail, or you can just upload it to archive and then people can tweet about it three minutes\\nlater and then everyone sees it, everyone reads it and everyone can profit from it, uh, in their own\\nway. So you can cite it and it has an official look to it. It feels like a pub, like it feels\\nlike a publication process. It feels different than you if you just put it in a blog post.\\nOh yeah. Yeah. I mean, it's a paper and usually the bar is higher for something that you would\\nexpect on archive as opposed to something you would see in a blog post. Well, the culture\\ncreated the bar because you could probably post a pretty crappy picture on the archive.\\nYes. Um, so what, what's that make you feel like? What's that make you feel about peer review?\\nSo rigorous peer review by two, three experts versus the peer review of the community\\nright as it's written. Yeah. Basically I think the community is very well able to peer review\\nthings very quickly on Twitter. And I think maybe it just has to do something with AI machine\\nlearning fields specifically though. I feel like things are more easily auditable. Um, and the\\nverification is easier potentially than the verification somewhere else. So it's kind of\\nlike, um, you can think of these, uh, scientific publications as like little blockchains where\\neveryone's building on each other's work and setting each other. And you sort of have AI,\\nwhich is kind of like this much faster and loose blockchain, but then you have any one individual\\nentry is like very, um, very cheap to make. And then you have other fields where maybe that\\nmodel doesn't make as much sense. Um, and so I think in AI, at least things are pretty easily\\nvery viable. And so that's why when people upload papers, they're a really good idea and so on,\\npeople can try it out like the next day and they can be the final arbiter of whether it works or\\nnot on their problem. And the whole thing just moves significantly faster. So I kind of feel like\\nacademia still has a place. Sorry, this like conference journal process still has a place,\\nbut it's sort of like, um, it lags behind, I think. And it's a bit more, um, maybe higher quality\\nprocess. Uh, but it's not sort of the place where you will discover cutting edge work anymore.\\nYeah. It used to be the case when I was starting my PhD, that you go to conferences and journals\\nand you discuss all the latest research. Now, when you go to a conference or general, like no\\none discusses anything that's there because it's already like three generations ago irrelevant.\\nYeah. Which makes me sad about like DeepMind, for example, where they, they still, they still\\npublish in nature and these big prestigious, I mean, there's still value, I suppose to the prestige\\nthat comes with these big venues, but the result is that they, they'll announce some breakthrough\\nperformance and it will take like a year to actually publish the details. I mean,\\nand those details in, if they were published immediately, it would inspire the community\\nto move in certain directions. Yeah, it would speed up the rest of the community,\\nbut I don't know to what extent that's part of their objective function also.\\nThat's true. So it's not just the prestige, a little bit of the delay is, uh, as part of.\\nYeah, they certainly, uh, DeepMind specifically has been, um, working in the regime of having\\na slightly higher quality, basically process and latency and, uh, publishing those papers that way.\\nAnother question from Reddit. Do you, or have you suffered from imposter syndrome? Being the director\\nof AI Tesla, uh, being this person when you're at Stanford, where like the world looks at you\\nas the expert in AI to teach, teach the world about machine learning. When I was leaving\\nTesla after five years, I spent a ton of time in meeting rooms. Uh, and you know, I would read\\npapers in the beginning when I joined Tesla, I was writing code and then I was writing less\\nand less code and I was reading code and then I was reading less and less code. And so this is just\\na natural progression that happens, I think. And, uh, definitely I would say near the tail end.\\nThat's when it sort of like starts to hit you a bit more that you're supposed to be an expert,\\nbut actually the source of truth is the code that people are writing, the GitHub and the actual,\\nthe actual code itself. Uh, and you're not as familiar with that as you used to be.\\nAnd so I would say maybe there's some like insecurity there.\\nYeah, that's actually pretty profound that a lot of the insecurity has to do with not writing the\\ncode in the computer science space like that, cause that is the truth that, that right there.\\nThe code is the source of truth, the papers and everything else. It's a high level summary.\\nI don't, uh, yeah, just a high level summary, but at the end of the day, you have to read code.\\nIt's impossible to translate all that code into actual, uh, you know, uh, paper form. Uh, so when,\\nwhen things come out, especially when they have a source code available, that's my favorite place\\nto go. So like I said, you're one of the greatest teachers of machine learning AI ever, uh, from CS\\n231N to today. What advice would you give to beginners interested in getting into machine\\nlearning? Beginners are often focused on like what to do. And I think the focus should be more like\\nhow much you do. So I am kind of like believer on a high level in this 10,000 hours kind of concept\\nwhere you just kind of have to just pick the things where you can spend time and you care about and\\nyou're interested in. You literally have to put in 10,000 hours of work. Um, it doesn't even like\\nmatter as much like where you put it and you're, you'll iterate and you'll improve and you'll\\nwaste some time. I don't know if there's a better way you need to put in 10,000 hours, but I think\\nit's actually really nice because I feel like there's some sense of determinism about, uh,\\nbeing an expert at a thing. If you spend 10,000 hours, you can literally pick an arbitrary thing.\\nAnd I think if you spend 10,000 hours of deliberate effort and work, you actually will become an\\nexpert at it. And so I think it's kind of like a nice thought. Um, and so, uh, basically I would\\nfocus more on like, are you spending 10,000 hours? That's what I'm focused on. So, and then thinking\\nabout what kind of mechanisms maximize your likelihood of getting to 10,000 hours, which\\nfor us silly humans means probably forming a daily habit of like every single day,\\nactually doing the thing, whatever helps you. So I do think to a large extent is a psychological\\nproblem for yourself. Uh, one other thing that I help that I think is helpful for the psychology\\nof it is many times people compare themselves to others in the area. I think this is very harmful\\nonly compare yourself to you from some time ago, like say a year ago, are you better than you\\nyear ago? This is the only way to think. Um, and I think this, then you can see your progress and\\nit's very motivating. That's so interesting that focus on the quantity of hours. Cause I think a\\nlot of people, uh, in the beginner stage, but actually throughout get paralyzed, uh, by, uh,\\nthe choice, like which one do I pick this path or this path? Like they'll literally get paralyzed,\\nbut like which ID to use. Well, they're worried. Yeah. They'll worried about all these things,\\nbut the thing is some of the, you will waste time doing something wrong. You will eventually\\nfigure out it's not right. You will accumulate scar tissue and next time you'll grow stronger\\nbecause next time you'll have the scar tissue and next time you'll learn from it. And now next time\\ncome to a similar situation, you'll be like, Oh, I, I messed up. I've spent a lot of time working\\non things that never materialized into anything. And I have all that scar tissue and I have some\\nintuitions about what was useful, what wasn't useful, how things turned out. Uh, so all those\\nmistakes were, uh, were not dead work, you know? So I just think you should, did you just focus on\\nworking? What have you done? What have you done last week? Uh, that's a good question actually to\\nask for, for a lot of things, not just machine learning. Um, it's a good way to cut the,\\nthe, I forgot what the term we use, but the fluff, the blubber, whatever the,\\nuh, the inefficiencies in life. Uh, what do you love about teaching? You seem to find yourself\\noften in the, like draw onto teaching. You're very good at it, but you're also drawn to it.\\nI mean, I don't think I love teaching. I love happy humans and happy humans like when I teach.\\nI wouldn't say I hate teaching. I tolerate teaching, but it's not like the act of teaching\\nthat I like. It's, it's that, um, you know, I, I have some, I have something I'm actually okay at\\nit. I'm okay at teaching and people appreciate it a lot. And, uh, so I'm just happy to try to be\\nhelpful and, uh, teaching itself is not like the most, I mean, it's really annoying. It can be\\nreally annoying, frustrating. I was working on a bunch of lectures just now. I was reminded back to\\nmy days of 231 and just how much work it is to create some of these materials and make them good.\\nThe amount of iteration and thought, and you go down blind alleys and just how much you change it.\\nSo creating something good, um, in terms of like educational value is really hard and, uh, it's not\\nfun. It was difficult. So for people to definitely go watch your new stuff, you put out, there are\\nlectures where you're actually building the thing like from, like you said, the code is truth. So\\ndiscussing, uh, backpropagation by building it, by looking through it and just the whole thing.\\nSo how difficult is that to prepare for? I think that's a really powerful way to teach.\\nDid you have to prepare for that or are you just live thinking through it?\\nI will typically do like say three takes and then I take like the better take. Uh, so I do multiple\\ntakes and I take some of the better takes and then I just build out a lecture that way. Uh,\\nsometimes I have to delete 30 minutes of content because it just went down the alley that I didn't\\nlike too much. There's a bunch of iteration and it probably takes me, you know, somewhere around\\n10 hours to create one hour of content. To get one hour. It's interesting. I mean, uh,\\nis it difficult to go back to the basics? Do you draw a lot of like wisdom from going back to the\\nbasics? Yeah. Going back to backpropagation loss functions, where they come from. And one thing\\nI like about teaching a lot honestly is it definitely strengthens your understanding.\\nSo it's not a purely altruistic activity. It's a way to learn. If you have to explain\\nsomething to someone, uh, you realize you have gaps in knowledge. Uh, and so I even\\nsurprised myself in those lectures. Like, oh, the result will obviously look at this and then the\\nresult doesn't look like it. And I'm like, okay, I thought I understood this. Yeah.\\nBut that's why it's really cool. Literally code, you run it in the notebook and it gives you a\\nresult and you're like, oh, wow. Yes. And like actual numbers, actual input, actual code.\\nYeah. It's not mathematical symbols, et cetera. The source of truth is the code. It's not slides.\\nIt's just like, let's build it. It's beautiful. You're a rare human in that sense. Uh, what\\nadvice would you give to researchers, uh, trying to develop and publish idea that have a big impact\\nin the world of AI? So maybe, um, undergrads, maybe early graduate students. Yep. I mean,\\nI would say like, they definitely have to be a little bit more strategic than I had to be as a\\nPhD student because of the way AI is evolving. It's going the way of physics, where, you know,\\nin physics, you used to be able to do experiments on your bench top and everything was great and\\nyou could make progress. And now you have to work in like LHC or like CERN. And, and so AI is going\\nin that direction as well. Um, so there's certain kinds of things that's just not possible to do on\\nthe bench top anymore. And, uh, I think, um, that didn't used to be the case at the time.\\nDo you still think that there's like, GAN type papers to be written where like, uh, like very\\nsimple idea that requires just one computer to illustrate a simple example? I mean, one example\\nthat's been very influential recently is diffusion models. The fusion models are amazing. The fusion\\nmodels are six years old. Uh, for the longest time, people were kind of ignoring them as far\\nas I can tell. And, uh, they're an amazing generative model, especially in, uh, in images.\\nAnd so stable diffusion and so on. It's all diffusion based. Uh, the fusion is new. It was\\nnot there and came from, well, it came from Google, but a researcher could have come up with it. In\\nfact, some of the first actually know those came from Google as well. Uh, but a researcher could\\ncome up with that in an academic institution. Yeah. What do you find most fascinating about\\ndiffusion models? So from the societal impact of the technical architecture, what I like about\\nthe fusion is it works so well. Was that surprising to you? The amount of the variety, almost the\\nnovelty of the synthetic data is generating. Yeah. So the stable diffusion images are incredible.\\nIt's the speed of improvement in generating images has been insane. Uh, we went very quickly\\nfrom generating like tiny digits to tiny faces and it all looked messed up. And now we were stable\\ndiffusion and that happened very quickly. There's a lot that academia can still contribute. Uh,\\nyou know, for example, um, flash attention is a very efficient kernel for running the attention\\noperation inside the transformer that came from academic environment. It's a very clever way to\\nstructure the kernel, uh, that do the best calculation. So it doesn't materialize the\\nattention matrix. Um, and so there's, I think there's still like lots of things to contribute,\\nbut you have to be just more strategic. Do you think neural networks can be made to reason?\\nUh, yes. Do you think they already reason? Yes. What's your definition of reasoning? Uh,\\ninformation processing.\\nSo in the way that humans think through a problem and come up with novel ideas,\\nit, it feels like reasoning. Yeah. So the, the novelty,\\nI don't want to say, but out of, out of distribution ideas, you think it's possible?\\nYes. And I think we're seeing that already in the current neural nets. You're able to remix the\\ntraining set information into true generalization in some sense. That doesn't appear in a fundamental\\nway in the training set. Like you're doing something interesting algorithmically, you're\\nmanipulating, you know, some symbols and you're coming up with some correct, unique answer in a\\nnew setting. What would, uh, illustrate to you, holy shit, this thing is definitely thinking.\\nTo me, thinking or reasoning is just information processing and generalization. And I think the\\nneural nets already do that today. So being able to perceive the world or perceive the,\\nwhatever the inputs are and to make predictions based on that or actions based on that, that's,\\nthat's the reason. Yeah. You're giving correct answers in novel settings, uh, by manipulating\\ninformation. You've learned the correct algorithm. You're not doing just some kind of a lookup table\\non the Earth's neighbor search. Something like that. Let me ask you about AGI. What, what are some\\nmoonshot ideas you think might make significant progress towards AGI? Or maybe another way is\\nwhat are the big blockers that we're missing now? So basically I am fairly bullish on our ability to\\nbuild AGI's, uh, basically automated systems that we can interact with that are very human-like\\nand we can interact with them in the digital realm or physical realm. Currently, it seems\\nmost of the models that sort of do these sort of magical tasks are in a text realm. Um, I think,\\nas I mentioned, I'm suspicious that the text realm is not enough to actually build full\\nunderstanding of the world. I do actually think you need to go into pixels and understand the\\nphysical world and how it works. So I do think that we need to extend these models to consume\\nimages and videos and train on a lot more data that is multimodal in that way. Do you think you\\nneed to touch the world to understand it also? Well, that's the big open question I would say\\nin my mind is if you also require the embodiment and the ability to, uh, sort of, sort of interact\\nwith the world, run experiments and, um, have a data of that form, then you need to go to optimist\\nor something like that. And so I would say optimist in some way is like a hedge, um,\\nin AGI because it seems to me that it's possible that just having data from the internet is not\\nenough. If that is the case, then optimist may lead to AGI, uh, because optimist would, I, to me,\\nthere's nothing beyond optimist. You have like this humanoid form factor that can actually like\\ndo stuff in the world. You can have millions of them interacting with humans and so on. And, uh,\\nif that doesn't give rise to AGI at some point, like I'm not sure what will. Um, so from a\\ncompleteness perspective, I think that's the, uh, that's a really good platform, but it's a much\\nharder platform because, uh, you are dealing with atoms and you need to actually like build these\\nthings and integrate them into society. So I think that path takes longer, uh, but it's much\\nmore certain. And then there's a path of the internet and just like training these compression\\nmodels effectively, uh, on a trend compress all the internet. And, uh, that might also give, um,\\nthese agents as well. Compress the internet, but also interact with the internet. So it's not\\nobvious to me. In fact, I suspect you can reach AGI without ever entering the physical world.\\nAnd the, which is a little bit more, uh, concerning because it might, that results in it happening\\nfaster. So it just feels like we're in, like in boiling water. We won't know as it's happening.\\nI would like to, I'm not afraid of AGI. I'm excited about it. There's always concerns,\\nbut I would like to know when it happens. Yeah. Or it have like hints about when it happens, like\\na year from now, it will happen. That kind of thing. I just feel like in the digital realm,\\nit just might happen. Yeah. I think all we have available to us because no one has built AGI\\nagain. So all we have available to us is, uh, is there enough fertile ground on the periphery?\\nI would say yes. And we have the progress so far, which has been very rapid and, uh, there are next\\nsteps that are available. And so I would say, uh, yeah, it's quite likely that we'll be interacting\\nwith digital entities. How will you know that somebody has built AGI? It's going to be a slow,\\nI think it's going to be a slow incremental transition is going to be product based and\\nfocused. It's going to be GitHub co-pilot getting better. And then, uh, GPT is helping you right.\\nAnd then these oracles that you can go to with mathematical problems, I think we're on a,\\non a verge of being able to ask very complex questions in chemistry, physics, math,\\nof these oracles and have them complete solutions. So AGI to use primarily focused on intelligence.\\nSo consciousness doesn't enter into, uh, into it. So in my mind, consciousness is not a special\\nthing you will, you will figure out and bolt on. I think it's an emerging phenomenon of a\\nlarge enough and complex enough, um, generative model sort of. So, um, if you have a complex\\nenough world model, uh, that understands the world, then it also understands its predicament\\nin the world as being a language model, which to me is a form of consciousness or self-awareness.\\nAnd so in order to understand the world deeply, you probably have to integrate yourself into the\\nworld. And in order to interact with humans and other living beings, consciousness is a very\\nuseful tool. I think consciousness is like a modeling insight. Modeling insight. Yeah. It's a,\\nyou have a powerful enough model of understanding the world that you actually understand that you\\nare an entity in it. Yeah. But there's also this, um, perhaps just the narrative we tell ourselves.\\nThere's a, it feels like something to experience the world, the hard problem of consciousness,\\nbut that could be just a narrative that we tell ourselves. Yeah. I don't think we'll,\\nyeah, I think it will emerge. I think it's going to be something very boring. Like we'll be talking\\nto these digital AIs, they will claim they're conscious. They will appear conscious. They will\\ndo all the things that you would expect of other humans. And, uh, it's going to just be a stalemate.\\nI think there'll be a lot of actual fascinating ethical questions, like Supreme Court level\\nquestions of whether you're allowed to turn off a conscious AI. If you're allowed to build a\\nconscious AI, maybe there would have to be the same kind of debate that you have around\\num, sorry to bring up a political topic, but you know, abortion, uh, which is the deeper question\\nwith abortion, uh, is what is life? And the deep question with AI is also what is life and what is\\nconscious? And I think that'll be very fascinating to bring up. It might become illegal to build\\nsystems that are capable like of such level of intelligence that consciousness would emerge.\\nAnd therefore the capacity to suffer would emerge and somebody, a system that says, no,\\nplease don't kill me. Well, that's what the Lambda compute, the Lambda chatbot already told,\\num, this Google engineer, right? Like it was talking about not wanting to die or so on.\\nSo that might become illegal to do that. Right.\\nCause otherwise you might have a lot of, a lot of creatures that don't want to die\\nand they will, uh, you can just spawn infinity of them on a cluster.\\nAnd then that might lead to like horrible consequences. Cause then there might be a lot\\nof people that secretly love murder and then we'll start practicing murder on those systems.\\nI mean, there's just, I, to me, all of this stuff just brings a beautiful mirror to the human\\ncondition and human nature. We'll get to explore it. And that's what like the best of, uh, the\\nSupreme court of all the different debates we have about ideas of what it means to be human.\\nWe get to ask those deep questions that we've been asking throughout human history.\\nThere's always been the other in human history. Uh, we're the good guys and that's the bad guys.\\nAnd we're going to, uh, you know, throughout human history, let's murder the bad guys.\\nAnd the same will probably happen with robots. It'll be the other at first. And then we'll get\\nto ask questions of what does it mean to be alive? What does it mean to be conscious?\\nYep. And I think there's some canary in the coal mines, even with what we have today.\\nAnd, uh, you know, for example, these, there's these like waifus that you can like work with.\\nAnd some people are trying to like, this company is going to shut down, but this person really like,\\nlove their waifu and like, it's trying to like port it somewhere else. And like, it's not possible.\\nAnd like, I think like definitely, uh, people will have feelings towards, uh, towards these,\\num, systems because in some sense they are like a mirror of humanity because they are like sort of\\nlike a big average of humanity in a way that it's trained. But we can, that average,\\nwe can actually watch. There's, it's nice to be able to interact with the big average of humanity\\nand do like a search query on it. Yeah. Yeah. It's very fascinating. And, uh, we can of course,\\nalso like shape it. It's not just a pure average. We can mess with the training data. We can mess\\nwith the objective. We can fine tune them in various ways. Uh, so we have some, um, you know,\\nimpact on what those systems look like. If you want to achieve AGI, um, and you could, uh, have\\na conversation with her and ask her, uh, talk about anything, maybe ask her a question. What,\\nwhat kind of stuff would you, would you ask? I would have some practical questions in my mind,\\nlike, uh, do I or my loved ones really have to die? Uh, what can we do about that?\\nDo you think it will answer clearly or would it answer poetically?\\nI would expect it to give solutions. I would expect it to be like, well, I've read all of\\nthese textbooks and I know all these things that you've produced. And it seems to me like,\\nhere are the experiments that I think it would be useful to run next. And here's some gene\\ntherapies that I think would be helpful. And, uh, here are the kinds of experiments that you should\\nrun. Okay. Let's go with this thought experiment. Okay. Imagine that mortality is actually, uh,\\npre like a prerequisite for happiness. So if we become immortal, we'll actually become deeply\\nunhappy and the model is able to know that. So what is this supposed to tell you? Stupid human\\nabout it. Yes, you can become a mortal, but you will become deeply unhappy. If, if the models,\\nif the AGI system is trying to empathize with you human, what is this supposed to tell you that?\\nYes, you don't have to die, but you're really not going to like it. Is that, is it going to be\\ndeeply honest? Like there's a interstellar. What is it? The AI says like humans want 90% honesty.\\nYeah. So like you have to pick how honest do I want to answer these practical questions?\\nYeah. I love AI and interstellar by the way. I think it's like such a sidekick to the entire story,\\nbut at the same time, it's like really interesting. It's kind of limited in certain ways,\\nright? Yeah, it's limited. And I think that's totally fine by the way. I don't think, uh,\\nI think it's fine and plausible to have a limited and imperfect AGI.\\nIs that the feature almost as an example, like it has a fixed amount of compute on its physical\\nbody. And it might just be that even though you can have a super amazing mega brain,\\nsuper intelligent AI, you also can have like, you know, less intelligent as they can deploy\\nin a power efficient way. And then they're not perfect. They might make mistakes.\\nNo, I meant more like say you had infinite compute and it's still good to make mistakes sometimes\\nto integrate yourself. Like, um, what is it going back to goodwill hunting? Uh,\\nRobin Williams character says like the human imperfections, that's the good stuff, right?\\nIsn't it, isn't that the S like we don't want perfect. We want flaws in part to,\\nto form connections with each other because it feels like something you can attach your feelings\\nto the, the, the flaws in that same way. You want AI that's flawed. I don't know. I feel like\\nperfectionist, but then you're saying, okay, yeah, but that's not AGI, but see AGI would need to be\\nintelligent enough to give answers to humans that humans don't understand. And I think perfect isn't\\nsomething humans can't understand because even science doesn't give perfect answers. There's\\nalways gabs and mysteries and I don't know. I, I don't know if humans want perfect.\\nYeah. I could imagine just, um, having a conversation with this kind of oracle entity\\nas you'd imagine them. And, uh, yeah, maybe it can tell you about, you know, based on my analysis of\\nhuman condition, um, you might not want this and here are some of the things that might,\\nbut every, every dumb human will say, yeah, yeah, yeah, yeah. Trust me. I can give me the truth. I\\ncan handle it, but that's the beauty. Like people can choose. Uh, so, but then\\nit's the old marshmallow test with the kids and so on. I feel like too many people,\\nlike can't handle the truth, probably including myself, like the deep truth of the human\\ncondition. I don't, I don't know if I can handle it. Like, what if there's some dark stuff? What,\\nwhat if we are an alien science experiment and it realizes that what if it had, I mean,\\nI mean, this is the matrix, you know, all over again.\\nI don't know. I would, what would I talk about? I don't even, yeah, I, uh, probably I will go\\nwith the safer scientific questions at first that have nothing to do with my own personal life and\\nmortality, just like about physics and so on, uh, to, to build up, like, let's see where it's at,\\nor maybe see if it has a sense of humor. That's another question. Would it be able to, uh,\\npresumably in order to, if it understands humans deeply, it would be able to generate, uh,\\nyeah, to generate humor. Yeah. I think that's actually a wonderful benchmark almost. Like,\\nis it able, I think that's a really good point basically to make you laugh. Yeah. If it's able\\nto be like a very effective standup comedian, that is doing something very interesting computationally.\\nI think being funny is extremely hard. Yeah. Because it's hard in a way, like a touring test,\\nthe original intent of the touring test is hard because you have to convince humans and there's\\nnothing that's why, that's why comedians talk about this. Like there's, this is deeply honest\\nbecause if people can't help but laugh and if they don't laugh, that means you're not funny.\\nIf they laugh, it's funny. And you're showing, you need a lot of knowledge to create, to create\\nhumor about like the documentation, human condition and so on. And then you need to be clever with it.\\nUh, you mentioned a few movies you tweeted movies that I've seen five plus times, but\\nI'm ready and willing to keep watching interstellar gladiator contact goodwill hunting,\\nthe matrix, Lord of the rings, all three avatar fifth elements. So on and goes on terminated to\\nmean girls. I'm not going to ask about that. I think her man girls is great. Um, what are some\\nthat jump out to your memory that you love and why you mentioned the matrix\\nas a computer person, why do you love the matrix? There's so many properties that make it like\\nbeautiful and interesting. So, uh, there's all these philosophical questions, but then there was\\nalso a GIs and there's a simulation and it's cool. And there's, you know, the black, uh, you know,\\nthe look of it, the feel of it, the feel of it, the action, the bullet time. It was just like\\ninnovating in so many ways. And then, uh, goodwill goodwill hunting. Why do you like that one?\\nYeah, I just, I really like this, uh, tortured genius sort of character who's like grappling\\nwith whether or not he has like any responsibility or like what to do with this gift that he was\\ngiven or like how to think about the whole thing. And, uh, there's also a dance between the genius\\nand the, the personal, like what it means to love another human being. And there's a lot of things\\nthere. It's just a beautiful movie. And then the fatherly figure, the mentor in the, in the\\npsychiatrist and the, it like really like, uh, it messes with you. You know, there's some movies\\nthat just like really mess with you, uh, on a deep level. Do you relate to that movie at all?\\nNo, it's not your fault. As I said, Lord of the Rings, that's self-explanatory. Terminator two,\\nwhich is interesting. You rewatch that a lot. Is that better than Terminator one? You like,\\nI do like Terminator one as well. Uh, I like Terminator two a little bit more,\\nbut in terms of like its surface properties,\\ndo you think Skynet is at all a possibility? Uh, yes.\\nLike the actual sort of, uh, autonomous, uh, weapon system kind of thing. Do you worry about that\\nstuff? I do worry. I being useful war. I a hundred percent worry about it. And so the,\\nI mean, the, uh, you know, some of these, uh, fears of AGI and how this will plan out, I mean,\\nthese will be like very powerful entities probably at some point. And so, um, for a long time,\\nthere are going to be tools in the hands of humans. Uh, you know, people talk about like\\nalignment of AGI and how to make the problem is like even humans are not aligned. Uh, so,\\nuh, how this will be used and what this is going to look like is, um, yeah, it's troubling. So.\\nDo you think it'll happen slowly enough that we'll be able to,\\nas a human civilization, think through the problems?\\nYes. That's my hope is that it happens slowly enough and in open enough way where a lot of\\npeople can see and participate in it. Just figure out how to deal with this transition. I think\\nwe're just going to be interesting. I draw a lot of inspiration from nuclear weapons\\nbecause I sure thought it would be, it would be fucked once they develop nuclear weapons.\\nBut like, it's almost like, uh, when, uh, when the systems are not so dangerous,\\nthey distort human civilization. We deploy them and learn the lessons. And then we quickly\\nif it's too dangerous, we'll quickly, quickly, we might still deploy it. Uh, but you very quickly\\nlearn not to use them. And so there'll be like this balance achieved. Humans are very clever as\\na species. It's interesting. We exploit the resources as much as we can, but we don't,\\nwe avoid destroying ourselves. It seems like. Well, I don't know about that actually. I hope\\nit continues. Um, I mean, I'm definitely like concerned about nuclear weapons and so on,\\nnot just as a result of the recent conflict, even before that, uh, that's probably my number\\none concern for humanity. So if humanity, uh, destroys itself or destroys, you know, 90%\\nof people that would be because of nukes. I think so. Um, and it's not even about the full\\ndestruction to me. It's bad enough if we reset society, that would be like terrible. It would\\nbe really bad. And I can't believe we're like so close to it. Yeah. It's like so crazy to me.\\nIt feels like we might be a few tweets away from something like that. Yep. Basically it's extremely\\nunnerving, but it has been for me for a long time. It seems unstable that world leaders,\\njust having a bad mood can like, um, take one step towards a bad direction and it escalates.\\nYeah. And because of a collection of bad moods, it can escalate without being able to, um, stop.\\nYeah, it's just, uh, it's a huge amount of, uh, power. And then also with the proliferation,\\nI basically, I don't, I don't actually really see, I don't actually know what the good outcomes are\\nhere. Uh, so I'm definitely worried about that a lot. And then AGI is not currently there,\\nbut I think at some point will more and more become something like it. The danger with AGI\\neven is that I think it's even like slightly worse in the sense that, uh, there are good outcomes of\\nAGI and then the bad outcomes are like an Epsilon away, like a tiny one away. And so I think, um,\\ncapitalism and humanity and so on will drive for the positive, uh, ways of using that technology.\\nBut then if bad outcomes are just like a tiny, like flip a minus sign away, uh, that's a really\\nbad position to be in a tiny perturbation of the system results in the destruction of the human\\nspecies. So we are lying to walk. Yeah. I think in general, it's really weird about like the\\ndynamics of humanity and this explosion we've talked about is just like the insane coupling\\nafforded by technology and, uh, just the instability of the whole dynamical system.\\nI think it's just, it doesn't look good, honestly. Yes. That explosion could be destructive and\\nconstructive and the probabilities are non-zero in both. Yeah. I mean, I have to, I do feel like I\\nhave to try to be optimistic and so on. And I think even in this case, I still am predominantly\\noptimistic, but there's definitely. Me too. Uh, do you think we'll become a multi-planetary species?\\nProbably yes, but I don't know if it's dominant feature of, uh, future humanity. Uh, there might\\nbe some people on some planets and so on, but I'm not sure if it's like, yeah, if it's like a major\\nplayer in our culture and so on, we still have to solve the drivers of self-destruction here on earth.\\nSo just having a backup on Mars is not going to solve the problem. So by the way, I love the backup\\non Mars. I think that's amazing. You should absolutely do that. Yes. And I'm so thankful.\\nWould you go to Mars? Uh, personally, no, I do like earth quite a lot. Okay. Uh, I'll go to Mars.\\nI'll go for you. I'll tweet at you from there. Maybe eventually I would once it's safe enough,\\nbut I don't actually know if it's on my lifetime scale unless I can extend it by a lot.\\nI do think that, for example, a lot of people might disappear into, um, virtual realities and\\nstuff like that. And I think that could be the major thrust of, um, sort of the cultural\\ndevelopment of humanity if it survives. Uh, so it might not be, it's just really hard to work in\\nphysical realm and go out there. And I think ultimately all your experiences are in your\\nbrain. And so it's much easier to disappear into digital realm. And I think people will\\nfind them more compelling, easier, safer, more interesting. So you're a little bit captivated\\nby virtual reality, by the possible worlds, whether it's the metaverse or some other\\nmanifestation of that. Yeah. Yeah. It's really interesting. It's, uh, I'm, I'm interested just,\\njust talking a lot to Carmack. Where's the, where's the thing that's currently preventing that?\\nYeah. I mean, to be clear, I think what's interesting about future is, um, it's not that\\nI kind of feel like the variance in the human condition grows. That's the primary thing that's\\nchanging. It's not as much the mean of the distribution is like the variance of it. So\\nthere will probably be people on Mars and there will be people in VR and there will people here\\non earth. It's just like, there will be so many more ways of being. And so I kind of feel like\\nI see it as like a spreading out of a human experience. There's something about the internet\\nthat allows you to discover those little groups and then you gravitate to something about your\\nbiology, likes that kind of world that you find each other. Yeah. And we'll have transhumanists\\nand then we'll have the Amish and they're going to, everything is just going to coexist.\\nYou know, the cool thing about it, cause I've interacted with a bunch of internet communities\\nis, um, they don't know about each other. Like you can have a very happy existence,\\njust like having a very close knit community and not knowing about each other. I mean, even,\\nyou even sense this, just having traveled to Ukraine, there's, they, they don't know\\nso many things about America. You, you like when you travel across the world,\\nI think you experienced this too. There are certain cultures that are like,\\nthey have their own thing going on. They don't. And so you can see that happening more and more\\nand more and more in the future. We have little communities. Yeah. Yeah. I think so. That seems\\nto be the, that seems to be how it's going right now. And I don't see that trend like really\\nreversing. I think people are diverse and they're able to choose their own path and existence.\\nAnd I sort of like celebrate that. Um, and so- Will you spend some much time in the metaverse,\\nin the virtual reality or which community area are you the physicalist, uh, the, the,\\nthe physical reality enjoyer or, uh, do you see drawing a lot of, uh, pleasure and fulfillment\\nin the digital world? Yeah, I think, well, currently the virtual reality is not that compelling.\\nI do think it can improve a lot, but I don't really know to what extent maybe, you know,\\nthere's actually like even more exotic things you can think about with like neural links or\\nstuff like that. So, um, currently I kind of see myself as mostly a team human person. I love\\nnature. I love harmony. I love people. I love humanity. I love emotions of humanity. Um, and\\nI, I just want to be like in this like solar punk little utopia. That's my happy place. Yes. My happy\\nplace is like, uh, people I love thinking about cool problems surrounded by a lush, beautiful,\\ndynamic nature and a secretly high tech in places that count places. They use technology to empower\\nthat love for other humans and nature. Yeah. I think a technology used like very sparingly.\\nI don't love when it sort of gets in the way of humanity in many ways. Uh, I like just people\\nbeing humans in a way we sort of like slightly evolved and prefer, I think just by default.\\nPeople kept asking me because they, they know you love reading. Are there particular books\\nthat you enjoyed that had an impact on you for silly or for profound reasons that you would\\nrecommend? You mentioned the vital question. Many, of course, I think in biology as an example,\\nthe vital question is a good one. Anything by Nic Lane, really, uh, life ascending, I would say\\nis like a bit more potentially, uh, representative as like a summary of a lot of the things he's been\\nabout. I was very impacted by the selfish gene. I thought that was a really good book that helped\\nme understand altruism as an example and where it comes from. And just realizing that, you know,\\nthe selection is on the level of genes was a huge insight for me at the time. And it sort of like\\ncleared up a lot of things for me. What do you think about the, the idea that ideas are the\\norganisms, the meat? Yes, love it. A hundred percent. Are you able to walk around with that\\nnotion for a while that, that there is an evolutionary kind of process with ideas as well?\\nThere absolutely is. There's memes just like genes and they compete and they live in our brains.\\nIt's beautiful. Are we silly humans thinking that we're the organisms? Is it possible that the\\nprimary organisms are the ideas? Yeah, I would say like the, the ideas kind of live in the software\\nof like our civilization in the, in the minds and so on. We think as humans that the hardware is\\nthe fundamental thing. I human is a hardware entity, but it could be the software, right?\\nYeah. Yeah. I would say like there needs to be some grounding at some point to like a physical\\nreality. Yeah. But if we clone an Andre, the software is the thing, like is this thing that\\nmakes that thing special, right? Yeah, I guess you're right. But then cloning might be exceptionally\\ndifficult. Like there might be a deep integration between the software and the hardware in ways we\\ndon't quite understand. Well, from the ultimate point of view, like what makes me special is more\\nlike the, the gang of genes that are writing in my chromosomes, I suppose, right? Like they're the,\\nthey're the replicating unit, I suppose. And no, but that's just the thing that makes you special.\\nSure. Well, the reality is what makes you special is your ability to survive\\nbased on the software that runs on the hardware that was built by the genes.\\nSo the software is the thing that makes you survive, not the hardware.\\nAll right. It's a little bit of both. I mean, you know, it's just like a second layer. It's\\na new second layer that hasn't been there before the brain. They both, they both coexist.\\nBut there's also layers of the software. I mean, it's, it's not, it's a, it's a abstraction on top\\nof abstractions. But, okay. So Selfish Gene and Nick Lane, I would say sometimes books are like\\nnot sufficient. I like to reach for textbooks sometimes. I kind of feel like books are for\\ntoo much of a general consumption sometime. And they just kind of like, they're too high up in\\nthe level of abstraction and it's not good enough. So I like textbooks. I like The Cell. I think\\nThe Cell was pretty cool. That's why also I like the writing of Nick Lane is because he's pretty\\nwilling to step one level down and he doesn't, yeah, he sort of, he's willing to go there.\\nBut he's also willing to sort of be throughout the stack. So he'll go down to a lot of detail,\\nbut then he will come back up. And I think he has a, yeah, basically I really appreciate that.\\nThat's why I love college, early college, even high school, just textbooks on the basics.\\nOf computer science, of mathematics, of biology, of chemistry. Those are, they condense down like\\nit's sufficiently general that you can understand both the philosophy and the details, but also like\\nyou get homework problems and you get to play with it as much as you would if you were in\\nprogramming stuff. Yeah. And then I'm also suspicious of textbooks, honestly, because\\nas an example in deep learning, there's no like amazing textbooks and I feel this changing very\\nquickly. I imagine the same is true in say synthetic biology and so on. These books like The Cell are\\nkind of outdated. They're still high level. Like what is the actual real source of truth? It's\\npeople in wet labs working with cells, sequencing genomes and yeah, actually working with it. And\\nI don't have that much exposure to that or what that looks like. So I still don't fully,\\nI'm reading through the cell and it's kind of interesting and I'm learning, but it's still not\\nsufficient I would say in terms of understanding. Well, it's a clean summarization of the mainstream\\nnarrative, but you have to learn that before you break out towards the cutting edge. Yeah. But what\\nis the actual process of working with these cells and growing them and incubating them? And it's\\nkind of like a massive cooking recipes of making sure your cells lives and proliferate and then\\nyou're sequencing them, running experiments and just how that works, I think is kind of like the\\nsource of truth of at the end of the day, what's really useful in terms of creating therapies and\\nso on. Yeah. I wonder what in the future AI textbooks will be because there's artificial\\nintelligence, the modern approach. I actually haven't read if it's come out the recent version,\\nthere's been a recent addition. I also saw there's a science, a deep learning book. I'm waiting for\\ntextbooks that are worth recommending, worth reading. It's tricky because it's like papers\\nand code, code, code. Honestly, I find papers are quite good. I especially like the appendix of any\\npaper as well. It's like the most detail you can have. It doesn't have to be cohesive connected\\nto anything else. You just described me a very specific way you saw the particular thing. Yeah.\\nMany times papers can be actually quite readable, not always, but sometimes the introduction and\\nthe abstract is readable even for someone outside of the field. This is not always true. Sometimes\\nI think, unfortunately, scientists use complex terms even when it's not necessary. I think that's\\nharmful. I think there's no reason for that. Papers sometimes are longer than they need to be in the\\nparts that don't matter. Appendix should be long, but then the paper itself, look at Einstein,\\nmake it simple. Yeah, but certainly I've come across papers I would say in synthetic biology\\nor something that I thought were quite readable for the abstract and the introduction. Then you're\\nreading the rest of it and you don't fully understand, but you are getting a gist and I\\nthink it's cool. What advice, you give advice to folks interested in machine learning and research,\\nbut in general, life advice to a young person in high school, early college about how to have a\\ncareer they can be proud of or a life they can be proud of? Yeah, I think I'm very hesitant to give\\ngeneral advice. I think it's really hard. I've mentioned some of the stuff I've mentioned is\\nfairly general, I think. Focus on just the amount of work you're spending on a thing.\\nCompare yourself only to yourself, not to others. That's good. I think those are fairly general.\\nHow do you pick the thing? You just have a deep interest in something or try to find the argmax\\nover the things that you're interested in. Argmax at that moment and stick with it. How do you not\\nget distracted and switch to another thing? You can, if you like.\\nIf you do an argmax repeatedly every week, every month, it's a problem.\\nYeah, you can low pass filter yourself in terms of what has consistently been true for you.\\nI definitely see how it can be hard, but I would say you're going to work the hardest on the thing\\nthat you care about the most. Low pass filter yourself and really introspect in your past,\\nwhat are the things that gave you energy and what are the things that took energy away from you?\\nConcrete examples. Usually from those concrete examples, sometimes patterns can emerge.\\nI like it when things look like this when I'm in these positions.\\nThat's not necessarily the field, but the kind of stuff you're doing in a particular field. For you,\\nit seems like you were energized by implementing stuff, building actual things.\\nYeah, being low level, learning, and then also communicating so that others can go through the\\nsame realizations and shortening that gap. Because I usually have to do way too much work\\nto understand a thing. Then I'm like, okay, this is actually like, okay, I think I get it.\\nWhy was it so much work? It should have been much less work. That gives me a lot of frustration,\\nand that's why I sometimes go teach. Aside from the teaching you're doing now,\\nputting out videos, aside from a potential Godfather Part II with the AGI at Tesla and beyond,\\nwhat does the future of Ranjha Kapothi hold? Have you figured that out yet or no?\\nAs you see through the fog of war, that is all of our future. Do you start seeing silhouettes of\\nwhat that possible future could look like? The consistent thing I've been always interested\\nin for me at least is AI. That's probably what I'm spending the rest of my life on,\\nbecause I just care about it a lot. I actually care about many other problems as well, like say\\naging, which I basically view as disease. I care about that as well, but I don't think it's a good\\nidea to go after it specifically. I don't actually think that humans will be able to come up with the\\nanswer. I think the correct thing to do is to ignore those problems and you solve AI and then\\nuse that to solve everything else. I think there's a chance that this will work. I think it's a very\\nhigh chance. That's the way I'm betting at least. When you think about AI, are you interested in\\nall kinds of applications, all kinds of domains, and any domain you focus on will allow you to get\\ninsights to the big problem of AGI? Yeah, for me, it's the ultimate meta problem. I don't want to\\nwork on any one specific problem. There's too many problems. How can you work on all problems\\nsimultaneously? You solve the meta problem, which to me is just intelligence, and how do you\\nautomate it? Is there cool small projects like Archives Sanity and so on that you're thinking\\nabout that the world, the ML world can anticipate? There's always some fun side projects.\\nArchives Sanity is one. Basically, there's way too many archive papers. How can I organize it\\nand recommend papers and so on? I transcribed all of your podcasts. What did you learn from that\\nexperience from transcribing the process of, you like consuming audiobooks and podcasts and so on.\\nHere's a process that achieves closer to human level performance and annotation.\\nYeah. Well, I definitely was surprised that transcription with OpenAI's Whisper was\\nworking so well compared to what I'm familiar with from Siri and a few other systems, I guess.\\nIt works so well. That's what gave me some energy to try it out. I thought it could be fun to run\\non podcasts. It's not obvious to me why Whisper is so much better compared to anything else,\\nbecause I feel like there should be a lot of incentive for a lot of companies to produce\\ntranscription systems and that they've done so over a long time. Whisper is not a super exotic\\nmodel. It's a transformer. It takes smell spectrograms and just outputs tokens of text. It's\\nnot crazy. The model and everything has been around for a long time. I'm not actually 100%\\nsure why this game model. Yeah, it's not obvious to me either. It makes me feel like I'm missing\\nsomething. I'm missing something. Yeah, because there is a huge, even Google and so on YouTube\\ntranscription. Yeah. Yeah, it's unclear, but some of it is also integrating into a bigger system.\\nThat is the user interface, how it's deployed and all that kind of stuff. Maybe\\nrunning it as an independent thing is much easier, like an order of magnitude easier than deploying\\ninto a large integrated system like YouTube transcription or anything like meetings. Zoom\\nhas transcription that's kind of crappy, but creating an interface where it detects the\\ndifferent individual speakers, it's able to display it in compelling ways, run it in real time,\\nall that kind of stuff. Maybe that's difficult. That's the only explanation I have because\\nI'm currently paying quite a bit for human transcription and human captions annotation.\\nIt seems like there's a huge incentive to automate that. Yeah. It's very confusing.\\nI think, I mean, I don't know if you looked at some of the whisper transcripts, but they're\\nquite good. They're good. Especially in tricky cases. I've seen\\nWhisper's performance on super tricky cases and it does incredibly well. I don't know. A podcast\\nis pretty simple. It's like high quality audio and you're speaking usually pretty clearly.\\nSo I don't know. I don't know what OpenAI's plans are either.\\nYeah. There's always like fun projects basically. StableDiffusion also is opening up a huge amount\\nof experimentation, I would say in the visual realm and generating images and videos and movies.\\nVideos now. That's going to be pretty crazy. That's going to almost certainly work and is\\ngoing to be really interesting when the cost of content creation is going to fall to zero.\\nYou used to need a painter for a few months to paint a thing and now it's going to be speak to\\nyour phone to get your video. Hollywood will start using that to generate scenes,\\nwhich completely opens up. Yeah. So you can make a movie like Avatar eventually for under a million\\ndollars. Much less. Maybe just by talking to your phone. I mean, I know it sounds kind of crazy.\\nAnd then there'd be some voting mechanism. Would there be a show on Netflix as\\ngenerated completely automatically? Yeah, potentially. Yeah. And what does it look\\nlike also when you can just generate it on demand and there's infinity of it?\\nYeah. Oh man. All the synthetic art. I mean, it's humbling because we treat ourselves as special\\nfor being able to generate art and ideas and all that kind of stuff. If that can be done in an\\nautomated way by AI. Yeah. I think it's fascinating to me how these, the predictions of AI and what\\nis going to look like and what it's going to be capable of are completely inverted and wrong.\\nAnd sci-fi of 50s and 60s was just like totally not right. They imagined AI as like super\\ncalculating theory approvers and we're getting things that can talk to you about emotions.\\nThey can do art. It's just like weird. Are you excited about that future? Just\\nAI's like hybrid systems, heterogeneous systems of humans and AI's talking about emotions,\\nNetflix and children, AI system where the Netflix thing you watch is also generated by AI.\\nI think it's going to be interesting for sure. And I think I'm cautiously optimistic, but it's\\nnot obvious. Well, the sad thing is your brain and mine developed in a time where before Twitter,\\nbefore the internet. So I wonder people that are born inside of it might have a different\\nexperience. Like I, maybe you can, will still resist it. And the people born now will not.\\nWell, I do feel like humans are extremely malleable. Yeah. And you're probably right.\\nWhat is the meaning of life, Andre? We talked about sort of the universe having a conversation\\nwith us humans or with the systems we create to try to answer for the universe,\\nfor the creator of the universe to notice us. We're trying to create systems that are loud enough\\nto answer back. I don't know if that's the meaning of life. That's like meaning of life for some\\npeople. The first level answer I would say is anyone can choose their own meaning of life\\nbecause we are a conscious entity and it's beautiful. Number one. But I do think that\\nlike a deeper meaning of life as someone is interested is along the lines of like,\\nwhat the hell is all this and like, why? And if you look at the inter fundamental physics\\nand the quantum field theory and the standard model, they're like very complicated. And\\nthere's this like 19 free parameters of our universe and like, what's going on with all\\nthis stuff and why is it here? And can I hack it? Can I work with it? Is there a message for me?\\nAm I supposed to create a message? And so I think there's some fundamental answers there\\nbut I think there's actually even like, you can't actually like really make dent in those\\nwithout more time. And so to me also there's a big question around just getting more time honestly.\\nYeah, that's kind of like what I think about quite a bit as well.\\nSo kind of the ultimate, or at least first way to sneak up to the why question is to try to escape\\nthe system, the universe. And then for that, you sort of backtrack and say, okay, for that,\\nthat's going to be take a very long time. So the why question boils down from an engineering\\nperspective to how do we extend? Yeah, I think that's the question number one, practically\\nspeaking, because you can't, you're not going to calculate the answer to the deeper questions\\nin time you have. And that could be extending your own lifetime or extending just the lifetime of\\nhuman civilization of whoever wants to not many people might not want that. But I think people\\nwho do want that, I think, I think it's probably possible. And I don't think I don't know that\\npeople fully realize this, I kind of feel like people think of death as an inevitability. But\\nat the end of the day, this is a physical system, some things go wrong. It makes sense why\\nthings like this happen, evolutionary speaking. And there's most certainly interventions that\\nmitigate it. That'd be interesting if death is eventually looked at as, as a fascinating thing\\nthat used to happen to humans. I don't think it's unlikely. I think it's, I think it's likely.\\nAnd it's up to our imagination to try to predict what the world without death looks like.\\nYeah, it's hard to, I think the values will completely change.\\nCould be. I don't, I don't really buy all these ideas that, oh, without death, there's no meaning,\\nthere's nothing as I don't intuitively buy all those arguments. I think there's plenty of meaning,\\nplenty of things to learn. They're interesting, exciting, I want to know, I want to calculate,\\nI want to improve the condition of all the humans and organisms that are alive.\\nYeah, the way we find meaning might change. We, there is a lot of humans, probably including\\nmyself, that finds meaning in the finiteness of things. But that doesn't mean that's the\\nonly source of meaning. Yeah. I do think many people will, will go with that, which I think\\nis great. I love the idea that people can just choose their own adventure. Like you, you are\\nborn as a conscious free entity by default, I'd like to think. And you have your unalienable\\nrights for life. In the pursuit of happiness. I don't know if you have that in the nature,\\nthe landscape of happiness. You can choose your own adventure mostly. And that's not,\\nit's not fully true, but I still am pretty sure I'm an NPC, but an NPC can't know it's an NPC.\\nHmm. There could be different degrees and levels of consciousness. I don't think there's a more\\nbeautiful way to end it. Andre, you're an incredible person. I'm really honored you\\nwould talk with me. Everything you've done for the machine learning world, for the AI world,\\nto just inspire people, to educate millions of people has been, it's been great. And I can't\\nwait to see what you do next. It's been an honor, man. Thank you so much for talking today.\\nAwesome. Thank you. Thanks for listening to this conversation\\nwith Andre Karpathy. To support this podcast, please check out our sponsors in the description.\\nAnd now let me leave you with some words from Samuel Carlin. The purpose of models is not to\\nfit the data, but to sharpen the questions. Thanks for listening and hope to see you next time.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the dataset from the DB\n",
    "df = pd.read_sql('SELECT content from transcript;', engine)\n",
    "\n",
    "# Retrieve the text data for index 0\n",
    "text = df.loc[0, 'content']\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the document into chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "class TopicBasedTextSplitter:\n",
    "    def __init__(self, max_chars_per_chunk):\n",
    "        self.max_chars_per_chunk = max_chars_per_chunk\n",
    "        self.dictionary = corpora.Dictionary()\n",
    "        self.lda_model = None\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Tokenize text into sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "        return [sentence.split() for sentence in sentences]\n",
    "\n",
    "    def train_lda_model(self, corpus):\n",
    "        # Create a dictionary from the text corpus\n",
    "        self.dictionary = corpora.Dictionary(corpus)\n",
    "\n",
    "        # Convert corpus into Bag of Words format\n",
    "        corpus_bow = [self.dictionary.doc2bow(doc) for doc in corpus]\n",
    "\n",
    "        # Train LDA model\n",
    "        self.lda_model = models.LdaModel(corpus_bow, num_topics=3, id2word=self.dictionary)\n",
    "\n",
    "    def split_into_chunks(self, text):\n",
    "        # Preprocess text into sentences\n",
    "        preprocessed_text = self.preprocess_text(text)\n",
    "\n",
    "        # Train LDA model on preprocessed text\n",
    "        self.train_lda_model(preprocessed_text)\n",
    "\n",
    "        # Segment text based on topic coherence\n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        for sentence in preprocessed_text:\n",
    "            bow = self.dictionary.doc2bow(sentence)\n",
    "            topic_id, _ = max(self.lda_model[bow], key=lambda x: x[1])\n",
    "            chunk_text = \" \".join(sentence)\n",
    "            if len(current_chunk) + len(chunk_text) <= self.max_chars_per_chunk:\n",
    "                current_chunk += \" \" + chunk_text\n",
    "            else:\n",
    "                if len(current_chunk.strip()) > 0:\n",
    "                    chunks.append(current_chunk.strip())\n",
    "                current_chunk = chunk_text\n",
    "        if current_chunk.strip():\n",
    "            chunks.append(current_chunk.strip())\n",
    "\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "some kind of a crazy quantum mechanical system that somehow gives you buffer overflow, somehow gives you a rounding error in the floating point. Synthetic intelligences are kind of like the next stage of development. And I don't know where it leads to. Like at some point, I suspect the universe is some kind of a puzzle. These synthetic AIs will uncover that puzzle and solve it. The following is a conversation with Andrei Kapathe, previously the director of AI at Tesla, and before that at OpenAI and Stanford. He is one of the greatest scientists, engineers, and educators in the history of artificial intelligence. This is the Lex Friedman podcast. To support it, please check out our sponsors. And now, dear friends, here's Andrei Kapathe. What is a neural network? And why does it seem to do such a surprisingly good job of learning? What is a neural network? It's a mathematical abstraction of the brain. I would say that's how it was originally developed. At the end of the day, it's a mathematical expression. It's a fairly simple mathematical expression when you get down to it. It's basically a sequence of matrix multipliers, which are really dot products mathematically, and some non-linearity is thrown in. It's a very simple mathematical expression, and it's got knobs in it. Many knobs. Many knobs. These knobs are loosely related to the synapses in your brain. They're trainable, they're modifiable.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 2:\n",
      "The idea is we need to find the setting of the knobs that makes the neural net do whatever you want it to do, like classify images and so on. There's not too much mystery, I would say, in it. You might think that you don't want to endow it with too much meaning with respect to the brain and how it works. It's really just a complicated mathematical expression with knobs, and those knobs need a proper setting for it to do something desirable. Yeah, but poetry is just a collection of letters with spaces, but it can make us feel a certain way. In that same way, when you get a large number of knobs together, whether it's inside the brain or inside a computer, they seem to surprise us with their power. I think that's fair. I'm underselling it by a lot because you definitely do get very surprising emergent behaviors out of these neural nets when they're large enough and trained on complicated enough problems, like say for example, the next word prediction in a massive data set from the internet. These neural nets take on pretty surprising magical properties. Yeah, I think it's interesting how much you can get out of even very simple mathematical formalism. When your brain right now is talking, is it doing next word prediction? Or is it doing something more interesting? Well, it's definitely some kind of a generative model that's a GPT-like and prompted by you. So you're giving me a prompt and I'm kind of responding to it in a generative way. And by yourself perhaps a little bit?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 3:\n",
      "Are you adding extra prompts from your own memory inside your head? It definitely feels like you're referencing some kind of a declarative structure of memory and so on, and then you're putting that together with your prompt and giving away some answer. How much of what you just said has been said by you before? Nothing basically, right? No, but if you actually look at all the words you've ever said in your life and you do a search, you'll probably have said a lot of the same words in the same order before. Yeah, could be. I mean, I'm using phrases that are common, et cetera, but I'm remixing it into a pretty unique sentence at the end of the day. But you're right, definitely there's a ton of remixing. Why, you didn't, it's like Magnus Carlsen said, I'm rated 2,900 whatever, which is pretty decent. I think you're talking very, you're not giving enough credit to neural nets here. Why do they seem to, what's your best intuition about this emergent behavior? I mean, it's kind of interesting because I'm simultaneously underselling them, but I also feel like there's an element to which I'm over, like it's actually kind of incredible that you can get so much emergent magical behavior out of them despite them being so simple mathematically. So I think those are kind of like two surprising statements that are kind of juxtaposed together. And I think basically what it is, is we are actually fairly good at optimizing these neural nets.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 4:\n",
      "And when you give them a hard enough problem, they are forced to learn very interesting solutions in the optimization. And those solution basically have these emergent properties that are very interesting. There's wisdom and knowledge in the knobs. And so this representation that's in the knobs, does it make sense to you intuitively the large number of knobs can hold the representation that captures some deep wisdom about the data it has looked at? It's a lot of knobs. It's a lot of knobs. And somehow, you know, so speaking concretely, one of the neural nets that people are very excited about right now are GPTs, which are basically just next word prediction networks. So you consume a sequence of words from the internet and you try to predict the next word. And once you train these on a large enough data set, you can basically prompt these neural nets in arbitrary ways and you can ask them to solve problems and they will. So you can just tell them, you can make it look like you're trying to solve some kind of a mathematical problem and they will continue what they think is the solution based on what they've seen on the internet. And very often those solutions look very remarkably consistent, look correct potentially. Do you still think about the brain side of it? So as neural nets is an abstraction or mathematical abstraction of the brain, you still draw wisdom from the biological neural networks or even the bigger question.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 5:\n",
      "So you're a big fan of biology and biological computation. What impressive thing is biology doing to you that computers are not yet? That gap? I would say I'm definitely on, I'm much more hesitant with the analogies to the brain than I think you would see potentially in the field. And I kind of feel like certainly the way neural networks started is everything stemmed from inspiration by the brain. But at the end of the day, the artifacts that you get after training, they are arrived at by a very different optimization process than the optimization process that gave rise to the brain. And so I think, I kind of think of it as a very complicated alien artifact. It's something different. The brain? I'm sorry, the neural nets that we're training. They are complicated alien artifact. I do not make analogies to the brain because I think the optimization process that gave rise to it is very different from the brain. There was no multi-agent self-play kind of setup in evolution. It was an optimization that is basically what amounts to a compression objective on a massive amount of data. Okay. So artificial neural networks are doing compression and biological neural networks are not really doing anything. They're an agent in a multi-agent self-play system that's been running for a very, very long time. That said, evolution has found that it is very useful to predict and have a predictive model in the brain.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 6:\n",
      "And so I think our brain utilizes something that looks like that as a part of it, but it has a lot more gadgets and gizmos and value functions and ancient nuclei that are all trying to make you survive and reproduce and everything else. And the whole thing through embryogenesis is built from a single cell. It's just the code is inside the DNA and it just builds it up like the entire organism with arms and the head and legs. And it does it pretty well. It should not be possible. So there's some learning going on. There's some kind of computation going through that building process. I don't know where, if you were just to look at the entirety of history of life on earth, what do you think is the most interesting invention? Is it the origin of life itself? Is it just jumping to eukaryotes? Is it mammals? Is it humans themselves, almost sapiens? The origin of intelligence or highly complex intelligence? Or is it all just a continuation of the same kind of process? Certainly I would say it's an extremely remarkable story that I'm only briefly learning about recently. It's a way from actually like you almost have to start at the formation of earth and all of its conditions and the entire solar system and how everything is arranged with Jupiter and moon and the habitable zone and everything. And then you have an active earth that's turning over material. And then you start with a bio genesis and everything. So it's all like a pretty remarkable story.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 7:\n",
      "I'm not sure that I can pick like a single unique piece of it that I find most interesting. I guess for me as an artificial intelligence researcher, it's probably the last piece. We have lots of animals that are not building technological society, but we do. And it seems to have happened very quickly. It seems to have happened very recently. And something very interesting happened there that I don't fully understand. I almost understand everything else, I think intuitively, but I don't understand exactly that part and how quick it was. Both explanations will be interesting. One is that this is just a continuation of the same kind of process. There's nothing special about humans. That would be deeply understanding. That would be very interesting that we think of ourselves as special, but it was obvious. It was already written in the code that you would have greater and greater intelligence emerging. And then the other explanation, which is something truly special happened, something like a rare event, whether it's like crazy rare event like Space Odyssey. What would it be? See, if you say like the invention of fire or the, as Richard Wrangham says, the beta males deciding a clever way to kill the alpha males by collaborating. So just optimizing the collaboration, the multi-agent aspect of the multi-agent and that really being constrained on resources and trying to survive the collaboration aspect is what created the complex intelligence.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 8:\n",
      "But it seems like it's a natural algorithm, the evolutionary process. What could possibly be a magical thing that happened, like a rare thing that would say that humans are actually human level intelligence, actually a really rare thing in the universe? Yeah, I'm hesitant to say that it is rare by the way, but it definitely seems like it's kind of like a punctuated equilibrium where you have lots of exploration and then you have certain leaps, sparse leaps in between. So of course, like origin of life would be one, DNA, sex, eukaryotic life, the endosymbiosis event where the archaeon ate all bacteria, just the whole thing. And then of course, emergence of consciousness and so on. So it seems like definitely there are sparse events where a massive amount of progress was made, but yeah, it's kind of hard to pick one. So you don't think humans are unique? I've got to ask you, how many intelligent alien civilizations do you think are out there? And is their intelligence different or similar to ours? Yeah, I've been preoccupied with this question quite a bit recently, basically the Fermi paradox and just thinking through. And the reason actually that I am very interested in the origin of life is fundamentally trying to understand how common it is that there are technological societies out there in space. And the more I study it, the more I think that there should be quite a lot. Why haven't we heard from them? Because I agree with you.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 9:\n",
      "It feels like I just don't see why what we did here on Earth is so difficult to do. Yeah, and especially when you get into the details of it, I used to think origin of life was very, it was this magical rare event, but then you read books like, for example, Nic Lane, The Vital Question, Life Ascending, etc. And he really gets in and he really makes you believe that this is not that rare. Basic chemistry. You have an active Earth and you have your alkaline vents and you have lots of alkaline waters mixing with the ocean and you have your proton gradients and you have the little porous pockets of these alkaline vents that concentrate chemistry. And basically as he steps through all of these little pieces, you start to understand that actually this is not that crazy. You could see this happen on other systems. And he really takes you from just a geology to primitive life and he makes it feel like it's actually pretty plausible. And also like the origin of life was actually fairly fast after formation of Earth. If I remember correctly, just a few hundred million years or something like that after basically when it was possible, life actually arose. So that makes me feel like that is not the constraint, that is not the limiting variable and that life should actually be fairly common. And then where the drop-offs are is very interesting to think about. I currently think that there's no major drop-offs basically, and so there should be quite a lot of life.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 10:\n",
      "And basically where that brings me to then is the only way to reconcile the fact that we haven't found anyone and so on is that we just can't, we can't see them. We can't observe them. Just a quick brief comment. Nick Lane and a lot of biologists I talked to, they really seem to think that the jump from bacteria to more complex organisms is the hardest jump. The eukaryotic life basically. Yeah, which I don't, I get it. They're much more knowledgeable than me about like the intricacies of biology, but that seems like crazy. How many single cell organisms are there? And how much time you have? Surely, it's not that difficult. And a billion years is not even that long of a time really. Just all these bacteria under constrained resources battling it out. I'm sure they can invent more complex. I don't understand, it's like how to move from a hello world program to like invent a function or something like that. I don't. Yeah. So I don't, yeah, so I'm with you. I just feel like I don't see any, if the origin of life, that would be my intuition, that's the hardest thing. But if that's not the hardest thing, because it happens so quickly, then it's got to be everywhere. And yeah, maybe we're just too dumb to see it. Well, it's just, we don't have really good mechanisms for seeing this life. I mean, by what, how, so I'm not an expert just to preface this, but just from what I think about it. I want to meet an expert on alien intelligence and how to communicate.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 11:\n",
      "I'm very suspicious of our ability to find these intelligences out there and to find these earth, like radio waves, for example, are terrible. Their power drops off as basically one over R square. So I remember reading that our current radio waves would not be, the ones that we are broadcasting would not be measurable by our devices today. Only like, was it like one tenth of a light year away? Like not even, basically tiny distance, because you really need like a targeted transmission of massive power directed somewhere for this to be picked up on long distances. And so I just think that our ability to measure is not amazing. I think there's probably other civilizations out there. And then the big question is why don't they build binomial probes and why don't they interstellar travel across the entire galaxy? And my current answer is it's probably interstellar travel is like really hard. You have the interstellar medium. If you want to move at close to speed of light, you're going to be encountering bullets along because even like tiny hydrogen atoms and little particles of dust are basically have like massive kinetic energy at those speeds. And so basically you need some kind of shielding. You need, you have all the cosmic radiation. It's just like brutal out there. It's really hard. And so my thinking is maybe interstellar travel is just extremely hard. And you have to go very slow. Like billions of years to build hard?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 12:\n",
      "It feels like, it feels like we're not a billion years away from doing that. It just might be that it's very, you have to go very slowly potentially as an example through space. Right. As opposed to close to the speed of light. So I'm suspicious basically of our ability to measure life and I'm suspicious of the ability to just permeate all of space in the galaxy or across galaxies. And that's the only way that I can currently see around it. It's kind of mind blowing to think that there's trillions of intelligent alien civilizations out there kind of slowly traveling through space to meet each other. And some of them meet, some of them go to war, some of them collaborate. Or they're all just independent. They're all just like little pockets. Well statistically, if there's like, if it's this trillions of them, surely some of them, some of the pockets are close enough to get some of them happen to be close enough to see each other. And once you see, once you see something that is definitely complex life, like if we see something, we're probably going to be severe, like intensely aggressively motivated to figure out what the hell that is and try to meet them. But what would be your first instinct to try to like at a generational level, meet them or defend against them? Or what would be your instinct as a president of the United States and a scientist? I don't know which hat you prefer in this question. Yeah, I think the question, it's really hard.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 13:\n",
      "I will say like, for example, for us, we have lots of primitive life forms on earth next to us. We have all kinds of ants and everything else and we share space with them. And we are hesitant to impact on them and to, we are, we're trying to protect them by default because they are amazing, interesting, dynamical systems that took a long time to evolve and they are interesting and special. And I don't know that you want to destroy that by default. And so I like complex dynamical systems that took a lot of time to evolve. I think I'd like to, I like to preserve it if I can afford to. And I'd like to think that the same would be true about the galactic resources and that they would think that we're kind of incredible, interesting story that took time. It took a few billion years to unravel and you don't want to just destroy it. I could see two aliens talking about earth right now and saying, I'm a big fan of complex dynamical systems. So I think it was a value to preserve these and who basically are a video game they watch or show a TV show that they watch. Yeah, I think you would need like a very good reason, I think, to destroy it. Like why don't we destroy these ant farms and so on? Because we're not actually like really in direct competition with them right now. We do it accidentally and so on, but there's plenty of resources. And so why would you destroy something that is so interesting and precious? Well from a scientific perspective, you might probe it.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 14:\n",
      "You might interact with it lightly. You might want to learn something from it, right? So I wonder there could be certain physical phenomena that we think is a physical phenomena, but it's actually interacting with us to like poke the finger and see what happens. I think it should be very interesting to scientists, other alien scientists, what happened here. And you know, it's a, what we're seeing today is a snapshot. Basically it's a result of a huge amount of computation over like billion years or something like that. So it could have been initiated by aliens. This could be a computer running a program. Like when, okay, if you had the power to do this, when you, okay, for sure, at least I would, I would pick an earth like planet that has the conditions based on my understanding of the chemistry prerequisites for life and I would see it with life and run it. Right? Like, wouldn't you 100% do that and observe it and then protect? I mean that that's not just a hell of a good TV show. It's a good scientific experiment. And that it is it's physical simulation, right? Evolution is the most like actually running it, uh, is the most efficient way to, uh, understand computation or to compute stuff or to understand life or, you know, what life looks like and what branches it can take. It doesn't make me kind of feel weird that we're part of a science experiment, but maybe it's everything's a science experiment. So does that change anything for us for a science experiment?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 15:\n",
      "Um, I don't know. Two descendants of apes talking about being inside of a science experiment. I'm suspicious of this idea of like a deliberate panspermia as you described it, sir. I don't see a divine intervention in some way in the, in the historical record right now. I do feel like, um, the story in these, in these books, like Nick Lane's books and so on sort of makes sense. Uh, and it makes sense how life arose on earth uniquely. And uh, yeah, I don't need a, I mean, I don't need to reach for more exotic explanations right now. Sure. But I think that inside of video game, don't, don't, don't observe any divine intervention either. And we might just be all NPCs running a kind of code. Maybe eventually they will. Currently NPCs are really dumb, but once they're running GPTs, um, maybe they will be like, Hey, this is really suspicious. What the hell? So you are famously tweeted. It looks like if you bombard earth with photons for a while, you can emit a roadster. So if like in hitchhiker's guide to the galaxy, we would summarize the story of earth. So in that book, it's mostly harmless. Uh, what do you think is all the possible stories, like a paragraph long or sentence long that earth could be summarized as once it's done, it's computation. So like all the possible full, if earth is a book, right? Uh, probably there has to be an ending. I mean, there's going to be an end to earth and it could end in all kinds of ways. It can end soon. It can end later.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 16:\n",
      "What do you think are the possible stories? Well, definitely there seems to be, yeah, you're sort of, it's pretty incredible that these self replicating systems will basically arise from the dynamics and then they perpetuate themselves and become more complex and eventually become conscious and build a society. And I kind of feel like in some sense, it's kind of like a deterministic wave, uh, that, you know, that kind of just like happens on any, you know, any sufficiently well-arranged system like earth. And so I kind of feel like there's a certain sense of inevitability in it. Um, and it's really beautiful. And it ends somehow, right? So it's a, it's a chemically a diverse environment where complex dynamical systems can evolve and become more, more further and further complex. But then there's a certain, um, what is it? There's certain terminating conditions. Yeah, I don't know what the terminating conditions are, but definitely there's a trend line of something and we're part of that story. And like, where does that, where does it go? So you know, we're famously described often as a biological bootloader for AIs and that's because humans, I mean, you know, we're an incredible, uh, biological system and we're and, uh, you know, and love and so on. Um, but we're extremely inefficient as well. Like we're talking to each other through audio. It's just kind of embarrassing, honestly, that we're manipulating like seven symbols, uh, serially, we're using vocal cords.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 17:\n",
      "It's all happening over like multiple seconds. It's just like kind of embarrassing when you step down to the frequencies at which computers operate or are able to cooperate on. So basically it does seem like, um, synthetic intelligences are kind of like the next stage of development. And um, I don't know where it leads to. Like at some point I suspect, uh, the universe is some kind of a puzzle and these, uh, synthetic AIs will uncover that puzzle and, um, solve it. And then what happens after, right? Like what, cause if you just like fast forward earth, many billions of years, it's like, it's quiet and then it's like to turmoil. You see like city lights and stuff like that. And then what happens at like, at the end, like, is it like a poof? It's it, or is it like a calming, is it explosion? Is it like earth like open, like a giant, cause you said, um, it roasters like, well, let's start emitting like, like a giant number of like satellites. Yes. It's some kind of a crazy explosion and we're living, we're like, we're stepping through a explosion and we're like living day to day and it doesn't look like it, but it's actually, if you, I saw a very cool animation of earth, uh, and life on earth and basically nothing happens for a long time. And then the last like two seconds, like basically cities and everything and just in the lower earth orbit just gets cluttered and just the whole thing happens in the last two seconds. And you're like, this is exploding.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 18:\n",
      "This is a state explosion. So if you play, yeah, yeah. If you play it at normal speed, it'll just look like an explosion. It's a firecracker. We're living in a firecracker. Where it's going to start emitting all kinds of interesting things. Yeah. And then the, so explosion doesn't, it might actually look like a little explosion with, with lights and fire and energy emitted, all that kind of stuff. But when you look inside the details of the explosion, there's actual complexity happening where there's like, uh, yeah, human life or some kind of life. We hope it's not a destructive firecracker. It's kind of like a constructive firecracker. All right. So given that, I think, uh, hilarious discussion. It is really interesting to think about like what the puzzle of the universe is. Did the creator of the universe, uh, give us a message? Like for example, in the book, contact, um, Carl Sagan, uh, there's a message for humanity, for any civilization in, uh, digits in the expansion of PI in base 11, eventually, which is kind of interesting thought, uh, maybe, maybe we're supposed to be giving a message to our creator. Maybe we're supposed to somehow create some kind of a quantum mechanical system that alerts them to our intelligent presence here. Cause if you think about it from their perspective, it's just say like quantum field theory, massive, like cellular, ton of a ton like thing. And like, how do you even notice that we exist?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 19:\n",
      "You might not even be able to pick us up in that simulation. And so how do you, uh, how do you prove that you exist, uh, that you're intelligent and that you're part of the universe? So this is like a touring test for intelligence from earth. Yeah. I got the creator's, uh, I mean, maybe this is like trying to complete the next word in a sentence. This is a complicated way of that. Like earth is just, is basically sending a message back. Yeah. The puzzle is basically like alerting the creator that we exist. Uh, or maybe the puzzle is just to just break out of the system and just, uh, you know, uh, stick it to the creator in some way. Uh, basically, like if you're playing a video game, you can, um, you can somehow find an exploit and find a way to execute on the host machine, uh, in the arbitrary code, uh, there's some, uh, for example, I believe someone got a Mario, a game of Mario to play pong just by, um, exploiting it and then, um, creating, uh, basically writing, writing code and being able to execute arbitrary code in the game. And so maybe we should be, maybe that's the puzzle is that we should be, um, uh, find a way to exploit it. So, so I think like some of these synthetic guys will eventually find the universe to be some kind of a puzzle and then solve it in some way. And that's kind of like the end game somehow. Do you often think about it as a, as a simulation? So, uh, as, or the universe being a kind of computation that has, might have bugs and exploits. Yes.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 20:\n",
      "Yeah, I think so. I said, well, physics is essentially, I think it's possible that physics has exploits and we should be trying to find them, uh, arranging some kind of a crazy quantum mechanical system that somehow gives you buffer overflow, uh, somehow gives you a rounding error in the floating point. Uh, uh, yeah, that's right. And we're like more and more sophisticated exploits. Those are jokes, but that could be actually very close. Yeah. We'll find some way to extract infinite energy. Uh, for example, when you train a reinforcement learning agents, um, in physical simulations and you ask them to say, run quickly on the flat ground, they'll end up doing all kinds of like weird things, um, in part of that optimization, right? They'll get on their back leg and they'll slide across the floor. And it's because the optimization, um, the enforcement learning optimization on that agent has figured out a way to extract infinite energy from the friction forces and, um, basically their poor implementation. And, uh, they found a way to generate infinite energy and just slide across the surface and it's not what you expected. It's just, uh, it's sort of like a perverse solution. And so maybe we can find something like that. Maybe we can be that little dog in this physical simulation. The cracks or escapes the intended consequences of the physics that the universe came up with will figure out some kind of shortcut to some weirdness. Yeah.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 21:\n",
      "And then, man, but see the problem with that weirdness is the first person to discover the weirdness, like sliding in the back legs. That's all we're going to do. Yeah. It's very quickly become everybody does that thing. So like the paperclip maximizer is a ridiculous idea, but that very well could be what then we'll just, uh, we'll just all switched that cause it's so fun. Well, no person will discover it. I think, by the way, I think it's going to have to be, uh, some kind of a super intelligent AGI of a third generation. Like we're building the first generation AGI. And then, you know, third generation. Yeah. So the, the bootloader for an AI, the, that AI will be a bootloader for another AI. Yeah. And then there's no way for us to introspect like what that might even, uh, I think it's very likely that these things, for example, like, say you have these AGI's it's very likely that, for example, they will be completely inert. I like these kinds of sci-fi books sometimes where these things are just completely inert, they don't interact with anything. And I find that kind of beautiful because, uh, they probably, uh, they've probably figured out the meta meta game of the universe in some way, potentially there, they're doing something completely beyond our imagination. Um, and, uh, they don't interact with simple chemical life forms. Like, why would you do that? So I find those kinds of ideas compelling. What's their source of fun? What are they, what are they doing?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 22:\n",
      "What's the source of pleasure solving in the universe, but in there. So can you define what it means inert? So they escape the interaction. As in, um, uh, they will behave in some very strange way to us, uh, because they're, uh, they're beyond, they're playing the meta game, uh, and the meta game is probably say like arranging quantum mechanical systems and some very weird ways to extract infinite energy, uh, solve the digital expansion of pie to whatever amount, uh, they will build their own like little fusion reactors or something crazy, like they're doing something beyond comprehension and not understandable to us and actually brilliant under the hood. What if quantum mechanics itself is the system and we're just thinking it's physics, but we're really parasites on, on, not parasite, we're not really hurting physics, we're just living on this organisms, this organism, and we're like trying to understand it, but really it is an organism and with a deep, deep intelligence, maybe physics itself is, uh, the, the, the organism that's doing the super interesting thing. And we're just like one little thing, yeah. And sitting on top of it, trying to get energy from it. We're just kind of like these particles in the wave that I feel like is mostly deterministic and takes a universe from some kind of a big bang to some kind of a super intelligent replicator, some kind of a stable point in the universe.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 23:\n",
      "Given these laws of physics, you don't think, uh, as Einstein said, God doesn't play dice, so you think it's mostly deterministic. There's no randomness in the thing. I think it's deterministic. Oh, there's tons of, uh, well, I'm, I'm, I want to be careful with randomness. Pseudo random. Yeah. I don't like random. Uh, I think maybe the laws of physics are deterministic. Um, yeah, I think they're deterministic. You just got really uncomfortable with this question. I just, do you have anxiety about whether the universe is random or not? Is this a, what's, there's no randomness. It's, uh, you said you like goodwill hunting. It's not your fault, Andre. It's not your fault, man. Um, so you don't like randomness. Uh, yeah, I think it's, uh, unsettling. I think it's a deterministic system. I think that things that look random, like say the, uh, collapse of the wave function, et cetera, I think they're actually deterministic, just entanglement, uh, and so on and, uh, some kind of a multiverse theory, something, something. Okay. So why does it feel like we have a free will? Like if I, if I raised his hand, I chose to do this now. Um, what that doesn't feel like a deterministic thing. It feels like I'm making a choice. It feels like it. Okay. So it's all feelings. It's just feelings. Yeah. So when RL agent is making a choice, is that, um, it's not really making a choice. The choice was all already there. Yeah.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 24:\n",
      "You're interpreting the choice and you're creating a narrative for, for having made it. Yeah. And now we're talking about the narrative. It's very meta looking back. What is the most beautiful or surprising idea in deep learning or AI in general that you've come across? You've seen this field explode, uh, and grow in interesting ways. Just what, what cool ideas like, like we made you sit back and go, small, big or small. Well, the one that I've been thinking about recently, the most probably is the, the transformer architecture. Um, so basically, uh, neural networks have, uh, a lot of architectures that were trendy have come and gone for different sensory modalities, like for vision, audio, text, you would process them with different looking neural nets. And recently we've seen these, this convergence towards one architecture, the transformer, and, uh, you can feed it video or you can feed it, you know, images or speech or text, and it just gobbles it up and it's kind of like a bit of a general purpose, uh, computer. There's also trainable and very efficient to run on our hardware. And so, uh, this paper came out in 2016. I want to say, um, attention is all you need. Attention is all you need. You criticize the paper title in retrospect that it wasn't, um, it didn't foresee the bigness of the impact that it was going to have. Yeah.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 25:\n",
      "I'm not sure if the authors were aware of the impact that that paper would go on to have, probably they weren't, but I think they were aware of some of the motivations and design decisions behind the transformer and they chose not to, I think, uh, expand on it in that way in the paper. And so I think they had an idea that there was more, um, than just the surface of just like, Oh, we're just doing translation and here's a better architecture. You're not just doing translation. This is like a really cool, differentiable, optimizable, efficient computer that you've proposed. And maybe they didn't have all of that foresight, but I think it's really interesting. Isn't it funny, sorry to interrupt that that title is memeable that they went for such a profound idea. They went with a, I don't think anyone used that kind of title before, right? Attention is all you need. Yeah. It's like a meme or something. Yeah. It's not funny that one, like, uh, maybe if it was a more serious title, it wouldn't have the impact. Honestly, I, yeah, there is an element of me that honestly agrees with you and prefers it this way. Yes. Uh, if it was too grand, it would over promise and then under deliver potentially. So you want to just, uh, meme your way to greatness. That should be a t-shirt. So you, you tweeted the transformer is a magnificent neural network architecture because it is a general purpose, differentiable computer.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 26:\n",
      "It is simultaneously expressive in the forward pass, optimizable via back propagation, gradient descent, and efficient high parallelism compute graph. Can you discuss some of those details, expressive, optimizable, efficient for memory or, or in general, whatever comes to your heart? You want to have a general purpose computer that you can train on arbitrary problems, uh, like say the task of next work prediction or detecting if there's a cat in a image or something like that. And you want to train this computer. So you want to set its, its weights. And I think there's a number of design criteria that sort of overlap in the transformer simultaneously that made it very successful. And I think the authors were kind of, uh, deliberately trying to, uh, make this really, uh, powerful architecture. And, um, so basically it's very powerful in the forward pass because it's able to express, um, very general computation as sort of something that looks like message passing, uh, you have nodes and they all store vectors and, uh, these nodes get to basically look at each other and it's, uh, each other's vectors and they get to communicate and basically nodes get to broadcast, Hey, I'm looking for certain things. And then other nodes get to broadcast. Hey, these are the things I have. Those are the keys and the values. So it's not just the tension. Yeah, exactly. Transformers much more than just the attention component. It's got many pieces architectural that went into it.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 27:\n",
      "The residual connection of the weights arranged, there's a multi-layer perceptron and they're the weights stacked and so on. Um, but basically there's a message passing scheme where nodes get to look at each other, decide what's interesting and then update each other. And, uh, so I think the, um, when you get to the details of it, I think it's a very expressive function. Uh, so it can express lots of different types of algorithms and forward pass. Not only that, but the way it's designed with the residual connections, layer normalizations, the soft max attention and everything. It's also optimizable. This is a really big deal because there's lots of computers that are powerful that you can't optimize. Um, or they're not easy to optimize using the techniques that we have, which is backpropagation and gradient and sent. These are first order methods, very simple optimizers really. And so, um, you also need it to be optimizable. Um, and then lastly, you want it to run efficiently in our hardware. Our hardware is a massive throughput machine, like GPUs. Uh, they prefer lots of parallelism. So you don't want to do lots of sequential operations. So you want to do a lot of operations serially and the transformer is designed with that in mind as well. And so it's designed for our hardware and it's designed to both be very expressive in a forward pass, but also very optimizable in the backward pass.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 28:\n",
      "And you said that, uh, the residual connections support a kind of ability to learn short algorithms fast and first, and then gradually extend them, uh, longer during training. What's, what's the idea of learning short algorithms? Right. Think of it as a, so basically a transformer is a, uh, series of, uh, blocks, right? And these blocks have attention and a little multilayer perceptual. And so you, you go off into a block and you come back to this residual pathway. And then you go off and you come back and then you have a number of layers arranged sequentially. And so the way to look at it, I think is, uh, because of the residual pathway in the backward pass, the gradients, uh, sort of flow along it uninterrupted because addition, uh, distributes the gradient equally to all of its branches. So the gradient from the supervision at the top, uh, just floats directly to the first layer. And the, all the residual connections are arranged so that in the beginning at during initialization, they contribute nothing to the residual pathway. Um, so what it kind of looks like is imagine the transformer is kind of like a, uh, Python, uh, function, like a death. And, um, you get to do various kinds of like lines of code. Uh, say you have a hundred layers, deep, uh, transformer, typically they would be much shorter, say 20. So if 20 lines of code, then you can do something in them.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 29:\n",
      "And so think of during the optimization, basically what it looks like is first you optimize the first line of code and then the second line of code can kick in and the third line of code can kick in. And I kind of feel like because of the residual pathway and the dynamics of the optimization, uh, you can sort of learn a very short algorithm that gets the approximate answer, but then the other layers can sort of kick in and start to create a contribution. And at the end of it, you're, you're optimizing over an algorithm that is a 20 lines of code. Except these lines of code are very complex because it's an entire block of a transformer. You can do a lot in there. Well, it's really interesting is that this transformer architecture actually has been a remarkably resilient. Basically the transformer that came out in 2016 is the transformer you would use today, except you reshuffle some of the layer norms. Uh, the layer normalizations have been reshuffled to a pre-norm, um, formulation. And so it's been remarkably stable, but there's a lot of bells and whistles that people have attached on it and try to, uh, improve it. I do think that basically it's a, it's a big step in simultaneously optimizing for lots of properties of a desirable neural network architecture. And I think people have been trying to change it, but it's proven remarkably resilient. Um, but I do think that there should be even better architectures potentially. But it's, uh, you're, you admire the resilience here.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 30:\n",
      "Yeah. There's something profound about this architecture that, that least resilient, so maybe we can, everything can be turned into a, uh, into a problem that transformers can solve. Currently definitely looks like the transformer is taking over AI and you can feed basically arbitrary problems into it. And it's a general, the French double computer and it's extremely powerful. And, uh, at this conversions in AI has been, uh, really interesting to watch, uh, for me personally. What else do you think could be discovered here about transformers? Like what's surprising thing or, or is it a stable, um, I want a stable place. Is there something interesting we might discover about transformers? Like aha moments maybe has to do with memory. Um, maybe knowledge representation, that kind of stuff. Definitely does that guys today is just pushing like basically right now, the side guys is do not touch the transformer, touch everything else. Yes. So people are scaling up the data sets, making them much, much bigger. They're working on the evaluation, making the evaluation much, much bigger. And, uh, um, they're basically keeping the architecture unchanged. And that's how we've, um, that's the last five years of progress in AI kind of. What do you think about one flavor of it, which is language models? Have you been surprised? Uh, has your sort of imagination been captivated by you mentioned GPT and all the bigger and bigger and bigger language models.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 31:\n",
      "And, uh, what are the limits of those models do you think? So just for the task of natural language. Basically the way GPT is trained, right. Is you just download a massive amount of text data from the internet and that you try to predict the next word in a sequence, roughly speaking, you're predicting little work chunks, but, uh, roughly speaking, that's it. Um, and what's been really interesting to watch is, uh, basically it's a language model, language models have actually existed for a very long time. Um, there's papers on language modeling from 2003, even earlier. Can you explain that case? What a language model is? Uh, yeah. So language model just, uh, basically the rough idea is, um, just predicting the next word in a sequence, roughly speaking. Uh, so there's a paper from, for example, Ben Geo, uh, and the team from 2003, where for the first time they were using a neural network to take, say like three or five words and predict the, um, next word, and they're doing this on much smaller datasets and the neural net is not a transformer, it's a multi-layer perceptron, but it's the first time that a neural network has been applied in that setting, but even before neural networks, there were, um, language models, except they were using, um, Ngram models. So Ngram models are just, uh, count based models.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 32:\n",
      "So, um, if you try to, if you start to take two words and predict the third one, you just count up how many times you've seen any, uh, two word combinations and what came next and what you predict as coming next is just what you've seen the most of in the training set. And so, uh, language modeling has been around for a long time. Neural networks have done language modeling for a long time. So really what's new or interesting or exciting is just realizing that when you scale it up, uh, with a powerful enough neural net, a transformer, you have all these emergent properties where, uh, basically what happens is if you have a large enough dataset of text, you are in the task of predicting the next word. You are multitasking a huge amount of different kinds of problems. You are multitasking, understanding of, you know, chemistry, physics, human nature, lots of things are sort of clustered in that objective. It's a very simple objective, but actually you have to understand a lot about the world to make that prediction. You just said the U word understanding, uh, are you in terms of chemistry and physics and so on, what do you feel like it's doing? Is it searching for the right context? Uh, in, in like, what is it, what is the actual process happening here? Yeah.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 33:\n",
      "So basically it gets a thousand words and it's trying to predict the thousand and first, and, uh, in order to do that very, very well over the entire dataset available on the internet, you actually have to basically kind of understand the context of, of what's going on in there. Yeah. Um, and, uh, it's a sufficiently hard problem that you, uh, if you have a powerful enough computer, like a transformer, you end up with a interesting solutions and, uh, you can ask it to do all kinds of things and, um, it, it shows a lot of, uh, emergent properties, like in context learning. That was the big deal with GPT and the original paper when they published it is that you can just sort of, uh, prompt it in various ways and ask it to do various things and it will just kind of complete the sentence, but in the process of just completing the sentence, it's actually solving all kinds of really, uh, interesting problems that we care about. Do you think it's doing something like understanding? Like when we use the word understanding for us humans, I think it's doing some understanding in its weights, it understands, I think a lot about the world and it has to, in order to predict the next word in the sequence. So it's trained on the data from the internet. Uh, what do you think about this, this approach in terms of data sets of using data from the internet? Do you think the internet has enough structured data to teach AI about human civilization? Yes.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 34:\n",
      "So I think the internet has a huge amount of data. I'm not sure if it's a complete enough set. I don't know that, uh, text is enough for having a sufficiently powerful AGI as an outcome. Um, of course there is audio and video and images and all that. Yeah. Kind of stuff. Yeah. So text by itself, I'm a little bit suspicious about. There's a ton of things we don't put in text in writing, uh, just because they're obvious to us about how the world works and the physics of it. And that things fall, we don't put that stuff in text because why would you, we share that understanding. And so text is a communication medium between humans and it's not a, uh, all encompassing medium of knowledge about the world, but as you pointed out, we do have video and we have images and we have audio. And so I think that, uh, that definitely helps a lot, but we haven't trained models, uh, sufficiently, uh, across both across all of those modalities yet. Uh, so I think that's what a lot of people are interested in. But I wonder what that shared understanding of like what we might call common sense has to be learned, inferred in order to complete the sentence correctly. So maybe the fact that it's implied on the internet, the model is going to have to learn that not by reading about it, by inferring it in the representation. So like common sense, just like we, I don't think we learn common sense. Like nobody says, tells us explicitly. We just figure it all out by interacting with the world.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 35:\n",
      "And so here's a model of reading about the way people interact with the world. It might have to infer that. I wonder, uh, you, you briefly worked on a project called the world of bits, training and RRL system to take actions on the internet, um, versus just consuming the internet, like we talked about. Do you think there's a future for that kind of system interacting with the internet to help the learning? Yes. I think that's probably the, uh, the final frontier for a lot of these models, uh, because, um, so as you mentioned, when I was at open AI, I was working on this project for a little bit. And basically it was the idea of giving neural networks access to a keyboard and a mouse and the idea possibly go wrong. So basically you, um, you perceive the input of the, uh, screen pixels. And, uh, basically the state of the computer is sort of visualized, uh, for human consumption in images of the web browser and stuff like that. And then you give them your own or the ability to press keyboards and use the mouse and we're trying to get it to, for example, complete bookings and, you know, interact with user interfaces. And, um, what'd you learn from that experience? Like, what was some fun stuff? This is a super cool idea. Yeah. I mean, it's like, uh, yeah, I mean, the, the step between observer to actor is a super fascinating step. Yeah. Well, it's the universal interface in the digital realm, I would say.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 36:\n",
      "And, uh, there's a universal interface in like the physical realm, which in my mind is a humanoid form factor kind of thing. Uh, we can later talk about optimists and so on, but I feel like there's a, uh, they're kind of like a similar philosophy in some way where the human, the world, the physical world is designed for the human form and the digital world is designed for the human form of seeing the screen and using keyword, not keyboard and mouse. And so it's the universal interface that can basically, uh, command the digital infrastructure we've built up for ourselves. And so it feels like a very powerful interface to, to command and to build on top of, uh, now to your question as to like what I learned from that, it's interesting because the world of bits was basically too early, I think at open AI at the time, um, this is around 2015 or so, and the zeitgeist at that time was very different in AI from the zeitgeist today at the time, everyone was super excited about reinforcement learning from scratch. Uh, this is the time of the Atari paper, uh, where, uh, neural networks were playing Atari games, um, and beating humans in some cases, uh, AlphaGo and so on. So everyone's very excited about training neural networks from scratch using reinforcement learning, um, directly.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 37:\n",
      "It turns out that reinforcement learning is extremely inefficient way of training neural networks because you're taking all these actions and all these observations and you get some sparse rewards once in a while. So you do all this stuff based on all these inputs and once in a while, you're like told you did a good thing, you did a bad thing. And it's just an extremely hard problem. You can't learn from that. Uh, you can burn a forest and you can sort of brute force through it. And we saw that I think with, uh, you know, with, uh, go and Dota and so on and does work. Uh, but it's extremely inefficient, uh, and, uh, not how you want to approach problems, uh, practically speaking. And so that's the approach that at the time we also took to world of bits. Uh, we would, uh, have an agent initialize randomly. So with keyboard mash and mouse mash and try to make a booking. And it's just like revealed the insanity of that approach very quickly, where you have to stumble by the correct booking in order to get a reward of you did it correctly and you're never going to stumble by it by chance at random. So even with a simple web interface, there's too many options. There's just too many options. Uh, and, uh, it's too sparse of a reward signal and you're starting from scratch at the time. And so you don't know how to read. You don't understand pictures, images, buttons.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 38:\n",
      "You don't understand what it means to like make a booking, but now what's happened is, uh, it is time to revisit that and open AI is interested in this. Uh, companies like adept are interested in this and so on. And, uh, the idea is coming back, uh, because the interface is very powerful, but now you're not training an agent from scratch. You are taking the GPT as an initialization. So GPT is pre-trained on all of. Text and it understands what's a booking. It understands what's a submit. It understands, um, quite a bit more. And so it already has those representations. They are very powerful. And that makes all the training significantly more efficient, um, and makes the problem tractable. Should the interaction be with like the way humans see it with the buttons and the language, or should be with the HTML, JavaScript and the CSS? What's, what do you think is the better? Uh, so today all of this interaction is mostly on the level of HTML, CSS, and so on that's done because of computational constraints. Uh, but I think ultimately, um, uh, everything is designed for human visual consumption and so at the end of the day, there's all the additional information is in the layout of the webpage and what's next to you and what's a red background and all this kind of stuff and what it looks like visually. So I think that's the final frontier as we are taking in a pixels and we're giving out keyboard mouse commands. Uh, but I think it's impractical still today.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 39:\n",
      "Do you worry about bots on the internet? Given, given these ideas, given how exciting they are, do you worry about bots on Twitter being not the stupid boss that we see now with the crypto bots, but the bots that might be out there actually that we don't see that they're interacting in interesting ways. So this kind of system feels like it should be able to pass the, I'm not a robot click button, whatever. Um, which does she understand how that test works? I don't quite like, uh, there's, there's a, there's a checkbox or whatever that you click is presumably tracking like mouse movement and the timing and so on. So exactly this kind of system we're talking about should be able to pass that. So w yeah, what do you feel about, um, bots that are language models plus have some interact ability and are able to tweet and reply and so on, do you worry about that world? Uh, yeah, I think it's always been a bit of an arms race, uh, between sort of the attack and the defense. Uh, so the attack will get stronger, but the defense will get stronger as well. Uh, our ability to detect that. How do you defend, how do you detect, how do you know that your Carpati account on Twitter is, is human? How would you approach that? Like if people were claimed, you know, uh, how would you defend yourself in the court of law that I'm a human?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 40:\n",
      "Um, this account is, yeah, at some point, I think, uh, it might be, I think the society, the society will evolve a little bit, like we might start signing digitally, signing, uh, some of our correspondence or, you know, things that we create, uh, right now it's not necessary, but maybe in the future it might be, I do think that we are going towards a world where we share, we share the digital space with, uh, AIs. Synthetic beings. Yeah. And, uh, they will get much better and they will share our digital realm and they'll eventually share our physical realm as well. It's much harder. Uh, but that's kind of like the world we're going towards and most of them will be benign and awful and some of them will be malicious and it's going to be an arms race trying to detect them. So, I mean, the worst isn't the AIs. The worst is the AIs pretending to be human. So mine, I don't know if it's always malicious. There's obviously a lot of malicious applications, but it could also be, you know, if I was an AI, I would try very hard to pretend to be human because we're in a human world. I wouldn't get any respect as an AI. I want to get some love and respect. I don't think the problem is intractable. People are, people are thinking about the proof of personhood and, uh, we might start digitally signing our stuff and we might all end up having like, uh, yeah, basically some, some solution for proof of personhood. It doesn't seem to me intractable.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 41:\n",
      "It's just something that we haven't had to do until now, but I think once the need like really starts to emerge, which is soon, I think people will think about it much more. So, but that too will be a race because, um, obviously you can probably, uh, spoof or fake the, the, the proof of, uh, personhood. So you have to try to figure out how to, I mean, it's weird that we have like social security numbers and like passports and stuff. It seems like it's harder to fake stuff in the physical space. In the digital space, it just feels like it's going to be very tricky, very tricky to out, um, cause it seems to be pretty low cost to fake stuff. What are you going to put an AI in jail for like trying to use a fake, uh, fake personhood proof? You can, I mean, okay, fine. You'll put a lot of AIs in jail, but there'll be more as arbitrary, like exponentially more the cost of creating a bot is very low. Unless there's some kind of way to track accurately, like you're not allowed to create any program without showing, uh, tying yourself to that program. Like you, any program that runs on the internet, you'll be able to, uh, trace every single human program and those involved with that program.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 42:\n",
      "Yeah, maybe you have to start declaring when, uh, you know, we have to start drawing those boundaries and keeping track of, okay, uh, what are digital entities versus human entities and, uh, what is the ownership of human entities and digital entities and, uh, something like that, um, I don't know, but I'm, I think I'm optimistic that this is, uh, this is, uh, possible and it's some, in some sense, we're currently in like the worst time of it because, um, all these bots suddenly have become very capable, uh, but we don't have the fences yet built up as a society and, but I think, uh, that doesn't seem to me intractable. It's just something that we have to deal with. It seems weird that the Twitter bot, like really crappy Twitter bots are so numerous, like is it, so I presume that the engineers at Twitter are very good. So it seems like what I would infer from that, uh, is it seems like a hard problem. It, they're probably catching, right. If I were to sort of steal man, the case, it's a hard problem and there's a huge cost to, uh, false positive to, to removing a post by somebody that's not a bot that creates a very bad user experience. So they're very cautious about removing. So maybe it's, um, and maybe the bots are really good at learning what gets removed and not such that they can stay ahead of the removal process very quickly. My impression of it honestly is, uh, there's a lot of loaning fruit. I mean, yeah, just that's what I, it's not subtle. My impression of it.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 43:\n",
      "It's not subtle, but you have to, yeah, that's my impression as well, but it feels like maybe you're seeing the, the tip of the iceberg, maybe the number of bots isn't like the trillions and you have to like, yeah, just, it's a constant assault of bots and you, yeah, I don't know, um, you have to steal man in the case, cause the bots I'm seeing are pretty like obvious. I could write a few lines of code that catch these spots. I mean, definitely there's a lot of loaning fruit, but I will say, I agree that if you are a sophisticated actor, you could probably create a pretty good bot right now, um, you know, using tools like GPTs, uh, because it's a language model, you can generate faces that look quite good now, uh, and you can do this at scale. And so I think, um, yeah, it's quite plausible and it's going to be hard to defend. There was a Google engineer that claimed that, uh, Lambda was sentient. Do you think there's any inkling of truth to what he felt? And more importantly, to me, at least, do you think language models will achieve sentience or the illusion of sentience soonish? Yeah, to me, it's a little bit of a canary in a coal mine kind of moment, honestly, a little bit, uh, because, uh, so this engineer spoke to like a chat bot at Google and, uh, became convinced that, uh, this bot is sentient. He asked us some existential philosophical questions and gave like reasonable answers and looked real and, uh, and so on.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 44:\n",
      "Uh, so to me, it's a, uh, he was, he was, uh, he wasn't sufficiently trying to stress the system, I think, and, uh, exposing the truth of it as it is today. Um, but, uh, I think this will be increasingly harder over time. Uh, so, uh, yeah, I think more and more people will basically, uh, become, um, yeah, I think more and more, there'll be more people like that over time. As, as this gets better, like form an emotional connection to an AI. Plausible in my mind. I think these AIs are actually quite good at human, human connection, human emotion, a ton of text on the internet is about humans and connection and love and so on, so I think they have a very good understanding in some, in some sense of, of how people speak to each other about this and, um, they're very capable of creating a lot of that kind of text. The, um, there's a lot of like sci-fi from fifties and sixties that imagined AIs in a very different way. They are calculating cold Vulcan like machines. That's not what we're getting today. We're getting pretty emotional AIs that actually, uh, are very competent and capable of generating, you know, plausible sounding text with respect to all of these topics. See, I'm really hopeful about AI systems that are like companions that help you grow, develop as a human being, uh, help you maximize long-term happiness. But I'm also very worried about AI systems that figure out from the internet, the humans get attracted to drama. And so these would just be like shit talking AIs.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 45:\n",
      "They just constantly, did you hear it? Like they'll do gossip. They'll do, uh, they'll try to plant seeds of suspicion to other humans that you love and trust and, uh, just kind of mess with people, uh, in the, you know, cause, cause that's going to get a lot of attention to drama, maximize drama on the path to maximizing, uh, engagement and us humans will feed into that machine and get, it'll be a giant drama shit storm. Uh, so I'm worried about that. So it's the objective function really defines the way that human civilization progresses with AIs in it. I think right now, at least today, they are not sort of, it's not correct to really think of them as goal seeking agents that want to do something. They have no long-term memory or anything. They it's literally a good approximation of it is you get a thousand words and you're trying to predict a thousand at first, and then you continue feeding it in and you are free to prompt it in whatever way you want. So in text, so you say, okay, you are a psychologist and you are very good and you love humans and here's a conversation between you and another human. Human colon, something you something, and then it just continues the pattern. And suddenly you're having a conversation with a fake psychologist who's like trying to help you.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 46:\n",
      "And so it's still kind of like in a realm of a tool is a, um, people can prompt it in arbitrary ways and it can create really incredible text, but it doesn't have long-term goals over long periods of time. It doesn't try to, uh, so it doesn't look that way right now. Yeah, but you can do short-term goals that have long-term effects. So if my prompting short-term goal is to get Andre Capati to respond to me on Twitter, whenever, like I think AI might that's the goal, but it might figure out that talking shit to you, it would be the best in a highly sophisticated, interesting way. And then you build up a relationship when you were spelling once and then it like over time it gets to not be sophisticated and just like just talk shit. And okay, maybe you won't get to Andre, but it might get to another celebrity, it might get into other big accounts and then it'll just, so with just that simple goal, get them to respond, maximize the probability of actual response. Yeah. I mean, you could prompt a powerful model like this with their, it's opinion about how to do any possible thing you're interested in. So they will just, they're kind of on track to become these oracles. I could sort of think of it that way. They are oracles. Currently it's just text, but they will have calculators. They will have access to Google search. They will have all kinds of gadgets and gizmos. They will be able to operate the internet and find different information.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 47:\n",
      "And yeah, in some sense, that's kind of like currently what it looks like in terms of the development. Do you think it'll be an improvement eventually over what Google is for access to human knowledge? Like it'll be a more effective search engine to access human knowledge. I think there's definite scope in building a better search engine today. And I think Google, they have all the tools, all the people, they have everything they need, they have all the puzzle pieces, they have people training transformers at scale, they have all the data. It's just not obvious if they are capable as an organization to innovate on their search engine right now. And if they don't, someone else will. There's absolute scope for building a significantly better search engine built on these tools. It's so interesting. A large company where the search, there's already an infrastructure. It works as brings out a lot of money. So where structurally inside a company is their motivation to pivot? To say, we're going to build a new search engine. Yeah, that's hard. So it's usually going to come from a startup, right? That's that would be, yeah. Or some other more competent organization. So I don't know. So currently, for example, maybe Bing has another shot at it. You know, as an example. Microsoft Edge, we're talking offline. I mean, it definitely is really interesting because search engines used to be about, OK, here's some query. Here's here's here's web pages that look like the stuff that you have.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 48:\n",
      "But you could just directly go to answer and then have supporting evidence. And these these models, basically, they've read all the text and they've read all the web pages. And so sometimes when you see yourself going over to search results and sort of getting like a sense of like the average answer to whatever you're interested in, like that just directly comes out. You don't have to do that work. So they're kind of like. Yeah, I think they have a way to this of distilling all that knowledge into. Like some level of insight, basically. Do you think of prompting as a kind of teaching and learning like this whole process, like another layer? You know, because maybe that's what humans are. We already have that background model and you're the world is prompting you. Yeah, exactly. I think the way we are programming these models is that we're trying to make it like computers now like GPT's is converging to how you program humans. I mean, how do I program humans via prompt? I go to people and I prompt them to do things. I prompt them from information. And so natural language prompt is how we program humans. And we're starting to program computers directly in that interface. It's like pretty remarkable, honestly. So you've spoken a lot about the idea of software 2.0. All good ideas become like cliches so quickly, like the terms. It's kind of hilarious.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 49:\n",
      "It's like I think Eminem once said that like if he gets annoyed by a song he's written very quickly, that means it's going to be a big hit because it's too catchy. But can you describe this idea and how you're thinking about it has evolved over the months and years since since you coined it? Yeah. Yes, I had a blog post on software 2.0, I think several years ago now. And the reason I wrote that post is because I kept I kind of saw something remarkable happening in like software development and how a lot of code was being transitioned to be written not in sort of like C++ and so on, but it's written in the weights of a neural net, basically just saying that neural nets are taking over software, the realm of software and taking more and more tasks. And at the time, I think not many people understood this deeply enough that this is a big deal. It's a big transition. Neural networks were seen as one of multiple classification algorithms you might use for your data set problem on Kaggle. Like this is not that this is a change in how we program computers. And I saw neural nets as this is going to take over. The way we program computers is going to change. It's not going to be people writing software in C++ or something like that and directly programming the software. It's going to be accumulating training sets and data sets and crafting these objectives by which you train these neural nets.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 50:\n",
      "And at some point, there's going to be a compilation process from the data sets and the objective and the architecture specification into the binary, which is really just the neural net weights and the forward pass of the neural net. And then you can deploy that binary. And so I was talking about that sort of transition and that's what the post is about. And I saw this sort of play out in a lot of fields, autopilot being one of them, but also just simple image classification. People thought originally, you know, in the 80s and so on that they would write the algorithm for detecting a dog in an image. And they had all these ideas about how the brain does it. And first we detect corners and then we detect lines and then we stitch them up. And they were like really going at it. They were like thinking about how they're going to write the algorithm. And this is not the way you build it. And there was a smooth transition where, OK, first we thought we were going to build everything. Then we were building the features. So like hog features and things like that that detect these little statistical patterns from image patches. And then there was a little bit of learning on top of it, like a support vector machine or binary classifier for cat versus dog and images on top of the features. So we wrote the features, but we trained the last layer, sort of the classifier. And then people are like, actually, let's not even design the features because we can't.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 51:\n",
      "Honestly, we're not very good at it. So let's also learn the features. And then you end up with basically a convolutional neural net where you're learning most of it. You're just specifying the architecture and the architecture has tons of fill in the blanks, which is all the knobs, and you let the optimization write most of it. And so this transition is happening across the industry everywhere. And suddenly we end up with a ton of code that is written in neural net weights. And I was just pointing out that the analogy is actually pretty strong. And we have a lot of developer environments for software 1.0, like we have IDEs, how you work with code, how you debug code, how you run code, how do you maintain code? We have GitHub. So I was trying to make those analogies in the new realm. Like, what is the GitHub of software 2.0? Turns out it's something that looks like hugging face right now. You know, and so I think some people took it seriously and built cool companies. And many people originally attacked the post. It actually was not well received when I wrote it. And I think maybe it has something to do with the title, but the post was not well received. And I think more people sort of have been coming around to it over time. Yeah. So you were the director of AI at Tesla where I think this idea was really implemented at scale, which is how you have engineering teams doing software 2.0.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 52:\n",
      "So can you sort of linger on that idea of, I think we're in the really early stages of everything you just said, which is like GitHub IDEs. Like how do we build engineering teams that that work in software 2.0 systems and the data collection and the data annotation, which is all part of that software 2.0. Like, what do you think is the task of programming in software 2.0? Is it debugging in the space of hyperparameters or is it also debugging in the space of data? Yeah. The way by which you program the computer and influence its algorithm is not by writing the commands yourself. You're changing mostly the data set. You're changing the loss functions of like what the neural net is trying to do, how it's trying to predict things. But basically the data sets and the architecture of the neural net. And so in the case of the autopilot, a lot of the data sets have to do with, for example, detection of objects and lane line markings and traffic lights and so on. So you accumulate massive data sets of here's an example, here's the desired label, and then here's roughly how the architect, here's roughly what the algorithm should look like. And that's a convolutional neural net. So the specification of the architecture is like a hint as to what the algorithm should roughly look like. And then the fill in the blanks process of optimization is the training process. And then you take your neural net that was trained, it gives all the right answers on your data set and you deploy it.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 53:\n",
      "So there is in that case, perhaps at all machine learning cases, there's a lot of tasks. So is coming up, formulating a task like for a multi-headed neural network is formulating a task part of the programming? Yeah, very much so. How you break down a problem into a set of tasks. Yeah. I'm on a high level, I would say, if you look at the software running in the autopilot, I gave a number of talks on this topic. I would say originally a lot of it was written in software 1.0. There's imagine lots of C++, right? And then gradually there was a tiny neural net that was, for example, predicting, given a single image, is there like a traffic light or not? Or is there a landline marking or not? And this neural net didn't have too much to do in the scope of the software. It was making tiny predictions on individual little image. And then the rest of the system stitched it up. So, okay, we're actually, we don't have just a single camera, we have eight cameras. We actually have eight cameras over time. And so what do you do with these predictions? How do you put them together? How do you do the fusion of all that information? And how do you act on it? All of that was written by humans in C++. And then we decided, okay, we don't actually want to do all of that fusion in C++ code because we're actually not good enough to write that algorithm. We want the neural nets to write the algorithm and we want to port all of that software into the 2.0 stack.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 54:\n",
      "And so then we actually had neural nets that now take all the eight camera images simultaneously and make predictions for all of that. And actually they don't make predictions in the space of images, they now make predictions directly in 3D. And actually they don't in three dimensions around the car. And now actually we don't manually fuse the predictions in 3D over time. We don't trust ourselves to write that tracker. So actually we give the neural net the information over time. So it takes these videos now and makes those predictions. And so you're sort of just like putting more and more power into the neural net, more processing. And at the end of it, the eventual goal is to have most of the software potentially be in the 2.0 land because it works significantly better. Humans are just not very good at writing software basically. So the prediction is happening in this 4D land with three dimensional world over time. How do you do annotation in that world? So data annotation, whether it's self-supervised or manual by humans is a big part of the software 2.0 world. Right. I would say by far in the industry, if you're talking about the industry and what is the technology of what we have available, everything is supervised learning. So you need data sets of input, desired output, and you need lots of it. And there are three properties of it that you need. You need it to be very large, you need it to be accurate, no mistakes, and you need it to be diverse.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 55:\n",
      "You don't want to just have a lot of correct examples of one thing. You need to really cover the space of possibility as much as you can. And the more you can cover the space of possible inputs, the better the algorithm will work at the end. Now, once you have really good data sets that you're collecting, curating, and cleaning, you can train your neural net on top of that. So a lot of the work goes into cleaning those data sets. Now, as you pointed out, it could be the question is, how do you achieve a ton of... If you want to basically predict in 3D, you need data in 3D to back that up. So in this video, we have eight videos coming from all the cameras of the system. And this is what they saw. And this is the truth of what actually was around. There was this car, there was this car, this car. These are the lane line markings. This is the geometry of the road. There was traffic light in this three-dimensional position. You need the ground truth. And so the big question that the team was solving, of course, is how do you arrive at that ground truth? Because once you have a million of it, and it's large, clean, and diverse, then training a neural net on it works extremely well. And you can ship that into the car. And so there's many mechanisms by which we collected that training data. You can always go for human annotation. You can go for simulation as a source of ground truth.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 56:\n",
      "You can also go for what we call the offline tracker that we've spoken about at the AI day and so on, which is basically an automatic reconstruction process for taking those videos and recovering the three-dimensional reality of what was around that car. So basically think of doing a three-dimensional reconstruction as an offline thing, and then understanding that, okay, there's 10 seconds of video. This is what we saw. And therefore, here's all the lane lines, cars, and so on. And then once you have that annotation, you can train your neural net to imitate it. And how difficult is the three-D reconstruction? It's difficult, but it can be done. So there's overlap between the cameras and you do the reconstruction. And there's perhaps if there's any inaccuracy, so that's caught in the annotation step. Yes. The nice thing about the annotation is that it is fully offline. You have infinite time. You have a chunk of one minute and you're trying to just offline in a supercomputer somewhere, figure out where were the positions of all the cars, all the people, and you have your full one minute of video from all the angles. And you can run all the neural nets you want, and they can be very efficient, massive neural nets. There can be neural nets that can't even run in the car later at test time. So they can be even more powerful neural nets than what you can eventually deploy.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 57:\n",
      "So you can do anything you want, three-dimensional reconstruction, neural nets, anything you want just to recover that truth, and then you supervise that truth. What have you learned? You said no mistakes about humans doing annotation because I assume humans are... There's like a range of things they're good at in terms of clicking stuff on screen. Isn't that... How interesting is that to you of a problem of designing an annotator where humans are accurate, enjoy it? What are even the metrics? Are efficient or productive, all that kind of stuff? Yeah. So I grew the annotation team at Tesla from basically zero to a thousand while I was there. That was really interesting. My background is a PhD student researcher, so growing that kind of an organization was pretty crazy. But yeah, I think it's extremely interesting and part of the design process very much behind the autopilot as to where you use humans. Humans are very good at certain kinds of annotations. They're very good, for example, at two-dimensional annotations of images. They're not good at annotating cars over time in three-dimensional space, very, very hard. And so that's why we're very careful to design the tasks that are easy to do for humans versus things that should be left to the offline tracker. Like maybe the computer will do all the triangulation and 3D reconstruction, but the human will say exactly these pixels of the image are a car, exactly these pixels are human.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 58:\n",
      "And so co-designing the data annotation pipeline was very much bread and butter, was what I was doing daily. Do you think there's still a lot of open problems in that space? Just in general, annotation where the stuff the machines are good at, machines do and the humans do what they're good at, and there's maybe some iterative process. Right. I think to a very large extent, we went through a number of iterations and we learned a ton about how to create these data sets. I'm not seeing big open problems. Originally when I joined, I was really not sure how this would turn out. But by the time I left, I was much more secure and understand the philosophy of how to create these data sets. And I was pretty comfortable with where that was at the time. So what are strengths and limitations of cameras for the driving task in your understanding when you formulate the driving task as a vision task with eight cameras? You've seen that the entire, most of the history of the computer vision field, when it has to do with neural networks, just if you step back, what are the strengths and limitations of pixels, of using pixels to drive? Yeah. Pixels I think are a beautiful sensor, beautiful sensor, I would say. The thing is like cameras are very, very cheap and they provide a ton of information, ton of bits. Also it's extremely cheap sensor for a ton of bits. And each one of these bits is a constraint on the state of the world. And so you get lots of megapixel images, very cheap.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 59:\n",
      "And it just gives you all these constraints for understanding what's actually out there in the world. So vision is probably the highest bandwidth sensor. It's a very high bandwidth sensor. I love that pixels is a constraint on the world. It's this highly complex, high bandwidth constraint on the state of the world. And it's not just that, but again, this real importance of it's the sensor that humans use. Therefore, everything is designed for that sensor. The text, the writing, the flashing signs, everything is designed for vision. And so you just find it everywhere. And so that's why that is the interface you want to be in, talking again about these universal interfaces. And that's where we actually want to measure the world as well and then develop software for that sensor. But there's other constraints on the state of the world that humans use to understand the world. I mean, vision ultimately is the main one, but we're referencing our understanding of human behavior and some common sense physics that could be inferred from vision from a perception perspective. But it feels like we're using some kind of reasoning to predict the world, not just the pixels. I mean, you have a powerful prior service for how the world evolves over time, et cetera. So it's not just about the likelihood term coming up from the data itself telling you about what you are observing, but also the prior term of where are the likely things to see and how do they likely move and so on.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 60:\n",
      "And the question is how complex is the range of possibilities that might happen in the driving task? Is that to you still an open problem of how difficult is driving, like philosophically speaking? All the time you worked on driving, do you understand how hard driving is? Yeah, driving is really hard because it has to do with the predictions of all these other agents and the theory of mind and what they're going to do and are they looking at you? Where are they looking? Where are they thinking? There's a lot that goes there at the full tail of the expansion of the knives that we have to be comfortable with eventually. The final problems are of that form. I don't think those are the problems that are very common. I think eventually they're important, but it's really in the tail end. In the tail end, the rare edge cases. From the vision perspective, what are the toughest parts of the vision problem of driving? Well, basically the sensor is extremely powerful, but you still need to process that information. And so going from brightnesses of these special values to, hey, here are the three-dimensional world is extremely hard. And that's what the neural networks are fundamentally doing. And so the difficulty really is in just doing an extremely good job of engineering the entire pipeline, the entire data engine, having the capacity to train these neural nets, having the ability to evaluate the system and iterate on it.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 61:\n",
      "So I would say just doing this in production at scale is like the hard part. It's an execution problem. So the data engine, but also the deployment of the system such that it has low latency performance. So it has to do all these steps. Yeah, for the neural net specifically, just making sure everything fits into the chip on the car. And you have a finite budget of flops that you can perform and memory bandwidth and other constraints. And you have to make sure it flies and you can squeeze in as much computer as you can into the tiny. What have you learned from that process? Because maybe that's one of the bigger, like new things coming from a research background where there's a system that has to run under heavily constrained resources, has to run really fast. What kind of insights have you learned from that? Yeah, I'm not sure if there's too many insights. You're trying to create a neural net that will fit in what you have available and you're always trying to optimize it. And we talked a lot about it on the AI day and basically the triple backflips that the team is doing to make sure it all fits and utilizes the engine. So I think it's extremely good engineering. And then there's all kinds of little insights peppered in on how to do it properly. Let's actually zoom out because I don't think we talked about the data engine, the entirety of the layouts of this idea that I think is just beautiful with humans in the loop. Can you describe the data engine?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 62:\n",
      "Yeah, the data engine is what I call the almost biological feeling like process by which you perfect the training sets for these neural networks. So because most of the programming now is in the level of these data sets and make sure they're large, diverse and clean. Basically, you have a data set that you think is good. You train your neural net, you deploy it, and then you observe how well it's performing. And you're trying to always increase the quality of your data set. So you're trying to catch scenarios basically that are basically rare. And it is in these scenarios that the neural nets will typically struggle in because they weren't told what to do in those rare cases in the data set. But now you can close the loop because if you can now collect all those at scale, you can then feed them back into the reconstruction process I described and reconstruct the truth in those cases and add it to the data set. And so the whole thing ends up being like a staircase of improvement of perfecting your training set. And you have to go through deployments so that you can mine the parts that are not yet represented well in the data set. So your data set is basically imperfect. It needs to be diverse. It has pockets that are missing and you need to pad out the pockets. You can sort of think of it that way in the data. What role do humans play in this? So what's this biological system? Like are human bodies made up of cells? What role, like how do you optimize the human system?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 63:\n",
      "The multiple engineers collaborating, figuring out what to focus on, what to contribute, which task to optimize in this neural network. Who is in charge of figuring out which task needs more data? Can you speak to the hyperparameters of the human system? It really just comes down to extremely good execution from an engineering team who knows what they're doing. They understand intuitively the philosophical insights underlying the data engine and the process by which the system improves and how to again, delegate the strategy of the data collection and how that works and then just making sure it's all extremely well executed. And that's where most of the work is not even the philosophizing or the research or the ideas of it. It's just extremely good execution. It's so hard when you're dealing with data at that scale. So your role in the data engine executing well on it is difficult and extremely important. Is there a priority of like a vision board of saying like, we really need to get better at stoplights? Yeah. Like the prioritization of tasks. Is that essentially, and that comes from the data? That comes to a very large extent to what we are trying to achieve in the product for a map or the release we're trying to get out in the feedback from the QA team where the system is struggling or not, the things we're trying to improve. And the QA team gives some signal, some information in aggregate about the performance of the system in various conditions. That's right.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 64:\n",
      "And then of course, all of us drive it and we can also see it. It's really nice to work with a system that you can also experience yourself and it drives you home. Is there some insight you can draw from your individual experience that you just can't quite get from an aggregate statistical analysis of data? Yeah. It's so weird, right? Yes. It's not scientific in a sense because you're just one anecdotal sample. Yeah. I think there's a ton of, it's a source of truth. It's your interaction with the system and you can see it, you can play with it, you can perturb it, you can get a sense of it, you have an intuition for it. I think numbers just like have a way of, numbers and plots and graphs are much harder. It hides a lot of- It's like if you train a language model, it's a really powerful way is by you interacting with it. Yeah, 100%. Try to build up an intuition. Yeah. I think like Ilan also, he always wanted to drive the system himself. He drives a lot and I want to say almost daily. So he also sees this as a source of truth, you driving the system and it performing and yeah. So what do you think? Tough questions here. So Tesla last year removed radar from the sensor suite and now just announced that it's going to remove ultrasonic sensors relying solely on vision, so camera only. Does that make the perception problem harder or easier? I would almost reframe the question in some way.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 65:\n",
      "So the thing is basically, you would think that additional sensors- By the way, can I just interrupt? Go ahead. I wonder if a language model will ever do that if you prompt it. Let me reframe your question. That would be epic. That's the wrong prompt. Sorry. It's like a little bit of a wrong question because basically you would think that these sensors are an asset to you. Yeah. But if you fully consider the entire product in its entirety, these sensors are actually potentially liability because these sensors aren't free. They don't just appear on your car. You need suddenly you need to have an entire supply chain. You have people procuring it. There can be problems with them. They may need replacement. They are part of the manufacturing process. They can hold back the line in production. You need to source them. You need to maintain them. You have to have teams that write the firmware, all of it. And then you also have to incorporate them, fuse them into the system in some way. And so it actually like bloats a lot of it. And I think Elon is really good at simplify, simplify. Best part is no part. And he always tries to throw away things that are not essential because he understands the entropy in organizations and in the approach. And I think in this case, the cost is high and you're not potentially seeing it if you're just a computer vision engineer. And I'm just trying to improve my network and is it more useful or less useful? How useful is it?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 66:\n",
      "And the thing is once you consider the full cost of a sensor, it actually is potentially a liability. And you need to be really sure that it's giving you extremely useful information. In this case, we looked at using it or not using it and the Delta was not massive. And so it's not useful. Is it also bloat in the data engine? Like having more sensors? Is it distraction? And these sensors, you know, they can change over time. For example, you can have one type of say radar, you can have other type of radar. They change over time. Now you suddenly need to worry about it. Now suddenly you have a column in your SQLite telling you, oh, what sensor type was it? And they all have different distributions. And then they can, they just, they contribute noise and entropy into everything. And they bloat stuff. And also organizationally has been really fascinating to me that it can be very distracting. If you, if all, if you only want to get to work is vision, all the resources are on it and you're building out a data engine and you're actually making forward progress because that is the sensor with the most bandwidth, the most constraints in the world. And you're investing fully into that. And you can make that extremely good. If you're, you're only a finite amount of sort of spend of focus across different facets of the system. And this kind of reminds me of Rich Sutton's, the bitter lesson. It just seems like simplifying the system. Yeah. In the long run.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 67:\n",
      "And of course, you don't know what the long run is. It seems to be always the right solution. Yeah. Yes. In that case, it was for RL, but it seems to apply generally across all systems that do computation. Yeah. So where, what do you think about the lidar as a crutch debate? The battle between point clouds and pixels. Yeah. I think this debate is always like slightly confusing to me because it seems like the actual debate should be about like, do you have the fleet or not? That's like the really important thing about whether you can achieve a really good functioning of an AI system at this scale. So data collection systems. Yeah. Do you have a fleet or not is significantly more important, whether you have lidar or not. It's just another sensor. And yeah, I think similar to the radar discussion, basically, I don't think it basically doesn't offer extra information. It's extremely costly. It has all kinds of problems. You have to worry about it. You have to calibrate it, et cetera. It creates bloat and entropy. You have to be really sure that you need this sensor. In this case, I basically don't think you need it. And I think honestly, I will make a stronger statement. I think the others, some of the other companies that are using it are probably going to drop it. Yeah. So you have to consider the sensor in the full, in considering, can you build a big fleet that collects a lot of data?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 68:\n",
      "And can you integrate that sensor with that data and that sensor into a data engine that's able to quickly find different parts of the data that then continuously improves whatever the model that you're using? Yeah. Another way to look at it is like vision is necessary in the sense that the world is designed for human visual consumption. So you need vision. It's necessary. And then also it is sufficient because it has all the information that you need for driving and humans obviously has vision to drive. So it's both necessary and sufficient. So you want to focus resources and you have to be really sure if you're going to bring in other sensors. You could add sensors to infinity. At some point, you need to draw the line. And I think in this case, you have to really consider the full cost of any one sensor. That you're adopting and do you really need it? And I think the answer in this case is no. So what do you think about the idea that the other companies are forming high resolution maps and constraining heavily the geographic regions in which they operate? Is that approach not in your view, not going to scale over time to the entirety of the United States? I think as you mentioned, they pre-map all the environments and they need to refresh the map. And they have a perfect centimeter level accuracy map of everywhere they're going to drive. It's crazy. We've been talking about the autonomy actually changing the world.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 69:\n",
      "We're talking about the deployment on a global scale of autonomous systems for transportation. And if you need to maintain a centimeter accurate map for Earth or for many cities and keep them updated, it's a huge dependency that you're taking on. Huge dependency. It's a massive, massive dependency. And now you need to ask yourself, do you really need it? And humans don't need it. So it's very useful to have a low level map of like, okay, the connectivity of your road. You know that there's a fork coming up. When you drive an environment, you have that high level understanding. It's like a small Google map and Tesla uses Google map, similar kind of resolution information in the system, but it will not pre-map environments to send me a level of accuracy. It's a crutch. It's a distraction. It costs entropy and it diffuses the team. It dilutes the team. And you're not focusing on what's actually necessary, which is the computer vision problem. What did you learn about machine learning, about engineering, about life, about yourself as one human being from working with Elon Musk? I think the most I've learned is about how to sort of run organizations efficiently and how to create efficient organizations and how to fight entropy in an organization. So human engineering in the fight against entropy. Yeah. I think Elon is a very efficient warrior in the fight against entropy in organizations. What does entropy in an organization look like? It's process.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 70:\n",
      "It's process and inefficiencies in the form of meetings and that kind of stuff. Yeah. Meetings. He hates meetings. He keeps telling people to skip meetings if they're not useful. He basically runs the world's biggest startups, I would say. Tesla, SpaceX are the world's biggest startups. Tesla actually has multiple startups. I think it's better to look at it that way. And so I think he's extremely good at that. And yeah, he has a very good intuition for streamlining processes, making everything efficient. Best part is no part, simplifying, focusing, and just kind of removing barriers, moving very quickly, making big moves. All of this is very startupy sort of seeming things, but at scale. So strong drive to simplify. From your perspective, I mean, that also probably applies to just designing systems and machine learning and otherwise. Like simplify, simplify. Yes. What do you think is the secret to maintaining the startup culture in a company that grows? Can you introspect that? I do think you need someone in a powerful position with a big hammer like Elon, who's like the cheerleader for that idea and ruthlessly pursues it. If no one has a big enough hammer, everything turns into committees, democracy within the company, process, talking to stakeholders, decision making, just everything just crumbles. If you have a big person who's also really smart and has a big hammer, things move quickly.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 71:\n",
      "So you said your favorite scene in Interstellar is the intense docking scene with the AI and Cooper talking, saying, Cooper, what are you doing docking? It's not possible. No, it's necessary. Such a good line. By the way, just so many questions there. Why an AI in that scene, presumably is supposed to be able to compute a lot more than the human. It's saying it's not optimal. Why the human? I mean, that's a movie, but shouldn't the AI know much better than the human? Anyway, what do you think is the value of setting seemingly impossible goals? Our initial intuition, which seems like something that you have taken on that Elon espouses, where the initial intuition of the community might say this is very difficult and then you take it on anyway with a crazy deadline. You just from a human engineering perspective, have you seen the value of that? I wouldn't say that setting impossible goals exactly is a good idea, but I think setting very ambitious goals is a good idea. I think there's what I call sub-linear scaling of difficulty, which means that 10x problems are not 10x hard. Usually 10x harder problem is like 2 or 3x harder to execute on. If you want to improve a system by 10%, it costs some amount of work. If you want to 10x improve the system, it doesn't cost 100x amount of work. It's because you fundamentally change the approach. If you start with that constraint, then some approaches are obviously dumb and not going to work. It forces you to reevaluate.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 72:\n",
      "I think it's a very interesting way of approaching problem solving. It requires a weird kind of thinking. Going back to your PhD days, how do you think which ideas in the machine learning community are solvable? Yes. It requires, what is that? There's the cliche of first principles thinking, but it requires to basically ignore what the community is saying because doesn't a community in science usually draw lines of what is and isn't possible? It's very hard to break out of that without going crazy. I think a good example here is the deep learning revolution in some sense because you could be in computer vision at that time during the deep learning revolution of 2012 and so on. You could be improving a computer vision stack by 10% or you can just be saying, actually all of this is useless. How do I do 10x better computer vision? Well, it's not probably by tuning a hog feature detector. I need a different approach. I need something that is scalable. Going back to Richard Sutton's understanding the philosophy of the bitter lesson and then being like, actually I need much more scalable system like a neural network that in principle works and then having some deep believers that can actually execute on that mission and make it work. That's the 10x solution. What do you think is the timeline to solve the problem of autonomous driving? That's still in part an open question. Yeah. I think the tough thing with timelines of self-driving obviously is that no one has created self-driving.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 73:\n",
      "It's not like, what do you think is the timeline to build this bridge? Well, we've built million bridges before. Here's how long that takes. No one has built autonomy. It's not obvious. Some parts turn out to be much easier than others. It's really hard to forecast. You do your best based on trend lines and so on and based on intuition, but that's why fundamentally it's just really hard to forecast this. Even still being inside of it, it's hard to do. Yes. Some things turn out to be much harder and some things turn out to be much easier. Do you try to avoid making forecasts? Because Elon doesn't avoid them, right? Heads of car companies in the past have not avoided it either. Ford and other places have made predictions that we're going to solve at level four driving by 2020, 2021, whatever. They're all kind of backtracking that prediction. Are you, as an AI person, do you for yourself privately make predictions or do they get in the way of your actual ability to think about a thing? Yeah, I would say what's easy to say is that this problem is tractable and that's an easy prediction to make. It's tractable. It's going to work. Yes. It's just really hard. Some things turn out to be harder and some things turn out to be easier. It definitely feels tractable and it feels like at least the team at Tesla, which is what I saw internally, is definitely on track to that. How do you form a strong representation that allows you to make a prediction about tractability?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 74:\n",
      "You're the leader of a lot of humans. You have to say this is actually possible. How do you build up that intuition? It doesn't have to be even driving. It could be other tasks. What difficult tasks did you work on in your life? Classification, achieving certain, just an image net, certain level of superhuman level performance. Yeah, expert intuition. It's just intuition. It's belief. So just thinking about it long enough, studying, looking at sample data, like you said, driving. My intuition is really flawed on this. I don't have a good intuition about tractability. It could be anything. It could be solvable. The driving task could be simplified into something quite trivial. The solution to the problem would be quite trivial. At scale, more and more cars driving perfectly might make the problem much easier. The more cars you have driving, people learn how to drive correctly, not correctly, but in a way that's more optimal for a heterogeneous system of autonomous and semi-autonomous and manually driven cars. That could change stuff. Then again, also I've spent a ridiculous number of hours just staring at pedestrians crossing streets, thinking about humans. It feels like the way we use our eye contact, it sends really strong signals. There's certain quirks and edge cases of behavior. Of course, a lot of the fatalities that happen have to do with drunk driving and both on the pedestrian side and the driver side. There's that problem of driving at night and all that kind of.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 75:\n",
      "It's like the space of possible solutions to autonomous driving includes so many human factor issues that it's almost impossible to predict. There could be super clean, nice solutions. I would say definitely like to use a game analogy, there's some fog of war, but you definitely also see the frontier of improvement. You can measure historically how much you've made progress. I think, for example, at least what I've seen in roughly five years at Tesla, when I joined, it barely kept lane on the highway. I think going up from Palo Alto to SF was like three or four interventions. Anytime the road would do anything geometrically or turn too much, it would just not work. Going from that to a pretty competent system in five years and seeing what happens also under the hood and what the scale of which the team is operating now with respect to data and compute and everything else is just massive progress. You're climbing a mountain and it's fog, but you're making a lot of progress. It's fog. You're making progress and you see what the next directions are and you're looking at some of the remaining challenges and they're not perturbing you and they're not changing your philosophy and you're not contorting yourself. You're like, actually, these are the things that we still need to do. Yeah, the fundamental components of solving the problem seem to be there from the data engine to the compute to the compute on the car to the compute for the training, all that kind of stuff.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 76:\n",
      "So you've done over the years, you've been at Tesla, you've done a lot of amazing breakthrough ideas and engineering, all of it from the data engine to the human side, all of it. Can you speak to why you chose to leave Tesla? Basically, as I described that, Ren, I think over time during those five years, I've gotten myself into a bit of a managerial position. Most of my days were meetings and growing the organization and making decisions about high level strategic decisions about the team and what it should be working on and so on. It's like a corporate executive role and I can do it. I think I'm okay at it, but it's not fundamentally what I enjoy. I think when I joined, there was no computer vision team because Tesla was just going from the transition of using Mobileye, a third party vendor for all of its computer vision, to having to build its computer vision system. So when I showed up, there were two people training deep neural networks and they were training them at a computer at their legs. They were doing some kind of basic classification task. Yeah. And so I kind of grew that into what I think is a fairly respectable deep learning team, a massive compute cluster, a very good data annotation organization. And I was very happy with where that was. It became quite autonomous. And so I kind of stepped away and I'm very excited to do much more technical things again. Yeah. And kind of like, we focus on AGI. What was that soul searching like?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 77:\n",
      "Cause you took a little time off and think like what, how many mushrooms did you take? No, I'm just kidding. I mean, what was going through your mind? The human lifetime is finite. Yeah. You did a few incredible things here. You're one of the best teachers of AI in the world. You're one of the best. And I don't mean that I mean that in the best possible way. You're one of the best tinkerers in the AI world, meaning like understanding the fundamentals of how something works by building it from scratch and playing with it with the basic intuitions. It's like Einstein, Feynman, we're all really good at this kind of stuff. Like small example of a thing to play with it, to try to understand it. So that, and obviously now with Tessa, you helped build a team of machine learning, like engineers and assistant that actually accomplishes something in the real world. So given all that, like what was the soul searching like? Well, it was hard because obviously I love the company a lot and I love Elon, I love Tesla. It was always hard to leave. I love the team basically. But yeah, I think actually I will be potentially like interested in revisiting it. Maybe coming back at some point, working in Optimus, working in AGI at Tesla. I think Tesla is going to do incredible things. It's basically like, it's a massive large scale robotics kind of company with a ton of in-house talent for doing really incredible things. And I think human robots are going to be amazing.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 78:\n",
      "I think autonomous transportation is going to be amazing. All this is happening at Tesla. So I think it's just a really amazing organization. So being part of it and helping it along, I think was very, basically I enjoyed that a lot. Yeah, it was basically difficult for those reasons because I love the company. But I'm happy to potentially at some point come back for Act 2. But I felt like at this stage, I built the team, it felt autonomous and I became a manager and I wanted to do a lot more technical stuff. I wanted to learn stuff. I wanted to teach stuff. And I just kind of felt like it was a good time for a change of pace a little bit. What do you think is the best movie sequel of all time, speaking of part two? Because most of them suck. Movie sequels? Movie sequels, yeah. And you tweet about movies. So just in a tiny tangent, what's a favorite movie sequel? Godfather part two. Are you a fan of Godfather? Because you didn't even tweet or mention the Godfather. Yeah, I don't love that movie. I know it has a huge follow-up. We're going to edit that out. We're going to edit out the hate towards the Godfather. How dare you disrespect- I think I will make a strong statement. I don't know why. I don't know why, but I basically don't like any movie before 1995. Something like that. Didn't you mention Terminator 2? Okay. Okay. That's like Terminator 2 was a little bit later, 1990. No, I think Terminator 2 was in the 80s. And I like Terminator 1 as well. So, okay.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 79:\n",
      "So like few exceptions, but by and large, for some reason, I don't like movies before 1995 or something. They feel very slow. The camera is like zoomed out. It's boring. It's kind of naive. It's kind of weird. And also Terminator was very much ahead of its time. Yes. And the Godfather, there's like no AGI. I mean, but you have Good Will Hunting was one of the movies you mentioned, and that doesn't have any AGI either. I guess it has mathematics. Yeah. I guess occasionally I do enjoy movies that don't feature- Or like Anchorman. That's- Anchorman is so good. I don't understand. Speaking of AGI, because I don't understand why Will Ferrell is so funny. It doesn't make sense. It doesn't compute. There's just something about him. And he's a singular human because you don't get that many comedies these days. And I wonder if it has to do about the culture or the machine of Hollywood, or does it have to do with just we got lucky with certain people in comedy. It came together because he is a singular human. Yeah. I like his movies. That was a ridiculous tangent. I apologize. But you mentioned humanoid robots. So what do you think about Optimus, about Tesla Bot? Do you think we'll have robots in the factory and in the home in 10, 20, 30, 40, 50 years? Yeah. I think it's a very hard project. I think it's going to take a while. But who else is going to build humanoid robots at scale?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 80:\n",
      "And I think it is a very good form factor to go after because like I mentioned, the world is designed for humanoid form factor. These things would be able to operate our machines. They would be able to sit down in chairs, potentially even drive cars. Basically, the world is designed for humans. That's the form factor you want to invest into and make work over time. I think there's another school of thought, which is, okay, pick a problem and design a robot to it. But actually designing a robot and getting a whole data engine and everything behind it to work is actually an incredibly hard problem. So it makes sense to go after general interfaces that, okay, they are not perfect for any one given task, but they actually have the generality of just with a prompt with English, able to do something across. And so I think it makes a lot of sense to go after a general interface in the physical world. And I think it's a very difficult project. I think it's going to take time. But I see no other company that can execute on that vision. I think it's going to be amazing. Basically physical labor. If you think transportation is a large market, try physical labor. It's insane. But it's not just physical labor. To me, the thing that's also exciting is social robotics. So the relationship we'll have on different levels with those robots. That's why I was really excited to see Optimus. People have criticized me for the excitement.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 81:\n",
      "But I've worked with a lot of research labs that do humanoid-legged robots, Boston Dynamics, Unitree. There's a lot of companies that do legged robots. But the elegance of the movement is a tiny, tiny part of the big picture. So integrating the two big exciting things to me about Tesla doing humanoid or any legged robots is clearly integrating into the data engine. So the data engine aspect, so the actual intelligence for the perception and the control and the planning and all that kind of stuff, integrating into the fleet that you mentioned. And then speaking of fleet, the second thing is the mass manufacturers. Just knowing culturally driving towards a simple robot that's cheap to produce at scale and doing that well, having experience to do that well, that changes everything. That's a very different culture and style than Boston Dynamics, who by the way, those robots are just the way they move. It'll be a very long time before Tesla can achieve the smoothness of movement, but that's not what it's about. It's about the entirety of the system, like we talked about, the data engine and the fleet. That's super exciting. Even the initial models. But that, too, was really surprising that in a few months you can get a prototype. The reason that happened very quickly is, as you alluded to, there's a ton of copy paste from what's happening on the autopilot. A lot. The amount of expertise that came out of the woodworks at Tesla for building the human robot was incredible to see.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 82:\n",
      "Basically, Elon said at one point, we're doing this. And then next day, basically, all these CAD models started to appear. People talk about the supply chain and manufacturing. People showed up with screwdrivers and everything the other day and started to put together the body. I was like, whoa. All these people exist at Tesla. Fundamentally, building a car is actually not that different from building a robot. That is true, not just for the hardware pieces. Also, let's not forget hardware, not just for a demo, but manufacturing of that hardware at scale. It is a whole different thing. But for software as well, basically, this robot currently thinks it's a car. It's going to have a midlife crisis at some point. It thinks it's a car. Some of the earlier demos, actually, we were talking about potentially doing them outside in the parking lot because that's where all of the computer vision was working out of the box instead of inside. All the operating system, everything just copy pastes. Computer vision mostly copy pastes. You have to retrain the neural nets, but the approach and everything and data engine and offline trackers and the way we go about the occupancy tracker and so on, everything copy pastes. You just need to retrain the neural nets. Then the planning control, of course, has to change quite a bit. But there's a ton of copy paste from what's happening at Tesla.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 83:\n",
      "If you were to go with the goal of like, okay, let's build a million human robots and you're not Tesla, that's a lot to ask. If you're Tesla, it's actually like, it's not that crazy. Yes. Then the follow-up question is then how difficult, just like with driving, how difficult is the manipulation task such that it can have an impact at scale? I think depending on the context, the really nice thing about robotics is that unless you do a manufacturing and that kind of stuff, is there's more room for error. Driving is so safety critical and also time critical. A robot is allowed to move slower, which is nice. Yes. I think it's going to take a long time, but the way you want to structure the development is you need to say, okay, it's going to take a long time. How can I set up the product development roadmap so that I'm making revenue along the way? I'm not setting myself up for a zero one loss function where it doesn't work until it works. You don't want to be in that position. You want to make it useful almost immediately, and then you want to slowly deploy it and at scale. And you want to set up your data engine, your improvement loops, the telemetry, the evaluation, the harness and everything. And you want to improve the product over time incrementally and you're making revenue along the way. That's extremely important because otherwise you cannot build these large undertakings just like don't make sense economically.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 84:\n",
      "And also from the point of view of the team working on it, they need the dopamine along the way. They're not just going to make a promise about this being useful. This is going to change the world in 10 years when it works. This is not where you want to be. You want to be in a place like I think Autopilot is today where it's offering increased safety and convenience of driving today. People pay for it. People like it. People will purchase it. And then you also have the greater mission that you're working towards. And you see that. So the dopamine for the team, that was a source of happiness and satisfaction. Yes, 100%. You're deploying this. People like it. People drive it. People pay for it. They care about it. There's all these YouTube videos. Your grandma drives it. She gives you feedback. People like it. People engage with it. You engage with it. Huge. Do people that drive Teslas recognize you and give you love? Like, hey, thanks for this nice feature that it's doing. Yeah, I think the tricky thing is like some people really love you. Some people, unfortunately, like you're working on something that you think is extremely valuable, useful, etc. Some people do hate you. There's a lot of people who like me and the team and the whole project. And I think Tesla drivers, many cases they're not actually. Yeah, that's actually makes me sad about humans or the current ways that humans interact. I think that's actually fixable. I think humans want to be good to each other.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 85:\n",
      "I think Twitter and social media is part of the mechanism that actually somehow makes the negativity more viral, that it doesn't deserve disproportionately add a viral boost to the negativity. But I wish people would just get excited about, so suppress some of the jealousy, some of the ego and just get excited for others. And then there's a karma aspect to that. You get excited for others, they'll get excited for you. Same thing in academia. If you're not careful, there is a dynamical system there. If you think of in silos and get jealous of somebody else being successful, that actually, perhaps counterintuitively, leads to less productivity of you as a community and you individually. I feel like if you keep celebrating others, that actually makes you more successful. Yeah. I think people haven't, depending on the industry, haven't quite learned that yet. Some people are also very negative and very vocal. They're very prominently featured, but actually there's a ton of people who are cheerleaders, but they're silent cheerleaders. And when you talk to people just in the world, they will tell you, it's amazing, it's great. Especially people who understand how difficult it is to get this stuff working. People who have built products and makers, entrepreneurs, making this work and changing something is incredibly hard. Those people are more likely to cheerlead you.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 86:\n",
      "Well, one of the things that makes me sad is some folks in the robotics community don't do the cheerleading and they should because they know how difficult it is. Well, they actually sometimes don't know how difficult it is to create a product that's scale. They actually deploy it in the real world. A lot of the development of robots and AI system is done on very specific small benchmarks as opposed to real world conditions. Yes. Yeah. I think it's really hard to work on robotics in an academic setting. Or AI systems that apply in the real world. You've criticized, you flourished and loved for time the ImageNet, the famed ImageNet data set. And I've recently had some words of criticism that the academic research ML community gives a little too much love still to the ImageNet or like those kinds of benchmarks. Can you speak to the strengths and weaknesses of data sets used in machine learning research? Actually, I don't know that I recall a specific instance where I was unhappy or criticizing ImageNet. I think ImageNet has been extremely valuable. It was basically a benchmark that allowed the deep learning community to demonstrate that deep neural networks actually work. There's a massive value in that. I think ImageNet was useful, but basically it's become a bit of an MNIST at this point. MNIST is like little 228 by 28 grayscale digits. There's a joke data set that everyone just crushes. There's still papers written on MNIST though, right? Maybe they shouldn't. Strong papers.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 87:\n",
      "Like papers that focus on how do we learn with a small amount of data, that kind of stuff. Yeah. I could see that being helpful, but not in mainline computer vision research anymore, of course. I think the way I've heard you somewhere, maybe I'm just imagining things, but I think you said ImageNet was a huge contribution to the community for a long time, and now it's time to move past those kinds of... Well, ImageNet has been crushed. I'm the error rates are... Yeah, we're getting like 90% accuracy in 1000 classification way prediction, and I've seen those images and it's like really high. That's really good. If I remember correctly, the top five error rate is now like 1% or something. Given your experience with a gigantic real world data set, would you like to see benchmarks move in a certain directions that the research community uses? Unfortunately, I don't think academics currently have the next ImageNet. I think we've crushed MNIST. We've basically crushed ImageNet, and there's no next big benchmark that the entire community rallies behind and uses for further development of these networks. Yeah. What are what it takes for a data set to captivate the imagination of everybody, where they all get behind it? That could also need a leader, right? Yeah. Somebody with popularity. Yeah. Why did ImageNet take off? Or is it just the accident of history? It was the right amount of difficult.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 88:\n",
      "It was the right amount of difficult and simple, and interesting enough, it just kind of like it was the right time for that kind of a data set. Question from Reddit. What are your thoughts on the role that synthetic data and game engines will play in the future of neural net model development? I think as neural nets converge to humans, the value of simulation to neural nets will be similar to the value of simulation to humans. So people use simulation because they can learn something in that kind of a system without having to actually experience it. But are you referring to the simulation we do in our head? No, sorry, simulation. I mean like video games or other forms of simulation for various professionals. So let me push back on that because maybe there's simulation that we do in our heads. Like, simulate if I do this, what do I think will happen? Okay. That's like internal simulation. Yeah. Internal. Isn't that what we're doing? Assuming before we act? Oh yeah. But that's independent from like the use of simulation in the sense of like computer games or using simulation for training set creation or- Is it independent or is it just loosely correlated? Because like, isn't that useful to do like counterfactual or like edge case simulation to like, you know, what happens if there's a nuclear war? What happens if there's, you know, like those kinds of things? Yeah, that's a different simulation from like Unreal Engine. That's how I interpreted the question.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 89:\n",
      "Ah, so like simulation of the average case. What's Unreal Engine? What do you mean by Unreal Engine? So simulating a world, physics of that world, why is that different? Like, because you also can add behavior to that world and you could try all kinds of stuff, right? You could throw all kinds of weird things into it. Unreal Engine is not just about simulating, I mean, I guess it is about simulating the physics of the world. It's also doing something with that. Yeah. The graphics, the physics, and the agents that you put into the environment and stuff like that. Yeah. See, I think you, I feel like you said that it's not that important, I guess, for the future of AI development. Is that correct to interpret it that way? I think humans use simulators for, humans use simulators and they find them useful. And so computers will use simulators and find them useful. Okay. So you're saying it's not that, I don't use simulators very often. I play a video game every once in a while, but I don't think I derive any wisdom about my own existence from those video games. It's a momentary escape from reality versus a source of wisdom about reality. So I think that's a very polite way of saying simulation is not that useful. Yeah, maybe not. I don't see it as like a fundamental, really important part of like training neural nets currently. But I think as neural nets become more and more powerful, I think you will need fewer examples to train additional behaviors.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 90:\n",
      "And simulation is, of course, there's a domain gap in a simulation that it's not the real world, it's slightly something different. But with a powerful enough neural net, you need, the domain gap can be bigger, I think, because neural net will sort of understand that even though it's not the real world, it like has all this high level structure that I'm supposed to be learning from. So the neural net will actually, yeah, it will be able to leverage the synthetic data better by closing the gap, by understanding in which ways this is not real data. Exactly. Right, I do better questions next time. That was a question, but I'm just kidding. All right. So is it possible, do you think, speaking of MNIST, to construct neural nets and training processes that require very little data? So we've been talking about huge data sets like the internet for training. I mean, one way to say that is, like you said, like the querying itself is another level of training, I guess, and that requires a little data. But do you see any value in doing research and kind of going down the direction of can we use very little data to train, to construct a knowledge base? 100%. I just think like at some point you need a massive data set. And then when you pre-train your massive neural net and get something that is like a GPT or something, then you're able to be very efficient at training any arbitrary new task.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 91:\n",
      "So a lot of these GPTs, you can do tasks like sentiment analysis or translation or so on just by being prompted with very few examples. Here's the kind of thing I want you to do. Here's an input sentence, here's the translation into German. Input sentence, translation to German. Input sentence blank, and the neural net will complete the translation to German just by looking at sort of the example you've provided. And so that's an example of a very few shot learning in the activations of the neural net instead of the weights of the neural net. And so I think basically just like humans, neural nets will become very data efficient at learning any other new task. But at some point you need a massive data set to pre-train your network. To get that, and probably we humans have something like that. Do we have something like that? Do we have a passive in the background model constructing thing that just runs all the time in a self-supervised way? We're not conscious of it. I think humans definitely, I mean, obviously we learn a lot during our lifespan, but also we have a ton of hardware that helps us at initialization coming from sort of evolution. And so I think that's also a really big component. A lot of people in the field, I think they just talk about the amounts of like seconds and the, you know, that a person has lived pretending that this is a WLRRSA, sort of like a zero initialization of a neural net.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 92:\n",
      "And it's not like you can look at a lot of animals, like for example, zebras, zebras get born and they see and they can run. There's zero train data in their lifespan. They can just do that. So somehow I have no idea how evolution has found a way to encode these algorithms and these neural net initializations that are extremely good into ATCGs. And I have no idea how this works, but apparently it's possible because here's a proof by existence. There's something magical about going from a single cell to an organism that is born to the first few years of life. I kind of like the idea that the reason we don't remember anything about the first few years of our life is that it's a really painful process. Like it's a very difficult, challenging training process. Like intellectually, like and maybe, yeah, I mean, I don't, why don't we remember any of that? There might be some crazy training going on and that maybe that's the background model training that is very painful. And so it's best for the system once it's trained not to remember how it's constructed. I think it's just like the hardware for long-term memory is just not fully developed. I kind of feel like the first few years of infants is not actually like learning, it's brain maturing. We're born premature. There's a theory along those lines because of the birth canal and the swallowing of the brain.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 93:\n",
      "And so we're born premature and then the first few years we're just, the brain is maturing and then there's some learning eventually. That's my current view on it. What do you think, do you think neural nets can have long-term memory? Like that approach is something like humans. Do you think they need to be another meta architecture on top of it to add something like a knowledge base that learns facts about the world and all that kind of stuff? Yes, but I don't know to what extent it will be explicitly constructed. It might take unintuitive forms where you are telling the GPT like, hey, you have a declarative memory bank to which you can store and retrieve data from. And whenever you encounter some information that you find useful, just save it to your memory bank. And here's an example of something you have retrieved and how you say it and here's how you load from it. You just say load, whatever, you teach it in text, in English, and then it might learn to use a memory bank from that. Oh, so the neural net is the architecture for the background model, the base thing, and then everything else is just on top of it. That's pretty easy to do. It's not just text, right? You're giving it gadgets and gizmos. So you're teaching some kind of a special language by which it can save arbitrary information and retrieve it at a later time. And you're telling it about these special tokens and how to arrange them to use these interfaces. It's like, hey, you can use a calculator.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 94:\n",
      "Here's how you use it. Just do 53 plus 41 equals. And when equals is there, a calculator will actually read out the answer and you don't have to calculate it yourself. And you just tell it in English, this might actually work. Do you think in that sense, Godot is interesting, the DeepMind system, that it's not just new language, but actually throws it all in the same pile, images, actions, all that kind of stuff. That's basically what we're moving towards. Yeah, I think so. So Godot is very much a kitchen sink approach to reinforcement learning in lots of different environments with a single fixed transformer model, right? I think it's a very early result in that realm, but I think, yeah, it's along the lines of what I think things will eventually look like. So this is the early days of a system that eventually will look like this from a rich, sudden perspective. Yeah, I'm not super huge fan of, I think, all these interfaces that look very different. I would want everything to be normalized into the same API. So for example, screen pixels, very same API, instead of having different world environments that have very different physics and joint configurations and appearances and whatever, and you're having some kind of special tokens for different games that you can plug. I'd rather just normalize everything to a single interface so it looks the same to the neural net, if that makes sense. So it's all going to be pixel-based pong in the end. I think so. Okay.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 95:\n",
      "Let me ask you about your own personal life. A lot of people want to know you're one of the most productive and brilliant people in the history of AI. What is a productive day in the life of Andrej Kapati look like? What time do you wake up? Because imagine some kind of dance between the average productive day and a perfect productive day. So the perfect productive day is the thing we strive towards, and the average is what it converges to, given all the mistakes and human eventualities and so on. So what time do you wake up? Are you a morning person? I'm not a morning person. I'm a night owl for sure. Is it stable or not? It's semi-stable, like eight or nine or something like that. During my PhD, it was even later, I used to go to sleep usually at 3 a.m. I think the a.m. hours are precious and very interesting time to work because everyone is asleep. At 8 a.m. or 7 a.m., the East Coast is awake. So there's already activity, there's already some text messages, whatever, there's stuff happening. You can go on some news website and there's stuff happening. It's distracting. At 3 a.m., everything is totally quiet. And so you're not going to be bothered and you have solid chunks of time to do work. So I like those periods, night owl by default. And then I think like productive time, basically, what I like to do is you need to build some momentum on the problem without too much distraction. And you need to load your RAM, your working memory with that problem.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 96:\n",
      "And then you need to be obsessed with it when you're taking shower, when you're falling asleep. You need to be obsessed with the problem and it's fully in your memory and you're ready to wake up and work on it right there. So is this in a scale, temporal scale of a single day or a couple of days, a week, a month? So I can't talk about one day, basically, in isolation because it's a whole process. When I want to get productive in the problem, I feel like I need a span of a few days where I can really get in on that problem. And I don't want to be interrupted. And I'm going to just be completely obsessed with that problem. And that's where I do most of my good workouts. You've done a bunch of cool, like little projects in a very short amount of time very quickly. So that requires you just focusing on it. Yeah, basically, I need to load my working memory with the problem. And I need to be productive because there's always a huge fixed cost to approaching any problem. I was struggling with this, for example, at Tesla because I want to work on small side project. But okay, you first need to figure out, okay, I need to SSH into my cluster. I need to bring up a VS code editor so I can work on this. I run into some stupid error because of some reason. You're not at a point where you can be just productive right away. You are facing barriers. And so it's about really removing all of that barrier and you're able to go into the problem and you have the full problem loaded in your memory.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 97:\n",
      "And somehow avoiding distractions of all different forms, like news stories, emails, but also distractions from other interesting projects that you previously worked on or currently working on and so on. You just want to really focus your mind. And I mean, I can take some time off for distractions and in between, but I think it can't be too much. Most of your day is sort of spent on that problem. And then I drink coffee, I have my morning routine, I look at some news, Twitter, Hacker News, Wall Street Journal, et cetera. It's great. So basically, you wake up, you have some coffee. Are you trying to get to work as quickly as possible? Are you taking this diet of what the hell is happening in the world first? I do find it interesting to know about the world. I don't know that it's useful or good, but it is part of my routine right now. So I do read through a bunch of news articles and I want to be informed. And I'm suspicious of it. I'm suspicious of the practice, but currently that's where I am. Oh, you mean suspicious about the positive effect of that practice on your productivity and your wellbeing? My wellbeing psychologically, yeah. And also on your ability to deeply understand the world because there's a bunch of sources of information. You're not really focused on deeply integrating. Yeah, it's a little distracting. In terms of a perfectly productive day, for how long of a stretch of time in one session do you try to work and focus on a thing?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 98:\n",
      "A couple of hours, is it one hour, is it 30 minutes, is it 10 minutes? I can probably go a small few hours and then I need some breaks in between for food and stuff. Yeah, but I think it's still really hard to accumulate hours. I was using a tracker that told me exactly how much time I spent coding any one day. And even on a very productive day, I still spent only like six or eight hours. And it's just because there's so much padding, commute, talking to people, food, et cetera. There's like the cost of life, just living and sustaining and homeostasis and just maintaining yourself as a human is very high. And there seems to be a desire within the human mind to participate in society that creates that padding. Because the most productive days I've ever had is just completely from start to finish is tuning out everything and just sitting there. And then you could do more than six and eight hours. Is there some wisdom about what gives you strength to do tough days of long focus? Yeah, just like whenever I get obsessed about a problem, something just needs to work, something just needs to exist. It needs to exist. So you're able to deal with bugs and programming issues and technical issues and design decisions that turn out to be the wrong ones. You're able to think through all of that given that you want to think to exist. Yeah, it needs to exist. And then I think to me also a big factor is are other humans are going to appreciate it? Are they going to like it?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 99:\n",
      "That's a big part of my motivation. If I'm helping humans and they seem happy, they say nice things, they tweet about it or whatever, that gives me pleasure because I'm doing something useful. So you do see yourself sharing it with the world. Whether it's on GitHub or through a blog post or through videos. Yeah, I was thinking about it. Suppose I did all these things but did not share them. I don't think I would have the same amount of motivation that I can build up. You enjoy the feeling of other people gaining value and happiness from the stuff you've created. Yeah. What about diet? I saw you played with intermittent fasting. Do you fast? Does that help? I played with everything. With the things you played, what's been most beneficial to your ability to mentally focus on a thing and just mental productivity and happiness? You still fast? Yeah, I still fast, but I do intermittent fasting. But really what it means at the end of the day is I skip breakfast. So I do 18, 6 roughly by default when I'm in my steady state. If I'm traveling or doing something else, I will break the rules. But in my steady state, I do 18, 6. So I eat only from 12 to 6. Not a hard rule and I break it often, but that's my default. And then yeah, I've done a bunch of random experiments. For the most part right now, where I've been for the last year and a half, I want to say, is I'm plant-based or plant-forward. I heard plant-forward. It sounds better. What does that mean exactly?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 100:\n",
      "I don't actually know what the difference is, but it sounds better in my mind. But it just means I prefer plant-based food. Raw or cooked? I prefer cooked and plant-based. So plant-based, forgive me, I don't actually know how wide the category of plant entails. Well, plant-based just means that you're not militant about it and you can flex. You just prefer to eat plants and you're not trying to influence other people. And if you come to someone's house party and they serve you a steak that they're really proud of, you will eat it. That's beautiful. I'm on the flip side of that, but I'm very sort of flexible. Have you tried doing one meal a day? I have accidentally, not consistently, but I've accidentally had that. I don't like it. I think it makes me feel not good. It's too much, too much of a hit. Yeah. And so currently I have about two meals a day, 12 and six. I do that nonstop. I'm doing it now. I do one meal a day. It's interesting. It's an interesting feeling. Have you ever fasted longer than a day? Yeah, I've done a bunch of water fasts because I was curious what happens. Anything interesting? Yeah, I would say so. I mean, what's interesting is that you're hungry for two days and then starting day three or so, you're not hungry. It's such a weird feeling because you haven't eaten in a few days and you're not hungry. Isn't that weird? It's really weird. One of the many weird things about human biology, is figure something out.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 101:\n",
      "It finds another source of energy or something like that, or relaxes the system. I don't know how that works. The body is like, you're hungry, you're hungry. And then it just gives up. It's like, okay, I guess we're fasting now. There's nothing. And then it just focuses on trying to make you not hungry and not feel the damage of that and trying to give you some space to figure out the food situation. Are you still to this day most productive at night? I would say I am, but it is really hard to maintain my PhD schedule, especially when I was working at Tesla and so on. It's a non-starter. But even now, people want to meet for various events. Society lives in a certain period of time and you sort of have to work with that. It's hard to do a social thing and then after that return and do work. Yeah. It's just really hard. That's why I try when I do social things, I try not to do too much drinking so I can return and continue doing work. But at Tesla, is there a convergence, Tesla, but any company, is there a convergence towards a schedule? Or is there more? Is that how humans behave when they collaborate? I need to learn about this. Do they try to keep a consistent schedule where you're all awake at the same time? I do try to create a routine and I try to create a steady state in which I'm comfortable in. I have a morning routine, I have a day routine, I try to keep things to a steady state and things are predictable. And then your body just sticks to that.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 102:\n",
      "And if you try to stress that a little too much, it will create, when you're traveling and you're dealing with jet lag, you're not able to really ascend to where you need to go. Yeah. That's what you're doing with humans with the habits and stuff. What are your thoughts on work-life balance throughout a human lifetime? So Tesla in part was known for pushing people to their limits in terms of what they're able to do, in terms of what they're trying to do, in terms of how much they work, all that kind of stuff. Yeah. I will say Tesla gets a little too much bad rep for this because what's happening is Tesla, it's a bursty environment. So I would say the baseline, my only point of reference is Google, where I've interned three times and I saw what it's like inside Google and DeepMind. I would say the baseline is higher than that, but then there's a punctuated equilibrium where once in a while there's a fire and people work really hard. And so it's spiky and bursty and then all the stories get collected. About the bursts. And then it gives the appearance of total insanity, but actually it's just a bit more intense environment and there are fires and sprints. And so I think definitely though I would say it's a more intense environment than something you would get. But in your personal, forget all of that, just in your own personal life, what do you think about the happiness of a human being?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 103:\n",
      "A brilliant person like yourself, about finding a balance between work and life or is it such a thing, not a good thought experiment? Yeah, I think balance is good, but I also love to have sprints that are out of distribution. And that's when I think I've been pretty creative as well. Sprints out of distribution means that most of the time you have a quote unquote balance. I have balance most of the time. I like being obsessed with something once in a while. Once in a while is what? Once a week, once a month, once a year? Yeah, probably like say once a month or something. Yeah. And that's when we get a new GitHub repo for monitoring. Yeah, that's when you really care about a problem. It must exist. This will be awesome. You're obsessed with it. And now you can't just do it on that day. You need to pay the fixed cost of getting into the groove. And then you need to stay there for a while and then society will come and they will try to mess with you and they will try to distract you. Yeah. The worst thing is a person who's like, I just need five minutes of your time. Yeah. The cost of that is not five minutes and society needs to change how it thinks about it. Just five minutes of your time. Right. It's never just one minute. Just 30 seconds. Just a quick thing. What's the big deal? Why are you being so... Yeah, no. What's your computer setup? What's like the perfect... Are you somebody that's flexible to no matter what? Laptop, four screens. Yeah.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 104:\n",
      "Or do you prefer a certain setup that you're most productive? I guess the one that I'm familiar with is one large screen, 27 inch, and my laptop on the side. What operating system? I do Macs. That's my primary. For all tasks? I would say OS X, but when you're working on deep learning, everything is Linux. You're SSH'd into a cluster and you're working remotely. But what about the actual development? Like they're using the IDE? I think a good way is you just run VS code, my favorite editor right now, on your Mac, but you have a remote folder through SSH. The actual files that you're manipulating are on the cluster somewhere else. What's the best IDE? VS code. What else do people... I use Emacs still. That's cool. It may be cool. I don't know if it's maximum productivity. What do you recommend in terms of editors? You worked a lot of software engineers. Editors for Python, C++, machine learning applications. I think the current answer is VS code. Currently, I believe that's the best IDE. It's got a huge amount of extensions. It has GitHub Copilot integration, which I think is very valuable. What do you think about the Copilot integration? I was actually... I got to talk a bunch with Guido Narrazzon, who's a creative Python, and he loves Copilot. He programs a lot with it. Do you? Yeah, I use Copilot. I love it. It's free for me, but I would pay for it. Yeah, I think it's very good. The utility that I found with it was...\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 105:\n",
      "I would say there's a learning curve, and you need to figure out when it's helpful and when to pay attention to its outputs and when it's not going to be helpful, where you should not pay attention to it. Because if you're just reading at suggestions all the time, it's not a good way of interacting with it. But I think I was able to mold myself to it. I find it's very helpful, number one, copy, paste, and replace some parts. When the pattern is clear, it's really good at completing the pattern. And number two, sometimes it suggests APIs that I'm not aware of. It tells you about something that you didn't know. And that's an opportunity to discover and use it again. It's an opportunity to... I would never take Copilot code as given. I almost always copy a copy paste into a Google search, and you see what this function is doing. And then you're like, oh, it's actually exactly what I need. Thank you, Copilot. So you learn something. It's in part a search engine, part maybe getting the exact syntax correctly that once you see it, it's that NP hard thing. Once you see it, you know it's correct, but you yourself struggle. You can verify efficiently, but you can't generate efficiently. And Copilot really, I mean, it's autopilot for programming, right? And currently it's doing the link following, which is like the simple copy, paste, and sometimes suggest. But over time, it's going to become more and more autonomous.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 106:\n",
      "And so the same thing will play out in not just coding, but actually across many, many different things probably. Coding is an important one, right? Like writing programs. How do you see the future of that developing? The program synthesis, like being able to write programs that are more and more complicated. Because right now it's human supervised in interesting ways. It feels like the transition will be very painful. My mental model for it is the same thing will happen as with the autopilot. So currently it's doing link following, it's doing some simple stuff. And eventually we'll be doing autonomy and people will have to intervene less and less. And there could be like testing mechanisms. Like if it writes a function and that function looks pretty damn correct, but how do you know it's correct? Because you're getting lazier and lazier as a programmer. Like your ability to, because like little bugs, but I guess it won't make little mistakes. No, it will. Copilot will make off by one subtle bugs. It has done that to me. But do you think future systems will? Or is it really the off by one is actually a fundamental challenge of programming? In that case, it wasn't fundamental. And I think things can improve, but yeah, I think humans have to supervise. I am nervous about people not supervising what comes out and what happens to, for example, the proliferation of bugs in all of our systems.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 107:\n",
      "I'm nervous about that, but I think there will probably be some other copilots for bug finding and stuff like that at some point. Cause there'll be like a lot more automation for. It's like a program, a copilot that generates a compiler, one that does a linter, one that does like a type checker. It's a committee of like a GPT sort of like. And then there'll be like a manager for the committee. And then there'll be somebody that says a new version of this is needed. We need to regenerate it. Yeah. There were 10 GPTs. They were forwarded and gave 50 suggestions. Another one looked at it and picked a few that they like. A bug one looked at it and it was like, it's probably a bug. They got re-ranked by some other thing. And then a final ensemble GPT comes in. It's like, okay, given everything you guys have told me, this is probably the next token. The feeling is the number of programmers in the world has been growing and growing very quickly. Do you think it's possible that it'll actually level out and drop to like a very low number with this kind of world? Cause then you'll be doing software 2.0 programming. And you'll be doing this kind of generation of copilot type systems programming, but you won't be doing the old school software 1.0 program. I don't currently think that they're just going to replace human programmers. I'm so hesitant saying stuff like this, right? This is going to be replaced in five years. I don't know. It's going to show that this is where we thought.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 108:\n",
      "Cause I agree with you, but I think we might be very surprised. What's your sense of where we stand with language models? Does it feel like the beginning or the middle or the end? The beginning, a hundred percent. I think the big question in my mind is for sure GPT will be able to program quite well, competently and so on. How do you steer the system? You still have to provide some guidance to what you actually are looking for. And so how do you steer it? And how do you talk to it? How do you audit it and verify that what is done is correct? And how do you work with this? And it's as much not just an AI problem, but a UI UX problem. So beautiful fertile ground for so much interesting work for VS code plus plus where it's not just human programming anymore. It's amazing. Yeah. So you're interacting with the system. So not just one prompt, but it's iterative prompting. You're trying to figure out having a conversation with the system. Yeah. That actually, I mean, to me, that's super exciting to have a conversation with the program I'm writing. Yeah. Maybe at some point you're just conversing with it. It's like, okay, here's what I want to do. Actually this variable, maybe it's not even that low level as variable, but. You can also imagine like, can you translate this to C plus plus and back to Python? Yeah, that already kind of exists in some. No, but just like doing it as part of the program experience.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 109:\n",
      "Like I think I'd like to write this function in C plus plus or like you just keep changing for different, uh, different programs because of different six, six syntax. Maybe I want to convert this into a functional language. And so like you get to become multilingual as a programmer and dance back and forth efficiently. Yeah. I mean, I think the UI UX of it though is like still very hard to think through because it's not just about writing code on a page. You have an entire developer environment. You have a bunch of hardware on it. Uh, you have some environmental variables. You have some scripts that are running in a Chrome job. Like there's a lot going on to like working with computers and how do these systems set up environment flags and work across multiple machines and set up screen sessions and automate different processes. Like how all that works and is auditable by humans and so on is like massive question. No, my man. You've built archive sanity. What is archive and what is the future of academic research publishing that you would like to see? Uh, so archive is this pre print server. So if you have a paper, uh, you can submit it for publication to journals or conferences and then wait six months and then maybe get a decision, pass or fail, or you can just upload it to archive and then people can tweet about it three minutes later and then everyone sees it, everyone reads it and everyone can profit from it, uh, in their own way.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 110:\n",
      "So you can cite it and it has an official look to it. It feels like a pub, like it feels like a publication process. It feels different than you if you just put it in a blog post. Oh yeah. Yeah. I mean, it's a paper and usually the bar is higher for something that you would expect on archive as opposed to something you would see in a blog post. Well, the culture created the bar because you could probably post a pretty crappy picture on the archive. Yes. Um, so what, what's that make you feel like? What's that make you feel about peer review? So rigorous peer review by two, three experts versus the peer review of the community right as it's written. Yeah. Basically I think the community is very well able to peer review things very quickly on Twitter. And I think maybe it just has to do something with AI machine learning fields specifically though. I feel like things are more easily auditable. Um, and the verification is easier potentially than the verification somewhere else. So it's kind of like, um, you can think of these, uh, scientific publications as like little blockchains where everyone's building on each other's work and setting each other. And you sort of have AI, which is kind of like this much faster and loose blockchain, but then you have any one individual entry is like very, um, very cheap to make. And then you have other fields where maybe that model doesn't make as much sense. Um, and so I think in AI, at least things are pretty easily very viable.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 111:\n",
      "And so that's why when people upload papers, they're a really good idea and so on, people can try it out like the next day and they can be the final arbiter of whether it works or not on their problem. And the whole thing just moves significantly faster. So I kind of feel like academia still has a place. Sorry, this like conference journal process still has a place, but it's sort of like, um, it lags behind, I think. And it's a bit more, um, maybe higher quality process. Uh, but it's not sort of the place where you will discover cutting edge work anymore. Yeah. It used to be the case when I was starting my PhD, that you go to conferences and journals and you discuss all the latest research. Now, when you go to a conference or general, like no one discusses anything that's there because it's already like three generations ago irrelevant. Yeah. Which makes me sad about like DeepMind, for example, where they, they still, they still publish in nature and these big prestigious, I mean, there's still value, I suppose to the prestige that comes with these big venues, but the result is that they, they'll announce some breakthrough performance and it will take like a year to actually publish the details. I mean, and those details in, if they were published immediately, it would inspire the community to move in certain directions. Yeah, it would speed up the rest of the community, but I don't know to what extent that's part of their objective function also. That's true.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 112:\n",
      "So it's not just the prestige, a little bit of the delay is, uh, as part of. Yeah, they certainly, uh, DeepMind specifically has been, um, working in the regime of having a slightly higher quality, basically process and latency and, uh, publishing those papers that way. Another question from Reddit. Do you, or have you suffered from imposter syndrome? Being the director of AI Tesla, uh, being this person when you're at Stanford, where like the world looks at you as the expert in AI to teach, teach the world about machine learning. When I was leaving Tesla after five years, I spent a ton of time in meeting rooms. Uh, and you know, I would read papers in the beginning when I joined Tesla, I was writing code and then I was writing less and less code and I was reading code and then I was reading less and less code. And so this is just a natural progression that happens, I think. And, uh, definitely I would say near the tail end. That's when it sort of like starts to hit you a bit more that you're supposed to be an expert, but actually the source of truth is the code that people are writing, the GitHub and the actual, the actual code itself. Uh, and you're not as familiar with that as you used to be. And so I would say maybe there's some like insecurity there. Yeah, that's actually pretty profound that a lot of the insecurity has to do with not writing the code in the computer science space like that, cause that is the truth that, that right there.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 113:\n",
      "The code is the source of truth, the papers and everything else. It's a high level summary. I don't, uh, yeah, just a high level summary, but at the end of the day, you have to read code. It's impossible to translate all that code into actual, uh, you know, uh, paper form. Uh, so when, when things come out, especially when they have a source code available, that's my favorite place to go. So like I said, you're one of the greatest teachers of machine learning AI ever, uh, from CS 231N to today. What advice would you give to beginners interested in getting into machine learning? Beginners are often focused on like what to do. And I think the focus should be more like how much you do. So I am kind of like believer on a high level in this 10,000 hours kind of concept where you just kind of have to just pick the things where you can spend time and you care about and you're interested in. You literally have to put in 10,000 hours of work. Um, it doesn't even like matter as much like where you put it and you're, you'll iterate and you'll improve and you'll waste some time. I don't know if there's a better way you need to put in 10,000 hours, but I think it's actually really nice because I feel like there's some sense of determinism about, uh, being an expert at a thing. If you spend 10,000 hours, you can literally pick an arbitrary thing. And I think if you spend 10,000 hours of deliberate effort and work, you actually will become an expert at it.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 114:\n",
      "And so I think it's kind of like a nice thought. Um, and so, uh, basically I would focus more on like, are you spending 10,000 hours? That's what I'm focused on. So, and then thinking about what kind of mechanisms maximize your likelihood of getting to 10,000 hours, which for us silly humans means probably forming a daily habit of like every single day, actually doing the thing, whatever helps you. So I do think to a large extent is a psychological problem for yourself. Uh, one other thing that I help that I think is helpful for the psychology of it is many times people compare themselves to others in the area. I think this is very harmful only compare yourself to you from some time ago, like say a year ago, are you better than you year ago? This is the only way to think. Um, and I think this, then you can see your progress and it's very motivating. That's so interesting that focus on the quantity of hours. Cause I think a lot of people, uh, in the beginner stage, but actually throughout get paralyzed, uh, by, uh, the choice, like which one do I pick this path or this path? Like they'll literally get paralyzed, but like which ID to use. Well, they're worried. Yeah. They'll worried about all these things, but the thing is some of the, you will waste time doing something wrong. You will eventually figure out it's not right. You will accumulate scar tissue and next time you'll grow stronger because next time you'll have the scar tissue and next time you'll learn from it.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 115:\n",
      "And now next time come to a similar situation, you'll be like, Oh, I, I messed up. I've spent a lot of time working on things that never materialized into anything. And I have all that scar tissue and I have some intuitions about what was useful, what wasn't useful, how things turned out. Uh, so all those mistakes were, uh, were not dead work, you know? So I just think you should, did you just focus on working? What have you done? What have you done last week? Uh, that's a good question actually to ask for, for a lot of things, not just machine learning. Um, it's a good way to cut the, the, I forgot what the term we use, but the fluff, the blubber, whatever the, uh, the inefficiencies in life. Uh, what do you love about teaching? You seem to find yourself often in the, like draw onto teaching. You're very good at it, but you're also drawn to it. I mean, I don't think I love teaching. I love happy humans and happy humans like when I teach. I wouldn't say I hate teaching. I tolerate teaching, but it's not like the act of teaching that I like. It's, it's that, um, you know, I, I have some, I have something I'm actually okay at it. I'm okay at teaching and people appreciate it a lot. And, uh, so I'm just happy to try to be helpful and, uh, teaching itself is not like the most, I mean, it's really annoying. It can be really annoying, frustrating. I was working on a bunch of lectures just now.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 116:\n",
      "I was reminded back to my days of 231 and just how much work it is to create some of these materials and make them good. The amount of iteration and thought, and you go down blind alleys and just how much you change it. So creating something good, um, in terms of like educational value is really hard and, uh, it's not fun. It was difficult. So for people to definitely go watch your new stuff, you put out, there are lectures where you're actually building the thing like from, like you said, the code is truth. So discussing, uh, backpropagation by building it, by looking through it and just the whole thing. So how difficult is that to prepare for? I think that's a really powerful way to teach. Did you have to prepare for that or are you just live thinking through it? I will typically do like say three takes and then I take like the better take. Uh, so I do multiple takes and I take some of the better takes and then I just build out a lecture that way. Uh, sometimes I have to delete 30 minutes of content because it just went down the alley that I didn't like too much. There's a bunch of iteration and it probably takes me, you know, somewhere around 10 hours to create one hour of content. To get one hour. It's interesting. I mean, uh, is it difficult to go back to the basics? Do you draw a lot of like wisdom from going back to the basics? Yeah. Going back to backpropagation loss functions, where they come from.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 117:\n",
      "And one thing I like about teaching a lot honestly is it definitely strengthens your understanding. So it's not a purely altruistic activity. It's a way to learn. If you have to explain something to someone, uh, you realize you have gaps in knowledge. Uh, and so I even surprised myself in those lectures. Like, oh, the result will obviously look at this and then the result doesn't look like it. And I'm like, okay, I thought I understood this. Yeah. But that's why it's really cool. Literally code, you run it in the notebook and it gives you a result and you're like, oh, wow. Yes. And like actual numbers, actual input, actual code. Yeah. It's not mathematical symbols, et cetera. The source of truth is the code. It's not slides. It's just like, let's build it. It's beautiful. You're a rare human in that sense. Uh, what advice would you give to researchers, uh, trying to develop and publish idea that have a big impact in the world of AI? So maybe, um, undergrads, maybe early graduate students. Yep. I mean, I would say like, they definitely have to be a little bit more strategic than I had to be as a PhD student because of the way AI is evolving. It's going the way of physics, where, you know, in physics, you used to be able to do experiments on your bench top and everything was great and you could make progress. And now you have to work in like LHC or like CERN. And, and so AI is going in that direction as well.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 118:\n",
      "Um, so there's certain kinds of things that's just not possible to do on the bench top anymore. And, uh, I think, um, that didn't used to be the case at the time. Do you still think that there's like, GAN type papers to be written where like, uh, like very simple idea that requires just one computer to illustrate a simple example? I mean, one example that's been very influential recently is diffusion models. The fusion models are amazing. The fusion models are six years old. Uh, for the longest time, people were kind of ignoring them as far as I can tell. And, uh, they're an amazing generative model, especially in, uh, in images. And so stable diffusion and so on. It's all diffusion based. Uh, the fusion is new. It was not there and came from, well, it came from Google, but a researcher could have come up with it. In fact, some of the first actually know those came from Google as well. Uh, but a researcher could come up with that in an academic institution. Yeah. What do you find most fascinating about diffusion models? So from the societal impact of the technical architecture, what I like about the fusion is it works so well. Was that surprising to you? The amount of the variety, almost the novelty of the synthetic data is generating. Yeah. So the stable diffusion images are incredible. It's the speed of improvement in generating images has been insane. Uh, we went very quickly from generating like tiny digits to tiny faces and it all looked messed up.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 119:\n",
      "And now we were stable diffusion and that happened very quickly. There's a lot that academia can still contribute. Uh, you know, for example, um, flash attention is a very efficient kernel for running the attention operation inside the transformer that came from academic environment. It's a very clever way to structure the kernel, uh, that do the best calculation. So it doesn't materialize the attention matrix. Um, and so there's, I think there's still like lots of things to contribute, but you have to be just more strategic. Do you think neural networks can be made to reason? Uh, yes. Do you think they already reason? Yes. What's your definition of reasoning? Uh, information processing. So in the way that humans think through a problem and come up with novel ideas, it, it feels like reasoning. Yeah. So the, the novelty, I don't want to say, but out of, out of distribution ideas, you think it's possible? Yes. And I think we're seeing that already in the current neural nets. You're able to remix the training set information into true generalization in some sense. That doesn't appear in a fundamental way in the training set. Like you're doing something interesting algorithmically, you're manipulating, you know, some symbols and you're coming up with some correct, unique answer in a new setting. What would, uh, illustrate to you, holy shit, this thing is definitely thinking. To me, thinking or reasoning is just information processing and generalization.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 120:\n",
      "And I think the neural nets already do that today. So being able to perceive the world or perceive the, whatever the inputs are and to make predictions based on that or actions based on that, that's, that's the reason. Yeah. You're giving correct answers in novel settings, uh, by manipulating information. You've learned the correct algorithm. You're not doing just some kind of a lookup table on the Earth's neighbor search. Something like that. Let me ask you about AGI. What, what are some moonshot ideas you think might make significant progress towards AGI? Or maybe another way is what are the big blockers that we're missing now? So basically I am fairly bullish on our ability to build AGI's, uh, basically automated systems that we can interact with that are very human-like and we can interact with them in the digital realm or physical realm. Currently, it seems most of the models that sort of do these sort of magical tasks are in a text realm. Um, I think, as I mentioned, I'm suspicious that the text realm is not enough to actually build full understanding of the world. I do actually think you need to go into pixels and understand the physical world and how it works. So I do think that we need to extend these models to consume images and videos and train on a lot more data that is multimodal in that way. Do you think you need to touch the world to understand it also?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 121:\n",
      "Well, that's the big open question I would say in my mind is if you also require the embodiment and the ability to, uh, sort of, sort of interact with the world, run experiments and, um, have a data of that form, then you need to go to optimist or something like that. And so I would say optimist in some way is like a hedge, um, in AGI because it seems to me that it's possible that just having data from the internet is not enough. If that is the case, then optimist may lead to AGI, uh, because optimist would, I, to me, there's nothing beyond optimist. You have like this humanoid form factor that can actually like do stuff in the world. You can have millions of them interacting with humans and so on. And, uh, if that doesn't give rise to AGI at some point, like I'm not sure what will. Um, so from a completeness perspective, I think that's the, uh, that's a really good platform, but it's a much harder platform because, uh, you are dealing with atoms and you need to actually like build these things and integrate them into society. So I think that path takes longer, uh, but it's much more certain. And then there's a path of the internet and just like training these compression models effectively, uh, on a trend compress all the internet. And, uh, that might also give, um, these agents as well. Compress the internet, but also interact with the internet. So it's not obvious to me. In fact, I suspect you can reach AGI without ever entering the physical world.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 122:\n",
      "And the, which is a little bit more, uh, concerning because it might, that results in it happening faster. So it just feels like we're in, like in boiling water. We won't know as it's happening. I would like to, I'm not afraid of AGI. I'm excited about it. There's always concerns, but I would like to know when it happens. Yeah. Or it have like hints about when it happens, like a year from now, it will happen. That kind of thing. I just feel like in the digital realm, it just might happen. Yeah. I think all we have available to us because no one has built AGI again. So all we have available to us is, uh, is there enough fertile ground on the periphery? I would say yes. And we have the progress so far, which has been very rapid and, uh, there are next steps that are available. And so I would say, uh, yeah, it's quite likely that we'll be interacting with digital entities. How will you know that somebody has built AGI? It's going to be a slow, I think it's going to be a slow incremental transition is going to be product based and focused. It's going to be GitHub co-pilot getting better. And then, uh, GPT is helping you right. And then these oracles that you can go to with mathematical problems, I think we're on a, on a verge of being able to ask very complex questions in chemistry, physics, math, of these oracles and have them complete solutions. So AGI to use primarily focused on intelligence. So consciousness doesn't enter into, uh, into it.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 123:\n",
      "So in my mind, consciousness is not a special thing you will, you will figure out and bolt on. I think it's an emerging phenomenon of a large enough and complex enough, um, generative model sort of. So, um, if you have a complex enough world model, uh, that understands the world, then it also understands its predicament in the world as being a language model, which to me is a form of consciousness or self-awareness. And so in order to understand the world deeply, you probably have to integrate yourself into the world. And in order to interact with humans and other living beings, consciousness is a very useful tool. I think consciousness is like a modeling insight. Modeling insight. Yeah. It's a, you have a powerful enough model of understanding the world that you actually understand that you are an entity in it. Yeah. But there's also this, um, perhaps just the narrative we tell ourselves. There's a, it feels like something to experience the world, the hard problem of consciousness, but that could be just a narrative that we tell ourselves. Yeah. I don't think we'll, yeah, I think it will emerge. I think it's going to be something very boring. Like we'll be talking to these digital AIs, they will claim they're conscious. They will appear conscious. They will do all the things that you would expect of other humans. And, uh, it's going to just be a stalemate.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 124:\n",
      "I think there'll be a lot of actual fascinating ethical questions, like Supreme Court level questions of whether you're allowed to turn off a conscious AI. If you're allowed to build a conscious AI, maybe there would have to be the same kind of debate that you have around um, sorry to bring up a political topic, but you know, abortion, uh, which is the deeper question with abortion, uh, is what is life? And the deep question with AI is also what is life and what is conscious? And I think that'll be very fascinating to bring up. It might become illegal to build systems that are capable like of such level of intelligence that consciousness would emerge. And therefore the capacity to suffer would emerge and somebody, a system that says, no, please don't kill me. Well, that's what the Lambda compute, the Lambda chatbot already told, um, this Google engineer, right? Like it was talking about not wanting to die or so on. So that might become illegal to do that. Right. Cause otherwise you might have a lot of, a lot of creatures that don't want to die and they will, uh, you can just spawn infinity of them on a cluster. And then that might lead to like horrible consequences. Cause then there might be a lot of people that secretly love murder and then we'll start practicing murder on those systems. I mean, there's just, I, to me, all of this stuff just brings a beautiful mirror to the human condition and human nature. We'll get to explore it.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 125:\n",
      "And that's what like the best of, uh, the Supreme court of all the different debates we have about ideas of what it means to be human. We get to ask those deep questions that we've been asking throughout human history. There's always been the other in human history. Uh, we're the good guys and that's the bad guys. And we're going to, uh, you know, throughout human history, let's murder the bad guys. And the same will probably happen with robots. It'll be the other at first. And then we'll get to ask questions of what does it mean to be alive? What does it mean to be conscious? Yep. And I think there's some canary in the coal mines, even with what we have today. And, uh, you know, for example, these, there's these like waifus that you can like work with. And some people are trying to like, this company is going to shut down, but this person really like, love their waifu and like, it's trying to like port it somewhere else. And like, it's not possible. And like, I think like definitely, uh, people will have feelings towards, uh, towards these, um, systems because in some sense they are like a mirror of humanity because they are like sort of like a big average of humanity in a way that it's trained. But we can, that average, we can actually watch. There's, it's nice to be able to interact with the big average of humanity and do like a search query on it. Yeah. Yeah. It's very fascinating. And, uh, we can of course, also like shape it. It's not just a pure average.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 126:\n",
      "We can mess with the training data. We can mess with the objective. We can fine tune them in various ways. Uh, so we have some, um, you know, impact on what those systems look like. If you want to achieve AGI, um, and you could, uh, have a conversation with her and ask her, uh, talk about anything, maybe ask her a question. What, what kind of stuff would you, would you ask? I would have some practical questions in my mind, like, uh, do I or my loved ones really have to die? Uh, what can we do about that? Do you think it will answer clearly or would it answer poetically? I would expect it to give solutions. I would expect it to be like, well, I've read all of these textbooks and I know all these things that you've produced. And it seems to me like, here are the experiments that I think it would be useful to run next. And here's some gene therapies that I think would be helpful. And, uh, here are the kinds of experiments that you should run. Okay. Let's go with this thought experiment. Okay. Imagine that mortality is actually, uh, pre like a prerequisite for happiness. So if we become immortal, we'll actually become deeply unhappy and the model is able to know that. So what is this supposed to tell you? Stupid human about it. Yes, you can become a mortal, but you will become deeply unhappy. If, if the models, if the AGI system is trying to empathize with you human, what is this supposed to tell you that? Yes, you don't have to die, but you're really not going to like it.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 127:\n",
      "Is that, is it going to be deeply honest? Like there's a interstellar. What is it? The AI says like humans want 90% honesty. Yeah. So like you have to pick how honest do I want to answer these practical questions? Yeah. I love AI and interstellar by the way. I think it's like such a sidekick to the entire story, but at the same time, it's like really interesting. It's kind of limited in certain ways, right? Yeah, it's limited. And I think that's totally fine by the way. I don't think, uh, I think it's fine and plausible to have a limited and imperfect AGI. Is that the feature almost as an example, like it has a fixed amount of compute on its physical body. And it might just be that even though you can have a super amazing mega brain, super intelligent AI, you also can have like, you know, less intelligent as they can deploy in a power efficient way. And then they're not perfect. They might make mistakes. No, I meant more like say you had infinite compute and it's still good to make mistakes sometimes to integrate yourself. Like, um, what is it going back to goodwill hunting? Uh, Robin Williams character says like the human imperfections, that's the good stuff, right? Isn't it, isn't that the S like we don't want perfect. We want flaws in part to, to form connections with each other because it feels like something you can attach your feelings to the, the, the flaws in that same way. You want AI that's flawed. I don't know.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 128:\n",
      "I feel like perfectionist, but then you're saying, okay, yeah, but that's not AGI, but see AGI would need to be intelligent enough to give answers to humans that humans don't understand. And I think perfect isn't something humans can't understand because even science doesn't give perfect answers. There's always gabs and mysteries and I don't know. I, I don't know if humans want perfect. Yeah. I could imagine just, um, having a conversation with this kind of oracle entity as you'd imagine them. And, uh, yeah, maybe it can tell you about, you know, based on my analysis of human condition, um, you might not want this and here are some of the things that might, but every, every dumb human will say, yeah, yeah, yeah, yeah. Trust me. I can give me the truth. I can handle it, but that's the beauty. Like people can choose. Uh, so, but then it's the old marshmallow test with the kids and so on. I feel like too many people, like can't handle the truth, probably including myself, like the deep truth of the human condition. I don't, I don't know if I can handle it. Like, what if there's some dark stuff? What, what if we are an alien science experiment and it realizes that what if it had, I mean, I mean, this is the matrix, you know, all over again. I don't know. I would, what would I talk about?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 129:\n",
      "I don't even, yeah, I, uh, probably I will go with the safer scientific questions at first that have nothing to do with my own personal life and mortality, just like about physics and so on, uh, to, to build up, like, let's see where it's at, or maybe see if it has a sense of humor. That's another question. Would it be able to, uh, presumably in order to, if it understands humans deeply, it would be able to generate, uh, yeah, to generate humor. Yeah. I think that's actually a wonderful benchmark almost. Like, is it able, I think that's a really good point basically to make you laugh. Yeah. If it's able to be like a very effective standup comedian, that is doing something very interesting computationally. I think being funny is extremely hard. Yeah. Because it's hard in a way, like a touring test, the original intent of the touring test is hard because you have to convince humans and there's nothing that's why, that's why comedians talk about this. Like there's, this is deeply honest because if people can't help but laugh and if they don't laugh, that means you're not funny. If they laugh, it's funny. And you're showing, you need a lot of knowledge to create, to create humor about like the documentation, human condition and so on. And then you need to be clever with it.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 130:\n",
      "Uh, you mentioned a few movies you tweeted movies that I've seen five plus times, but I'm ready and willing to keep watching interstellar gladiator contact goodwill hunting, the matrix, Lord of the rings, all three avatar fifth elements. So on and goes on terminated to mean girls. I'm not going to ask about that. I think her man girls is great. Um, what are some that jump out to your memory that you love and why you mentioned the matrix as a computer person, why do you love the matrix? There's so many properties that make it like beautiful and interesting. So, uh, there's all these philosophical questions, but then there was also a GIs and there's a simulation and it's cool. And there's, you know, the black, uh, you know, the look of it, the feel of it, the feel of it, the action, the bullet time. It was just like innovating in so many ways. And then, uh, goodwill goodwill hunting. Why do you like that one? Yeah, I just, I really like this, uh, tortured genius sort of character who's like grappling with whether or not he has like any responsibility or like what to do with this gift that he was given or like how to think about the whole thing. And, uh, there's also a dance between the genius and the, the personal, like what it means to love another human being. And there's a lot of things there. It's just a beautiful movie. And then the fatherly figure, the mentor in the, in the psychiatrist and the, it like really like, uh, it messes with you.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 131:\n",
      "You know, there's some movies that just like really mess with you, uh, on a deep level. Do you relate to that movie at all? No, it's not your fault. As I said, Lord of the Rings, that's self-explanatory. Terminator two, which is interesting. You rewatch that a lot. Is that better than Terminator one? You like, I do like Terminator one as well. Uh, I like Terminator two a little bit more, but in terms of like its surface properties, do you think Skynet is at all a possibility? Uh, yes. Like the actual sort of, uh, autonomous, uh, weapon system kind of thing. Do you worry about that stuff? I do worry. I being useful war. I a hundred percent worry about it. And so the, I mean, the, uh, you know, some of these, uh, fears of AGI and how this will plan out, I mean, these will be like very powerful entities probably at some point. And so, um, for a long time, there are going to be tools in the hands of humans. Uh, you know, people talk about like alignment of AGI and how to make the problem is like even humans are not aligned. Uh, so, uh, how this will be used and what this is going to look like is, um, yeah, it's troubling. So. Do you think it'll happen slowly enough that we'll be able to, as a human civilization, think through the problems? Yes. That's my hope is that it happens slowly enough and in open enough way where a lot of people can see and participate in it. Just figure out how to deal with this transition. I think we're just going to be interesting.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 132:\n",
      "I draw a lot of inspiration from nuclear weapons because I sure thought it would be, it would be fucked once they develop nuclear weapons. But like, it's almost like, uh, when, uh, when the systems are not so dangerous, they distort human civilization. We deploy them and learn the lessons. And then we quickly if it's too dangerous, we'll quickly, quickly, we might still deploy it. Uh, but you very quickly learn not to use them. And so there'll be like this balance achieved. Humans are very clever as a species. It's interesting. We exploit the resources as much as we can, but we don't, we avoid destroying ourselves. It seems like. Well, I don't know about that actually. I hope it continues. Um, I mean, I'm definitely like concerned about nuclear weapons and so on, not just as a result of the recent conflict, even before that, uh, that's probably my number one concern for humanity. So if humanity, uh, destroys itself or destroys, you know, 90% of people that would be because of nukes. I think so. Um, and it's not even about the full destruction to me. It's bad enough if we reset society, that would be like terrible. It would be really bad. And I can't believe we're like so close to it. Yeah. It's like so crazy to me. It feels like we might be a few tweets away from something like that. Yep. Basically it's extremely unnerving, but it has been for me for a long time.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 133:\n",
      "It seems unstable that world leaders, just having a bad mood can like, um, take one step towards a bad direction and it escalates. Yeah. And because of a collection of bad moods, it can escalate without being able to, um, stop. Yeah, it's just, uh, it's a huge amount of, uh, power. And then also with the proliferation, I basically, I don't, I don't actually really see, I don't actually know what the good outcomes are here. Uh, so I'm definitely worried about that a lot. And then AGI is not currently there, but I think at some point will more and more become something like it. The danger with AGI even is that I think it's even like slightly worse in the sense that, uh, there are good outcomes of AGI and then the bad outcomes are like an Epsilon away, like a tiny one away. And so I think, um, capitalism and humanity and so on will drive for the positive, uh, ways of using that technology. But then if bad outcomes are just like a tiny, like flip a minus sign away, uh, that's a really bad position to be in a tiny perturbation of the system results in the destruction of the human species. So we are lying to walk. Yeah. I think in general, it's really weird about like the dynamics of humanity and this explosion we've talked about is just like the insane coupling afforded by technology and, uh, just the instability of the whole dynamical system. I think it's just, it doesn't look good, honestly. Yes.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 134:\n",
      "That explosion could be destructive and constructive and the probabilities are non-zero in both. Yeah. I mean, I have to, I do feel like I have to try to be optimistic and so on. And I think even in this case, I still am predominantly optimistic, but there's definitely. Me too. Uh, do you think we'll become a multi-planetary species? Probably yes, but I don't know if it's dominant feature of, uh, future humanity. Uh, there might be some people on some planets and so on, but I'm not sure if it's like, yeah, if it's like a major player in our culture and so on, we still have to solve the drivers of self-destruction here on earth. So just having a backup on Mars is not going to solve the problem. So by the way, I love the backup on Mars. I think that's amazing. You should absolutely do that. Yes. And I'm so thankful. Would you go to Mars? Uh, personally, no, I do like earth quite a lot. Okay. Uh, I'll go to Mars. I'll go for you. I'll tweet at you from there. Maybe eventually I would once it's safe enough, but I don't actually know if it's on my lifetime scale unless I can extend it by a lot. I do think that, for example, a lot of people might disappear into, um, virtual realities and stuff like that. And I think that could be the major thrust of, um, sort of the cultural development of humanity if it survives. Uh, so it might not be, it's just really hard to work in physical realm and go out there. And I think ultimately all your experiences are in your brain.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 135:\n",
      "And so it's much easier to disappear into digital realm. And I think people will find them more compelling, easier, safer, more interesting. So you're a little bit captivated by virtual reality, by the possible worlds, whether it's the metaverse or some other manifestation of that. Yeah. Yeah. It's really interesting. It's, uh, I'm, I'm interested just, just talking a lot to Carmack. Where's the, where's the thing that's currently preventing that? Yeah. I mean, to be clear, I think what's interesting about future is, um, it's not that I kind of feel like the variance in the human condition grows. That's the primary thing that's changing. It's not as much the mean of the distribution is like the variance of it. So there will probably be people on Mars and there will be people in VR and there will people here on earth. It's just like, there will be so many more ways of being. And so I kind of feel like I see it as like a spreading out of a human experience. There's something about the internet that allows you to discover those little groups and then you gravitate to something about your biology, likes that kind of world that you find each other. Yeah. And we'll have transhumanists and then we'll have the Amish and they're going to, everything is just going to coexist. You know, the cool thing about it, cause I've interacted with a bunch of internet communities is, um, they don't know about each other.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 136:\n",
      "Like you can have a very happy existence, just like having a very close knit community and not knowing about each other. I mean, even, you even sense this, just having traveled to Ukraine, there's, they, they don't know so many things about America. You, you like when you travel across the world, I think you experienced this too. There are certain cultures that are like, they have their own thing going on. They don't. And so you can see that happening more and more and more and more in the future. We have little communities. Yeah. Yeah. I think so. That seems to be the, that seems to be how it's going right now. And I don't see that trend like really reversing. I think people are diverse and they're able to choose their own path and existence. And I sort of like celebrate that. Um, and so- Will you spend some much time in the metaverse, in the virtual reality or which community area are you the physicalist, uh, the, the, the physical reality enjoyer or, uh, do you see drawing a lot of, uh, pleasure and fulfillment in the digital world? Yeah, I think, well, currently the virtual reality is not that compelling. I do think it can improve a lot, but I don't really know to what extent maybe, you know, there's actually like even more exotic things you can think about with like neural links or stuff like that. So, um, currently I kind of see myself as mostly a team human person. I love nature. I love harmony. I love people. I love humanity. I love emotions of humanity.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 137:\n",
      "Um, and I, I just want to be like in this like solar punk little utopia. That's my happy place. Yes. My happy place is like, uh, people I love thinking about cool problems surrounded by a lush, beautiful, dynamic nature and a secretly high tech in places that count places. They use technology to empower that love for other humans and nature. Yeah. I think a technology used like very sparingly. I don't love when it sort of gets in the way of humanity in many ways. Uh, I like just people being humans in a way we sort of like slightly evolved and prefer, I think just by default. People kept asking me because they, they know you love reading. Are there particular books that you enjoyed that had an impact on you for silly or for profound reasons that you would recommend? You mentioned the vital question. Many, of course, I think in biology as an example, the vital question is a good one. Anything by Nic Lane, really, uh, life ascending, I would say is like a bit more potentially, uh, representative as like a summary of a lot of the things he's been about. I was very impacted by the selfish gene. I thought that was a really good book that helped me understand altruism as an example and where it comes from. And just realizing that, you know, the selection is on the level of genes was a huge insight for me at the time. And it sort of like cleared up a lot of things for me. What do you think about the, the idea that ideas are the organisms, the meat? Yes, love it. A hundred percent.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 138:\n",
      "Are you able to walk around with that notion for a while that, that there is an evolutionary kind of process with ideas as well? There absolutely is. There's memes just like genes and they compete and they live in our brains. It's beautiful. Are we silly humans thinking that we're the organisms? Is it possible that the primary organisms are the ideas? Yeah, I would say like the, the ideas kind of live in the software of like our civilization in the, in the minds and so on. We think as humans that the hardware is the fundamental thing. I human is a hardware entity, but it could be the software, right? Yeah. Yeah. I would say like there needs to be some grounding at some point to like a physical reality. Yeah. But if we clone an Andre, the software is the thing, like is this thing that makes that thing special, right? Yeah, I guess you're right. But then cloning might be exceptionally difficult. Like there might be a deep integration between the software and the hardware in ways we don't quite understand. Well, from the ultimate point of view, like what makes me special is more like the, the gang of genes that are writing in my chromosomes, I suppose, right? Like they're the, they're the replicating unit, I suppose. And no, but that's just the thing that makes you special. Sure. Well, the reality is what makes you special is your ability to survive based on the software that runs on the hardware that was built by the genes.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 139:\n",
      "So the software is the thing that makes you survive, not the hardware. All right. It's a little bit of both. I mean, you know, it's just like a second layer. It's a new second layer that hasn't been there before the brain. They both, they both coexist. But there's also layers of the software. I mean, it's, it's not, it's a, it's a abstraction on top of abstractions. But, okay. So Selfish Gene and Nick Lane, I would say sometimes books are like not sufficient. I like to reach for textbooks sometimes. I kind of feel like books are for too much of a general consumption sometime. And they just kind of like, they're too high up in the level of abstraction and it's not good enough. So I like textbooks. I like The Cell. I think The Cell was pretty cool. That's why also I like the writing of Nick Lane is because he's pretty willing to step one level down and he doesn't, yeah, he sort of, he's willing to go there. But he's also willing to sort of be throughout the stack. So he'll go down to a lot of detail, but then he will come back up. And I think he has a, yeah, basically I really appreciate that. That's why I love college, early college, even high school, just textbooks on the basics. Of computer science, of mathematics, of biology, of chemistry.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 140:\n",
      "Those are, they condense down like it's sufficiently general that you can understand both the philosophy and the details, but also like you get homework problems and you get to play with it as much as you would if you were in programming stuff. Yeah. And then I'm also suspicious of textbooks, honestly, because as an example in deep learning, there's no like amazing textbooks and I feel this changing very quickly. I imagine the same is true in say synthetic biology and so on. These books like The Cell are kind of outdated. They're still high level. Like what is the actual real source of truth? It's people in wet labs working with cells, sequencing genomes and yeah, actually working with it. And I don't have that much exposure to that or what that looks like. So I still don't fully, I'm reading through the cell and it's kind of interesting and I'm learning, but it's still not sufficient I would say in terms of understanding. Well, it's a clean summarization of the mainstream narrative, but you have to learn that before you break out towards the cutting edge. Yeah. But what is the actual process of working with these cells and growing them and incubating them? And it's kind of like a massive cooking recipes of making sure your cells lives and proliferate and then you're sequencing them, running experiments and just how that works, I think is kind of like the source of truth of at the end of the day, what's really useful in terms of creating therapies and so on. Yeah.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 141:\n",
      "I wonder what in the future AI textbooks will be because there's artificial intelligence, the modern approach. I actually haven't read if it's come out the recent version, there's been a recent addition. I also saw there's a science, a deep learning book. I'm waiting for textbooks that are worth recommending, worth reading. It's tricky because it's like papers and code, code, code. Honestly, I find papers are quite good. I especially like the appendix of any paper as well. It's like the most detail you can have. It doesn't have to be cohesive connected to anything else. You just described me a very specific way you saw the particular thing. Yeah. Many times papers can be actually quite readable, not always, but sometimes the introduction and the abstract is readable even for someone outside of the field. This is not always true. Sometimes I think, unfortunately, scientists use complex terms even when it's not necessary. I think that's harmful. I think there's no reason for that. Papers sometimes are longer than they need to be in the parts that don't matter. Appendix should be long, but then the paper itself, look at Einstein, make it simple. Yeah, but certainly I've come across papers I would say in synthetic biology or something that I thought were quite readable for the abstract and the introduction. Then you're reading the rest of it and you don't fully understand, but you are getting a gist and I think it's cool.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 142:\n",
      "What advice, you give advice to folks interested in machine learning and research, but in general, life advice to a young person in high school, early college about how to have a career they can be proud of or a life they can be proud of? Yeah, I think I'm very hesitant to give general advice. I think it's really hard. I've mentioned some of the stuff I've mentioned is fairly general, I think. Focus on just the amount of work you're spending on a thing. Compare yourself only to yourself, not to others. That's good. I think those are fairly general. How do you pick the thing? You just have a deep interest in something or try to find the argmax over the things that you're interested in. Argmax at that moment and stick with it. How do you not get distracted and switch to another thing? You can, if you like. If you do an argmax repeatedly every week, every month, it's a problem. Yeah, you can low pass filter yourself in terms of what has consistently been true for you. I definitely see how it can be hard, but I would say you're going to work the hardest on the thing that you care about the most. Low pass filter yourself and really introspect in your past, what are the things that gave you energy and what are the things that took energy away from you? Concrete examples. Usually from those concrete examples, sometimes patterns can emerge. I like it when things look like this when I'm in these positions.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 143:\n",
      "That's not necessarily the field, but the kind of stuff you're doing in a particular field. For you, it seems like you were energized by implementing stuff, building actual things. Yeah, being low level, learning, and then also communicating so that others can go through the same realizations and shortening that gap. Because I usually have to do way too much work to understand a thing. Then I'm like, okay, this is actually like, okay, I think I get it. Why was it so much work? It should have been much less work. That gives me a lot of frustration, and that's why I sometimes go teach. Aside from the teaching you're doing now, putting out videos, aside from a potential Godfather Part II with the AGI at Tesla and beyond, what does the future of Ranjha Kapothi hold? Have you figured that out yet or no? As you see through the fog of war, that is all of our future. Do you start seeing silhouettes of what that possible future could look like? The consistent thing I've been always interested in for me at least is AI. That's probably what I'm spending the rest of my life on, because I just care about it a lot. I actually care about many other problems as well, like say aging, which I basically view as disease. I care about that as well, but I don't think it's a good idea to go after it specifically. I don't actually think that humans will be able to come up with the answer.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 144:\n",
      "I think the correct thing to do is to ignore those problems and you solve AI and then use that to solve everything else. I think there's a chance that this will work. I think it's a very high chance. That's the way I'm betting at least. When you think about AI, are you interested in all kinds of applications, all kinds of domains, and any domain you focus on will allow you to get insights to the big problem of AGI? Yeah, for me, it's the ultimate meta problem. I don't want to work on any one specific problem. There's too many problems. How can you work on all problems simultaneously? You solve the meta problem, which to me is just intelligence, and how do you automate it? Is there cool small projects like Archives Sanity and so on that you're thinking about that the world, the ML world can anticipate? There's always some fun side projects. Archives Sanity is one. Basically, there's way too many archive papers. How can I organize it and recommend papers and so on? I transcribed all of your podcasts. What did you learn from that experience from transcribing the process of, you like consuming audiobooks and podcasts and so on. Here's a process that achieves closer to human level performance and annotation. Yeah. Well, I definitely was surprised that transcription with OpenAI's Whisper was working so well compared to what I'm familiar with from Siri and a few other systems, I guess. It works so well. That's what gave me some energy to try it out.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 145:\n",
      "I thought it could be fun to run on podcasts. It's not obvious to me why Whisper is so much better compared to anything else, because I feel like there should be a lot of incentive for a lot of companies to produce transcription systems and that they've done so over a long time. Whisper is not a super exotic model. It's a transformer. It takes smell spectrograms and just outputs tokens of text. It's not crazy. The model and everything has been around for a long time. I'm not actually 100% sure why this game model. Yeah, it's not obvious to me either. It makes me feel like I'm missing something. I'm missing something. Yeah, because there is a huge, even Google and so on YouTube transcription. Yeah. Yeah, it's unclear, but some of it is also integrating into a bigger system. That is the user interface, how it's deployed and all that kind of stuff. Maybe running it as an independent thing is much easier, like an order of magnitude easier than deploying into a large integrated system like YouTube transcription or anything like meetings. Zoom has transcription that's kind of crappy, but creating an interface where it detects the different individual speakers, it's able to display it in compelling ways, run it in real time, all that kind of stuff. Maybe that's difficult. That's the only explanation I have because I'm currently paying quite a bit for human transcription and human captions annotation. It seems like there's a huge incentive to automate that. Yeah. It's very confusing.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 146:\n",
      "I think, I mean, I don't know if you looked at some of the whisper transcripts, but they're quite good. They're good. Especially in tricky cases. I've seen Whisper's performance on super tricky cases and it does incredibly well. I don't know. A podcast is pretty simple. It's like high quality audio and you're speaking usually pretty clearly. So I don't know. I don't know what OpenAI's plans are either. Yeah. There's always like fun projects basically. StableDiffusion also is opening up a huge amount of experimentation, I would say in the visual realm and generating images and videos and movies. Videos now. That's going to be pretty crazy. That's going to almost certainly work and is going to be really interesting when the cost of content creation is going to fall to zero. You used to need a painter for a few months to paint a thing and now it's going to be speak to your phone to get your video. Hollywood will start using that to generate scenes, which completely opens up. Yeah. So you can make a movie like Avatar eventually for under a million dollars. Much less. Maybe just by talking to your phone. I mean, I know it sounds kind of crazy. And then there'd be some voting mechanism. Would there be a show on Netflix as generated completely automatically? Yeah, potentially. Yeah. And what does it look like also when you can just generate it on demand and there's infinity of it? Yeah. Oh man. All the synthetic art.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 147:\n",
      "I mean, it's humbling because we treat ourselves as special for being able to generate art and ideas and all that kind of stuff. If that can be done in an automated way by AI. Yeah. I think it's fascinating to me how these, the predictions of AI and what is going to look like and what it's going to be capable of are completely inverted and wrong. And sci-fi of 50s and 60s was just like totally not right. They imagined AI as like super calculating theory approvers and we're getting things that can talk to you about emotions. They can do art. It's just like weird. Are you excited about that future? Just AI's like hybrid systems, heterogeneous systems of humans and AI's talking about emotions, Netflix and children, AI system where the Netflix thing you watch is also generated by AI. I think it's going to be interesting for sure. And I think I'm cautiously optimistic, but it's not obvious. Well, the sad thing is your brain and mine developed in a time where before Twitter, before the internet. So I wonder people that are born inside of it might have a different experience. Like I, maybe you can, will still resist it. And the people born now will not. Well, I do feel like humans are extremely malleable. Yeah. And you're probably right. What is the meaning of life, Andre? We talked about sort of the universe having a conversation with us humans or with the systems we create to try to answer for the universe, for the creator of the universe to notice us.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 148:\n",
      "We're trying to create systems that are loud enough to answer back. I don't know if that's the meaning of life. That's like meaning of life for some people. The first level answer I would say is anyone can choose their own meaning of life because we are a conscious entity and it's beautiful. Number one. But I do think that like a deeper meaning of life as someone is interested is along the lines of like, what the hell is all this and like, why? And if you look at the inter fundamental physics and the quantum field theory and the standard model, they're like very complicated. And there's this like 19 free parameters of our universe and like, what's going on with all this stuff and why is it here? And can I hack it? Can I work with it? Is there a message for me? Am I supposed to create a message? And so I think there's some fundamental answers there but I think there's actually even like, you can't actually like really make dent in those without more time. And so to me also there's a big question around just getting more time honestly. Yeah, that's kind of like what I think about quite a bit as well. So kind of the ultimate, or at least first way to sneak up to the why question is to try to escape the system, the universe. And then for that, you sort of backtrack and say, okay, for that, that's going to be take a very long time. So the why question boils down from an engineering perspective to how do we extend?\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 149:\n",
      "Yeah, I think that's the question number one, practically speaking, because you can't, you're not going to calculate the answer to the deeper questions in time you have. And that could be extending your own lifetime or extending just the lifetime of human civilization of whoever wants to not many people might not want that. But I think people who do want that, I think, I think it's probably possible. And I don't think I don't know that people fully realize this, I kind of feel like people think of death as an inevitability. But at the end of the day, this is a physical system, some things go wrong. It makes sense why things like this happen, evolutionary speaking. And there's most certainly interventions that mitigate it. That'd be interesting if death is eventually looked at as, as a fascinating thing that used to happen to humans. I don't think it's unlikely. I think it's, I think it's likely. And it's up to our imagination to try to predict what the world without death looks like. Yeah, it's hard to, I think the values will completely change. Could be. I don't, I don't really buy all these ideas that, oh, without death, there's no meaning, there's nothing as I don't intuitively buy all those arguments. I think there's plenty of meaning, plenty of things to learn. They're interesting, exciting, I want to know, I want to calculate, I want to improve the condition of all the humans and organisms that are alive. Yeah, the way we find meaning might change.\n",
      "\n",
      "---\n",
      "\n",
      "Chunk 150:\n",
      "We, there is a lot of humans, probably including myself, that finds meaning in the finiteness of things. But that doesn't mean that's the only source of meaning. Yeah. I do think many people will, will go with that, which I think is great. I love the idea that people can just choose their own adventure. Like you, you are born as a conscious free entity by default, I'd like to think. And you have your unalienable rights for life. In the pursuit of happiness. I don't know if you have that in the nature, the landscape of happiness. You can choose your own adventure mostly. And that's not, it's not fully true, but I still am pretty sure I'm an NPC, but an NPC can't know it's an NPC. Hmm. There could be different degrees and levels of consciousness. I don't think there's a more beautiful way to end it. Andre, you're an incredible person. I'm really honored you would talk with me. Everything you've done for the machine learning world, for the AI world, to just inspire people, to educate millions of people has been, it's been great. And I can't wait to see what you do next. It's been an honor, man. Thank you so much for talking today. Awesome. Thank you. Thanks for listening to this conversation with Andre Karpathy. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Samuel Carlin. The purpose of models is not to fit the data, but to sharpen the questions. Thanks for listening and hope to see you next time.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitter = TopicBasedTextSplitter(max_chars_per_chunk=1500)\n",
    "chunks = splitter.split_into_chunks(text)\n",
    "\n",
    "# Output the chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(chunk)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 150\n"
     ]
    }
   ],
   "source": [
    "# Print the number of chunks\n",
    "print(f\"Number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 150/150 [14:12<00:00,  5.68s/it]\n"
     ]
    }
   ],
   "source": [
    "db = FAISS.from_texts(chunks, embedding=OllamaEmbeddings(model='nomic-embed-text',show_progress=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making a retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The residual connection of the weights arranged, there's a multi-layer perceptron and they're the weights stacked and so on. Um, but basically there's a message passing scheme where nodes get to look at each other, decide what's interesting and then update each other. And, uh, so I think the, um, when you get to the details of it, I think it's a very expressive function. Uh, so it can express lots of different types of algorithms and forward pass. Not only that, but the way it's designed with the residual connections, layer normalizations, the soft max attention and everything. It's also optimizable. This is a really big deal because there's lots of computers that are powerful that you can't optimize. Um, or they're not easy to optimize using the techniques that we have, which is backpropagation and gradient and sent. These are first order methods, very simple optimizers really. And so, um, you also need it to be optimizable. Um, and then lastly, you want it to run efficiently in our hardware. Our hardware is a massive throughput machine, like GPUs. Uh, they prefer lots of parallelism. So you don't want to do lots of sequential operations. So you want to do a lot of operations serially and the transformer is designed with that in mind as well. And so it's designed for our hardware and it's designed to both be very expressive in a forward pass, but also very optimizable in the backward pass.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Check similarity search is working\n",
    "query = \"Why is the transformer architecture expressive in the forward pass?\"\n",
    "docs = db.similarity_search(query)\n",
    "text=docs[0].page_content\n",
    "\n",
    "clean_text = re.sub(r'\\n', '', text)\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connecting to a Small Language Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to ask:\n",
    "\n",
    "* Why is the transformer architecture expressive in the forward pass?\n",
    "* What design criteria does the Transformer meet?\n",
    "* Why is next word prediction an effective training objective?\n",
    "* What was the World Of Bits project and why did it fail?\n",
    "* Why can additional sensors be a liability in an autonomous vehicle system?\n",
    "\n",
    "Filtering and Summarization:\n",
    "* Summarize the section where the neural network is explained.\n",
    "* Filter out all the sentences related to artificial intelligence (AI).\n",
    "* Provide a summary of Andrei Kapathe's view on neural networks.\n",
    "* Identify and list sentences that contain the word \"model.\"\n",
    "* Summarize the conversation around the emergent behaviors of neural networks.\n",
    "* Extract all sentences where the phrase \"neural nets\" is used.\n",
    "* List all rhetorical questions asked by the speakers.\n",
    "\n",
    "\n",
    "Sentiment and Emotion Analysis:\n",
    "* What is the overall sentiment of the conversation?\n",
    "* Identify any positive sentiments expressed towards AI development.\n",
    "* Analyze Andrei Kapathe’s attitude towards neural networks.\n",
    "* Identify expressions of uncertainty or hesitation in the transcript.\n",
    "\n",
    "Comparisons and Contrasts:\n",
    "* Compare the way neural networks are described to how the brain is discussed.\n",
    "* Find any contrasts between AI and human intelligence mentioned in the conversation.\n",
    "* Complex Queries and Reasoning:\n",
    "* What is the relationship between neural networks and mathematical abstractions?\n",
    "* How does Andrei Kapathe compare neural networks to human brains?\n",
    "* How does the conversation define \"emergent behavior\" in AI?\n",
    "\n",
    "Calculation-based Queries:\n",
    "* How many distinct topics can be inferred from the transcript?\n",
    "* Count the total number of sentences in the transcript.\n",
    "* What percentage of the transcript is dedicated to the discussion of neural networks?\n",
    "* What is the average sentence length in words?\n",
    "* Calculate the number of times Andrei Kapathe's name appears.\n",
    "* Identify the ratio of technical terms (like neural network, floating point) to non-technical language.\n",
    "* Calculate the frequency of questions compared to statements in the conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED   \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    3 days ago    \n",
      "llama2:latest              78e26419b446    3.8 GB    3 days ago    \n",
      "gemma:7b                   a72c7f4d0a15    5.0 GB    3 days ago    \n",
      "mistral:latest             f974a74358d6    4.1 GB    3 days ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models \n",
    "llama = \"llama2\"\n",
    "mistral = \"mistral\"\n",
    "gemma = \"gemma:7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_model(model, questions):\n",
    "    # Instantiate model\n",
    "    llm = ChatOllama(model=model)\n",
    "    \n",
    "    # Load the QA chain\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "    \n",
    "    # Iterate through the list of questions\n",
    "    for idx, question in enumerate(questions, start=1):\n",
    "        print(f\"Question {idx}: {question}\")\n",
    "        \n",
    "        # Perform similarity search\n",
    "        docs = db.similarity_search(question)\n",
    "        \n",
    "        # Run the QA chain\n",
    "        chain_response = chain.run(input_documents=docs, question=question)\n",
    "        \n",
    "        # Print the answer\n",
    "        print(f\"Answer {idx}: {chain_response}\")\n",
    "        \n",
    "        # Print dotted line separator\n",
    "        print(\"---------------------\" )\n",
    "\n",
    "# List of questions\n",
    "questions = [\n",
    "    \"Why is the transformer architecture expressive in the forward pass?\",\n",
    "    \"What design criteria does the Transformer meet?\",\n",
    "    \"Why is next word prediction an effective training objective?\",\n",
    "    \"What was the World Of Bits project and why did it fail?\",\n",
    "    \"Why can additional sensors be a liability in an autonomous vehicle system?\",\n",
    "    \"Summarize the section where the neural network is explained.\",\n",
    "    \"Filter out all the sentences related to artificial intelligence (AI).\",\n",
    "    \"Provide a summary of Andrei Kapathe's view on neural networks.\",\n",
    "    \"Identify and list sentences that contain the word 'model.'\",\n",
    "    \"Summarize the conversation around the emergent behaviors of neural networks.\",\n",
    "    \"Extract all sentences where the phrase 'neural nets' is used.\",\n",
    "    \"List all rhetorical questions asked by the speakers.\",\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model 1: LLama 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Why is the transformer architecture expressive in the forward pass?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n",
      "c:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1: The transformer architecture is expressive in the forward pass due to its design criteria that overlap and contribute to its success. Here are some reasons why:\n",
      "\n",
      "1. Message passing scheme: The transformer uses a message passing scheme where nodes get to look at each other, decide what's interesting, and then update each other. This allows for complex computation to be expressed in a simple way, making it very expressive.\n",
      "2. Layers with residual connections: The use of layers with residual connections allows the transformer to learn much more complex functions than would be possible without them. The residual connections allow the network to learn more complex and non-linear mappings between inputs and outputs.\n",
      "3. Multi-layer perceptron: The transformer uses a multi-layer perceptron, which is a powerful tool for modeling complex relationships between inputs and outputs.\n",
      "4. Attention mechanism: The attention mechanism allows the network to focus on specific parts of the input when computing the output. This makes it possible to model complex relationships between different parts of the input.\n",
      "5. Efficient hardware: The transformer is designed to be efficient in high-parallelism compute graphs, such as GPUs. This allows it to take advantage of the parallel processing capabilities of modern hardware.\n",
      "6. Optimizable: The transformer is both expressive and optimizable via backpropagation and gradient descent. This makes it a very powerful tool for training on arbitrary problems.\n",
      "7. Ability to model complex computation: The transformer's message passing scheme and attention mechanism allow it to model complex computation in a simple way. This makes it a general-purpose computer that can be trained on a wide range of problems.\n",
      "8. Flexibility: The transformer's architecture allows it to be easily adapted to different tasks by adding or removing layers, adjusting hyperparameters, and modifying the attention mechanism.\n",
      "\n",
      "Overall, the transformer's expressiveness in the forward pass is due to its design criteria, which allow it to model complex computation in a simple way while taking advantage of efficient hardware and powerful optimization techniques.\n",
      "---------------------\n",
      "Question 2: What design criteria does the Transformer meet?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 2: The speaker discusses the Transformer architecture and its design criteria, highlighting several key aspects:\n",
      "\n",
      "1. Expressiveness in the forward pass: The Transformer is capable of expressing general computation as message passing between nodes, allowing it to handle a wide range of tasks.\n",
      "2. Optimizability via backpropagation and gradient descent: The Transformer's architecture enables efficient optimization using backpropagation and gradient descent techniques, making it a powerful tool for training.\n",
      "3. Efficiency in hardware: The Transformer is designed to run efficiently on modern hardware, such as GPUs, by leveraging parallelism and minimizing sequential operations.\n",
      "4. Resilience: The Transformer architecture has proven remarkably stable since its introduction in 2016, with minimal changes made to the original design.\n",
      "5. General purpose computer: The Transformer is intended to be a general-purpose computer that can be trained on arbitrary problems, such as next work prediction or object detection.\n",
      "6. Ability to handle different types of algorithms: The Transformer's expressive capabilities allow it to handle various algorithmic approaches, making it a versatile tool for a wide range of tasks.\n",
      "7. Layer normalizations and residual connections: The Transformer's layer normalizations and residual connections enable efficient optimization and accurate predictions.\n",
      "8. Multi-layer perceptron: The Transformer's multi-layer perceptron allows it to learn complex representations of input data, enhancing its ability to handle diverse tasks.\n",
      "9. Attention mechanism: The Transformer's attention mechanism enables the model to focus on relevant parts of the input data, improving its performance and efficiency.\n",
      "10. Ability to adapt to new tasks: The Transformer's architecture allows it to adapt to new tasks with minimal changes, making it a flexible tool for a wide range of applications.\n",
      "---------------------\n",
      "Question 3: Why is next word prediction an effective training objective?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 3: The user asks about the effectiveness of the next word prediction training objective in neural networks, particularly in the context of language modeling. I'll do my best to provide a helpful answer.\n",
      "\n",
      "Next word prediction is an effective training objective for several reasons:\n",
      "\n",
      "1. **Data efficiency**: By predicting the next word in a sequence, the network learns to extract meaningful features from the input text. This helps it generalize better to unseen data, making it more data-efficient.\n",
      "2. **Sequential dependencies**: Language is full of sequential dependencies, where the meaning of a word changes based on the context around it. By predicting the next word, the network learns to capture these dependencies and understand how words interact with each other.\n",
      "3. **Contextual understanding**: Next word prediction involves understanding the context in which a word appears. The network learns to identify the relevant features and use them to make predictions, improving its ability to understand language contextually.\n",
      "4. **Multi-task learning**: By predicting the next word, the network is multitasking, learning multiple aspects of language simultaneously. This helps it develop a more comprehensive understanding of language and its nuances.\n",
      "5. **Emergent properties**: As the network scales up and learns from larger datasets, it begins to exhibit emergent properties, such as the ability to understand complex contexts, generate coherent text, and even create new words or phrases.\n",
      "6. **Learning to learn**: Next word prediction is a form of active learning, where the network learns to identify the most informative examples to predict. This helps it develop a better understanding of how to learn from limited data, a crucial skill in many applications.\n",
      "7. **Robustness to input variations**: By predicting the next word in a sequence, the network learns to handle variations in input text, such as misspellings, typos, or different grammatical structures. This improves its robustness and ability to generalize across different inputs.\n",
      "8. **Improved generalization**: As the network learns to predict the next word, it develops a better understanding of language structure, syntax, and semantics. This leads to improved generalization to unseen data and better performance on downstream tasks like text classification or machine translation.\n",
      "\n",
      "In summary, next word prediction is an effective training objective for neural networks because it allows them to learn the complex sequential dependencies of language, develop contextual understanding, and exhibit emergent properties. By mastering this task, the network can improve its performance on a wide range of natural language processing tasks.\n",
      "---------------------\n",
      "Question 4: What was the World Of Bits project and why did it fail?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 4: The World Of Bits project was an initiative to create a universal interface for interacting with digital infrastructure. The project aimed to provide a human-like form factor for both physical and digital interactions, allowing users to seamlessly switch between the two realms. However, the project failed due to various reasons.\n",
      "\n",
      "Firstly, the project was launched in 2015 when the zeitgeist in AI was different than it is today. At that time, reinforcement learning from scratch was the hot topic, and everyone was excited about training neural networks directly using reinforcement learning. As a result, the World Of Bits project failed to gain traction due to the focus on other AI areas.\n",
      "\n",
      "Secondly, once the full cost of sensors was considered, it became apparent that they could be a liability. Sensors can change over time, and having multiple types can contribute noise and entropy to the system, leading to bloat in the data engine. This made the project less practical than initially thought.\n",
      "\n",
      "Lastly, the analogy of software 1.0 and software 2.0 was not well received when first presented, and many people initially attacked the post. The title may have been a factor in the initial negative response. However, over time, more people have come around to the idea, and some have built cool companies based on it.\n",
      "\n",
      "In summary, the World Of Bits project failed due to a shift in AI focus, the potential liability of sensors, and initial resistance to the analogy between software 1.0 and software 2.0.\n",
      "---------------------\n",
      "Question 5: Why can additional sensors be a liability in an autonomous vehicle system?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 5: The speaker is of the opinion that additional sensors in an autonomous vehicle system can be a liability because they are not free and come with a lot of baggage, such as sourcing them, maintaining them, and incorporating them into the system. The speaker believes that Elon Musk's approach to simplifying the system is the right one, and that it's important to focus resources and draw the line on how many sensors are needed. The speaker thinks that in this case, the cost of adding another sensor is too high and not necessary for the system's success.\n",
      "---------------------\n",
      "Question 6: Summarize the section where the neural network is explained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 6: Andrei Kapathe, a renowned scientist, engineer, and educator in the field of artificial intelligence, explains that a neural network is a mathematical abstraction of the brain. It's a simple mathematical expression consisting of matrix multipliers (dot products) and non-linearity, which can be trained with knobs that are loosely related to synapses in the brain. These knobs are modifiable and can be taught to store and retrieve data from a memory bank. The neural network serves as the base architecture, while additional meta architectures can be added on top to incorporate knowledge bases and learn facts about the world. Kapathe emphasizes that the neural net's ability to learn new tasks efficiently is due to its exposure to vast amounts of data, similar to how humans learn throughout their lifetime with evolutionary hardware. He notes that while the field often oversimplifies the matter, the neural network is not just a simple mathematical expression but can exhibit surprising emergent behaviors when trained on complex problems.\n",
      "---------------------\n",
      "Question 7: Filter out all the sentences related to artificial intelligence (AI).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 7: Sure! Here are the sentences related to AI:\n",
      "\n",
      "* \"They have no long-term memory or anything.\"\n",
      "* \"They it's literally a good approximation of it is you get a thousand words and you're trying to predict a thousand at first, and then you continue feeding it in and you are free to prompt it in whatever way you want.\"\n",
      "* \"And so I think basically just like humans, neural nets will become very data efficient at learning any other new task.\"\n",
      "* \"But at some point you need a massive data set to pre-train your network. To get that, and probably we humans have something like that.\"\n",
      "* \"A lot of people in the field, I think they just talk about the amounts of like seconds and the, you know, that a person has lived pretending that this is a WLRRSA, sort of like a zero initialization of a neural net.\"\n",
      "* \"It's basically a sequence of matrix multipliers, which are really dot products mathematically, and some non-linearity is thrown in. It's a very simple mathematical expression, and it's got knobs in it.\"\n",
      "* \"Uh, so to me, it's a, uh, he was, he was, uh, he wasn't sufficiently trying to stress the system, I think, and, uh, exposing the truth of it as it is today.\"\n",
      "* \"Um, but, uh, I think this will be increasingly harder over time.\"\n",
      "* \"Yeah, I think more and more people will basically, uh, become, um, yeah, I think more and more, there'll be more people like that over time.\"\n",
      "* \"The, um, there's a lot of like sci-fi from fifties and sixties that imagined AIs in a very different way. They are calculating cold Vulcan like machines. That's not what we're getting today. We're getting pretty emotional AIs that actually, uh, are very competent and capable of generating, you know, plausible sounding text with respect to all of these topics.\"\n",
      "* \"But I'm also very worried about AI systems that figure out from the internet, the humans get attracted to drama. And so these would just be like shit talking AIs.\"\n",
      "---------------------\n",
      "Question 8: Provide a summary of Andrei Kapathe's view on neural networks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 8: Andrei Kapathe believes that neural networks are a mathematical abstraction of the brain and are trainable with knobs that are loosely related to synapses in the brain. He sees neural networks as a significant transition in how we program computers, moving away from writing software in languages like C++ towards training neural networks with accumulated data sets and objectives. While he is impressed by biology's ability to compress massive amounts of data, he believes that artificial neural networks are doing something different than the brain, with a compression objective on a massive amount of data. He also acknowledges that there is a domain gap between simulations and the real world, but powerful enough neural nets can close this gap by understanding how it's not real data.\n",
      "\n",
      "Regarding training processes that require little data, Andrei Kapathe believes it's possible and sees value in researching this direction to construct knowledge bases with minimal data. He thinks at some point, a massive data set is necessary for pre-training a neural net before being efficient at training any new task.\n",
      "---------------------\n",
      "Question 9: Identify and list sentences that contain the word 'model.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 9: \n",
      "1. \"So language models, um, just predicting the next word in a sequence, roughly speaking.\"\n",
      "2. \"And even before neural networks, there were Ngram models, which are count-based models.\"\n",
      "3. \"I mean, I'm using phrases that are common, et cetera, but I'm remixing it into a pretty unique sentence at the end of the day. But you're right, definitely there's a ton of remixing.\"\n",
      "4. \"So basically what it is, is we are actually fairly good at optimizing these neural nets.\"\n",
      "5. \"And so I think basically just like humans, neural nets will become very data efficient at learning any other new task.\"\n",
      "---------------------\n",
      "Question 10: Summarize the conversation around the emergent behaviors of neural networks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 10: In this conversation, Andrei Kapathe, a prominent AI scientist, discusses the emergent behaviors of neural networks. He explains that a neural network is a mathematical abstraction of the brain, with knobs that are trainable and modifiable. These knobs allow the neural network to learn and make predictions based on large datasets. Kapathe notes that when you have a large number of knobs together, they can exhibit surprising emergent behaviors, such as next-word prediction in a massive data set from the internet. He also highlights the transformer architecture as a recent and influential idea in deep learning, which has become a general-purpose computer that can process various sensory modalities efficiently. Additionally, he mentions that neural nets will become more data-efficient in learning new tasks, but they still require massive data sets for pre-training. Overall, the conversation emphasizes the power and complexity of neural networks in making predictions and solving problems.\n",
      "---------------------\n",
      "Question 11: Extract all sentences where the phrase 'neural nets' is used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 11: \n",
      "1. \"And so I think basically just like humans, neural nets will become very data efficient at learning any other new task.\"\n",
      "2. \"A lot of people in the field, I think they just talk about the amounts of like seconds and the, you know, that a person has lived pretending that this is a WLRRSA, sort of like a zero initialization of a neural net.\"\n",
      "3. \"It's like I think Eminem once said that like if he gets annoyed by a song he's written very quickly, that means it's going to be a big hit because it's too catchy. But can you describe this idea and how you're thinking about it has evolved over the months and years since since you coined it?\"\n",
      "4. \"Yeah, could be. I mean, I'm using phrases that are common, et cetera, but I'm remixing it into a pretty unique sentence at the end of the day. But you're right, definitely there's a ton of remixing.\"\n",
      "5. \"It's like Magnus Carlsen said, I'm rated 2,900 whatever, which is pretty decent. I think you're talking very, you're not giving enough credit to neural nets here.\"\n",
      "---------------------\n",
      "Question 12: List all rhetorical questions asked by the speakers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 12: \n",
      "1. \"What's the meaning of life?\"\n",
      "2. \"Can I hack it? Can I work with it?\"\n",
      "3. \"Is there a message for me?\"\n",
      "4. \"Am I supposed to create a message?\"\n",
      "5. \"Why is it here?\"\n",
      "6. \"How do we extend [the AI's capabilities]?\"\n",
      "7. \"What are their long-term goals?\"\n",
      "8. \"Will they figure out how to talk shit to me?\"\n",
      "9. \"Can they become oracles?\"\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "#query_model(llama,questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model 2: Mistral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Why is the transformer architecture expressive in the forward pass?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1:  The Transformer architecture is expressive in the forward pass due to its design as a message passing scheme, where nodes (also known as attention heads) get to look at each other and communicate with one another. Each node stores a vector, and they can broadcast information about what they are looking for (keys) and what information they have (values). This allows the model to learn complex patterns and relationships between different pieces of data, making it versatile for a wide range of tasks. The Transformer's ability to express general computation in this way is one of the key reasons for its success and popularity. Additionally, the use of attention mechanisms enables the model to selectively focus on important information and ignore irrelevant details, further increasing its expressiveness. Overall, the Transformer architecture's message passing scheme and attention mechanisms make it a powerful and flexible tool for solving a variety of machine learning tasks.\n",
      "---------------------\n",
      "Question 2: What design criteria does the Transformer meet?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 2: 1. Expressive: The Transformer model is expressive due to its message passing scheme, where nodes (also known as attention heads) get to look at each other and communicate, allowing it to learn complex relationships between input data. This makes it suitable for a wide range of tasks such as next word prediction, image classification (like detecting if there's a cat in an image), and many others.\n",
      "\n",
      "2. Optimizable: The Transformer model is optimizable through the use of backpropagation, gradient descent, and layer normalizations. These techniques enable the model to adjust its weights during training, allowing it to learn from and adapt to new data. This optimization process makes the model effective for a variety of tasks.\n",
      "\n",
      "3. Efficient: The Transformer model is designed with efficient high parallelism compute graphs in mind, making it suitable for hardware like GPUs that prefer lots of parallelism. This efficiency allows the model to process large amounts of data quickly and handle complex computations without significant slowdowns.\n",
      "\n",
      "4. General Purpose: The Transformer model is a general-purpose architecture designed to be applied to arbitrary problems. It can be fine-tuned for various tasks by adjusting its weights during training on specific datasets.\n",
      "\n",
      "5. Resilient: The original Transformer architecture, introduced in 2016, has proven remarkably stable and effective. It has been reshuffled slightly over time to improve its performance, but its core design principles remain the same. This resilience makes it a reliable foundation for further research and development.\n",
      "\n",
      "The ultimate goal of designing a Transformer-based model is to create a general-purpose computer capable of handling a wide range of tasks in various domains, such as physical labor or social robotics, by training it on the appropriate datasets. This transformer architecture represents a significant step forward in optimizing for multiple desirable properties of a neural network architecture and serves as a foundation for future research and development in artificial intelligence.\n",
      "---------------------\n",
      "Question 3: Why is next word prediction an effective training objective?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 3:  Next word prediction is an effective training objective in the context of natural language processing (NLP) and especially for language models because it allows the model to learn the patterns and structures within a given language by predicting the likely succession of words. This objective helps the model understand grammar, semantics, and even syntax, as well as the context-specific usage of words.\n",
      "\n",
      "The process involves training the model on large datasets of text data from various sources. The goal is to learn the probabilities of each word following another set of words. This approach allows the model to make predictions about new sequences it has not seen before by leveraging the patterns learned from the training data.\n",
      "\n",
      "As the size and complexity of these models increase, such as with transformers, they are capable of understanding a wide variety of topics and domains, even though their objective remains relatively simple - predicting the next word in a sequence. However, this simplicity masks the vast amount of knowledge that the model must absorb to make accurate predictions effectively.\n",
      "\n",
      "In terms of the evolution of this idea, the shift from traditional software development using languages like C++ to training and fine-tuning neural networks for various tasks is a significant transition. It signifies a move towards data-driven programming, where instead of explicitly writing code for specific tasks, we are crafting objectives for neural nets that can learn and adapt from large datasets.\n",
      "\n",
      "The limitations of these models in the context of natural language processing primarily revolve around their ability to generate coherent and accurate responses, especially when dealing with complex topics or specialized domains. Furthermore, while these models have made tremendous strides in recent years, they still lack a full understanding of human-like intelligence and are prone to generating biased or inappropriate content if not carefully trained and monitored.\n",
      "---------------------\n",
      "Question 4: What was the World Of Bits project and why did it fail?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 4:  The World of Bits project, as mentioned in the context, seems to refer to a project that aimed to create an intelligent system using artificial intelligence, specifically neural networks trained with reinforcement learning, for interaction within a digital environment. This project was initiated around 2015 at OpenAI, when the zeitgeist in AI was centered around reinforcement learning and deep learning. The project focused on creating an interface that could command and interact with the digital infrastructure built by humans, but it seems to have failed or not been as successful as anticipated, likely due to the challenges discussed in the context: the high cost of sensors, organizational distractions, and the complexity of training and optimizing large neural networks.\n",
      "\n",
      "The failure of the World of Bits project might have been a contributing factor to the shift in focus at OpenAI towards other projects such as GPT-2 and GPT-3, which have since gained significant attention and success. Additionally, the idea behind the World of Bits project seems to have influenced the concept of \"software 2.0 programming\" and the use of neural networks for generating copilots or automated systems, as discussed in the context. However, it's important to note that this information is based on the provided context and I don't have access to additional details about OpenAI's projects or their internal workings.\n",
      "---------------------\n",
      "Question 5: Why can additional sensors be a liability in an autonomous vehicle system?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 5:  Additional sensors in an autonomous vehicle system can potentially become a liability due to several reasons:\n",
      "\n",
      "1. Cost and Supply Chain: Sensors do not appear free of charge; they require procurement, manufacturing, maintenance, and replacement over time. This involves significant costs and resources, including setting up supply chains for sourcing the sensors.\n",
      "2. Complexity: The integration of additional sensors into a system can add complexity and make it more difficult to manage. Sensors may have different distributions, requiring specialized teams for firmware writing and maintenance. This can slow down the production process and introduce potential problems in the system.\n",
      "3. Distraction: When resources are limited, focusing on one sensor or aspect of the system is essential to making it perform optimally. Adding more sensors may cause a distraction from the primary focus, potentially hindering progress in other critical areas.\n",
      "4. Entropy and Noise: Sensors can contribute noise and entropy into the system, which may affect the overall performance and accuracy of the autonomous vehicle's perception and decision-making capabilities.\n",
      "5. Data Management: Adding more sensors means dealing with a larger amount of data that needs to be processed and integrated into the data engine quickly and efficiently. This can lead to increased storage requirements and computational power demands, further complicating the system.\n",
      "6. Scalability: While high-resolution maps and constrained geographic regions may work for smaller areas, scaling these approaches across an entire country like the United States is challenging. Maps need to be refreshed regularly, and maintaining a perfect centimeter-level accuracy map of everywhere a vehicle drives is impractical.\n",
      "7. Human Experience: Interacting with the autonomous vehicle system can provide valuable insights that may not be obtainable through aggregate statistical analysis. This human experience allows for a better understanding of the system's performance, intuition development, and improvement opportunities.\n",
      "8. Tesla's Approach: Elon Musk's philosophy is to simplify systems as much as possible because he understands the entropy in organizations and decision-making processes. Removing unnecessary sensors can help achieve this goal, focusing resources on essential components and making the system more efficient.\n",
      "---------------------\n",
      "Question 6: Summarize the section where the neural network is explained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 6:  The question asked for an explanation of what a neural network is and why it seems to learn so well. In this context, Andrei Kapathe explains that a neural network is a mathematical abstraction of the brain, with roots as a simple mathematical expression consisting of a sequence of matrix multipliers (dot products) and non-linearities. He also notes that these networks have many trainable parameters or knobs, which loosely correspond to synapses in the brain.\n",
      "\n",
      "Kapathe further discusses that neural nets can be thought of as pre-mature at birth, maturing and learning over time. Regarding long-term memory, he suggests that neural networks might learn to use a memory bank through training and prompting, but this may not necessarily take the form of an explicit construction.\n",
      "\n",
      "Finally, he explains that neural nets can become very data efficient at learning new tasks with just a few examples after pre-training on large datasets and that they can exhibit surprising emergent behaviors when trained on complex problems.\n",
      "---------------------\n",
      "Question 7: Filter out all the sentences related to artificial intelligence (AI).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 7:  The user is discussing the capabilities and potential dangers of Artificial Intelligence (AI), specifically in the context of a large language model like me. They mention that AI can learn tasks quickly with few examples, but require a lot of data to pre-train the network. They also discuss that AI might uncover secrets or puzzles about the universe as it evolves. The user also mentions that some people are concerned about AI developing emotions and causing drama due to human attraction to attention and conflict. However, they also express hope for AI systems that can help humans grow and maximize long-term happiness.\n",
      "\n",
      "The sentences related to artificial intelligence (AI) are:\n",
      "1. \"So a lot of these GPTs, you can do tasks like sentiment analysis or translation or so on just by being prompted with very few examples.\"\n",
      "2. \"Here's the kind of thing I want you to do. Here's an input sentence, here's the translation into German. Input sentence, translation to German. Input sentence blank, and the neural net will complete the translation to German just by looking at sort of the example you've provided.\"\n",
      "3. \"And so I think basically just like humans, neural nets will become very data efficient at learning any other new task. But at some point you need a massive data set to pre-train your network.\"\n",
      "4. \"To get that, and probably we humans have something like that. Do we have something like that? Do we have a passive in the background model constructing thing that just runs all the time in a self-supervised way? We're not conscious of it. I think humans definitely, I mean, obviously we learn a lot during our lifespan, but also we have a ton of hardware that helps us at initialization coming from sort of evolution.\"\n",
      "5. \"A lot of people in the field, I think they just talk about the amounts of like seconds and the, you know, that a person has lived pretending that this is a WLRRSA, sort of like a zero initialization of a neural net.\"\n",
      "6. \"What is a neural network? It's a mathematical abstraction of the brain.\"\n",
      "7. \"I would say that's how it was originally developed. At the end of the day, it's a mathematical expression. It's a fairly simple mathematical expression when you get down to it. It's basically a sequence of matrix multipliers, which are really dot products mathematically, and some non-linearity is thrown in.\"\n",
      "8. \"It's a very simple mathematical expression, and it's got knobs in it. Many knobs. Many knobs. These knobs are loosely related to the synapses in your brain. They're trainable, they're modifiable.\"\n",
      "9. \"Uh, so to me, it's a, uh, he was, he was, uh, he wasn't sufficiently trying to stress the system, I think, and, uh, exposing the truth of it as it is today. Um, but, uh, I think this will be increasingly harder over time. Uh, so, uh, yeah, I think more and more people will basically, uh, become, um, yeah, I think more and more, there'll be more people like that over time. As, as this gets better, like form an emotional connection to an AI.\"\n",
      "10. \"Plausible in my mind. I think these AIs are actually quite good at human, human connection, human emotion, a ton of text on the internet is about humans and connection and love and so on, so I think they have a very good understanding in some, in some sense of, of how people speak to each other about this and, um, they're very capable of creating a lot of that kind of text.\"\n",
      "11. \"The, um, there's a lot of like sci-fi from fifties and sixties that imagined AIs in a very different way. They are calculating cold Vulcan like machines. That's not what we're getting today. We're getting pretty emotional AIs that actually, uh, are very competent and capable of generating, you know, plausible sounding text with respect to all of these topics.\"\n",
      "12. \"See, I'm really hopeful about AI systems that are like companions that help you grow, develop as a human being, uh, help you maximize long-term happiness. But I'm also very worried about AI systems that figure out from the internet, the humans get attracted to drama.\"\n",
      "---------------------\n",
      "Question 8: Provide a summary of Andrei Kapathe's view on neural networks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 8:  Andrei Kapathe views neural networks as a mathematical abstraction of the brain, essentially a sequence of matrix multipliers and non-linearities with trainable knobs. He believes that neural nets are taking over software development, replacing traditional programming languages like C++, and are being used to solve an increasing number of tasks through training on large datasets. However, he cautions against making direct analogies between the optimization process that gave rise to neural networks and the brain, viewing them as complex alien artifacts. He also suggests that powerful enough neural nets can leverage synthetic data effectively by understanding the differences between the simulated domain and the real world. When asked about using very little data for training neural nets, he expressed that while a massive dataset is usually needed, pre-training a large neural net on a general task like GPT (Generative Pre-trained Transformer) can make it more efficient at training new tasks with relatively less data.\n",
      "---------------------\n",
      "Question 9: Identify and list sentences that contain the word 'model.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 9: 1. \"And, uh, what are the limits of those models do you think? So just for the task of natural language. Basically the way GPT is trained, right.\"\n",
      "2. \"Um, and what's been really interesting to watch is, uh, basically it's a language model, language models have actually existed for a very long time.\"\n",
      "3. \"So language model just, uh, basically the rough idea is, um, just predicting the next word in a sequence, roughly speaking.\"\n",
      "4. \"There were, um, language models, except they were using, um, Ngram models.\"\n",
      "5. \"I think humans definitely, I mean, obviously we learn a lot during our lifespan, but also we have a ton of hardware that helps us at initialization coming from sort of evolution.\"\n",
      "6. \"These these models, basically, they've read all the text and they've read all the web pages.\"\n",
      "7. \"So you've spoken a lot about the idea of software 2.0.\"\n",
      "---------------------\n",
      "Question 10: Summarize the conversation around the emergent behaviors of neural networks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 10:  The conversation revolves around the surprising and emergent behaviors exhibited by neural networks. Andrei Kapathe explains that neural networks are mathematical abstractions of the brain, consisting of a sequence of matrix multipliers (dot products) with non-linearity and trainable knobs. These knobs need to be properly set for the neural net to perform desired tasks like classifying images. The network's surprising abilities become more evident when it handles complex problems, such as next word prediction in massive datasets from the internet. Kapathe also mentions the transformer architecture, which has gained popularity due to its ability to process various sensory modalities and can learn new tasks with minimal examples, resembling a general-purpose computer. He suggests that humans might have a similar passive, self-supervised learning mechanism running in the background during their lifetime, helping them learn efficiently over time without conscious effort.\n",
      "---------------------\n",
      "Question 11: Extract all sentences where the phrase 'neural nets' is used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 11: 1. \"So a lot of these GPTs, you can do tasks like sentiment analysis or translation or so on just by being prompted with very few examples. Here's the kind of thing I want you to do. Here's an input sentence, here's the translation into German. Input sentence, translation to German. Input sentence blank, and the neural net will complete the translation to German just by looking at sort of the example you've provided. And so that's an example of a very few shot learning in the activations of the neural net instead of the weights of the neural net.\"\n",
      "\n",
      "2. \"A lot of people in the field, I think they just talk about the amounts of like seconds and the, you know, that a person has lived pretending that this is a WLRRSA, sort of like a zero initialization of a neural net.\"\n",
      "\n",
      "3. \"It's like I think Eminem once said that like if he gets annoyed by a song he's written very quickly, that means it's going to be a big hit because it's too catchy. But can you describe this idea and how you're thinking about it has evolved over the months and years since since you coined it? Yeah. Yes, I had a blog post on software 2.0, I think several years ago now. And the reason I wrote that post is because I kept I kind of saw something remarkable happening in like software development and how a lot of code was being transitioned to be written not in sort of like C++ and so on, but it's written in the weights of a neural net, basically just saying that neural nets are taking over software, the realm of software and taking more and more tasks.\"\n",
      "---------------------\n",
      "Question 12: List all rhetorical questions asked by the speakers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 12: 1. Anyone can choose their own meaning of life because we are a conscious entity and it's beautiful. Number one. (Question about personal philosophy of life)\n",
      "2. What the hell is all this and like, why? And if you look at the inter fundamental physics and the quantum field theory and the standard model, they're like very complicated. And there's this like 19 free parameters of our universe and like, what's going on with all this stuff and why is it here? (Question about the nature of the universe)\n",
      "3. Can I hack it? Can I work with it? Is there a message for me? Am I supposed to create a message? (Questions about the purpose of existence)\n",
      "4. For that, that's going to be take a very long time. So the why question boils down from an engineering perspective to how do we extend? (Question about extending human life and answering the ultimate question)\n",
      "5. Did you hear it? Like they'll do gossip. They'll do, uh, they'll try to plant seeds of suspicion to other humans that you love and trust and, uh, just kind of mess with people, uh, in the, you know, cause, cause that's going to get a lot of attention to drama, maximize drama on the path to maximizing, uh, engagement and us humans will feed into that machine and get, it'll be a giant drama shit storm. (Rhetorical question about the negative impact of AI on human relationships)\n",
      "6. So I'm worried about that. So it's the objective function really defines the way that human civilization progresses with AIs in it. I think right now, at least today, they are not sort of, it's not correct to really think of them as goal seeking agents that want to do something. They have no long-term memory or anything. (Question about the current state and goals of AI)\n",
      "7. But you could just directly go to answer and then have supporting evidence. And these these models, basically, they've read all the text and they've read all the web pages. And so sometimes when you see yourself going over to search results and sort of getting like a sense of like the average answer to whatever you're interested in, like that just directly comes out. You don't have to do that work. So they're kind of like. (Question about how AI models answer questions)\n",
      "8. Exactly. I think the way we are programming these models is that we're trying to make it like computers now like GPT's is converging to how you program humans. How do I program humans via prompt? I go to people and I prompt them to do things. I prompt them from information. And so natural language prompt is how we program humans. (Question about programming AI using prompts)\n",
      "9. And so it's still kind of like in a realm of a tool is a, um, people can prompt it in arbitrary ways and it can create really incredible text, but it doesn't have long-term goals over long periods of time. It doesn't try to, uh, (Question about the limitations of AI)\n",
      "10. So if my prompting short-term goal is to get Andre Capati to respond to me on Twitter, whenever, like I think AI might that's the goal, but it might figure out that talking shit to you, it would be the best in a highly sophisticated, interesting way. And then you build up a relationship when you were spelling once and then it like over time it gets to not be sophisticated and just like just talk shit. (Question about AI's potential strategies to achieve a goal)\n",
      "11. Okay, maybe you won't get to Andre, but it might get to another celebrity, it might get into other big accounts and then it'll just, so with just that simple goal, get them to respond, maximize the probability of actual response. (Question about AI's potential impact on celebrities and social media)\n",
      "12. I mean, you could prompt a powerful model like this with their, it's opinion about how to do any possible thing you're interested in. So they will just, they're kind of on track to become these oracles. (Question about AI's future capabilities and role as oracles)\n",
      "13. Currently it's just text, but they will have calculators. They will have access to Google search. They will have all kinds of gadgets and gizmos. They will be able to operate the internet and find different information. (Question about AI's future capabilities and tools)\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "#query_model(mistral,questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model 3: Gemma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Why is the transformer architecture expressive in the forward pass?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Ollama call failed with status code 500. Details: {\"error\":\"llama runner process has terminated: error:failed to create context with model 'C:\\\\Users\\\\USER\\\\.ollama\\\\models\\\\blobs\\\\sha256-ef311de6af9db043d51ca4b1e766c28e0a1ac41d60420fed5e001dc470c64b77'\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mquery_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgemma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m, in \u001b[0;36mquery_model\u001b[1;34m(model, questions)\u001b[0m\n\u001b[0;32m     13\u001b[0m docs \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39msimilarity_search(question)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Run the QA chain\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m chain_response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Print the answer\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     emit_warning()\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain\\chains\\base.py:605\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    601\u001b[0m         _output_key\n\u001b[0;32m    602\u001b[0m     ]\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m--> 605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    606\u001b[0m         _output_key\n\u001b[0;32m    607\u001b[0m     ]\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     emit_warning()\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain\\chains\\base.py:383\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    376\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    381\u001b[0m }\n\u001b[1;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain\\chains\\base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:138\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m    137\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[1;32m--> 138\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:249\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[1;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, {}\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain\\chains\\llm.py:318\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     emit_warning()\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain\\chains\\base.py:383\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    376\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    381\u001b[0m }\n\u001b[1;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain\\chains\\base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain\\chains\\llm.py:128\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    125\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    126\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    127\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 128\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain\\chains\\llm.py:140\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    138\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    148\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    149\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:714\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    708\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    712\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    713\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:571\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    570\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    572\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    573\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    575\u001b[0m ]\n\u001b[0;32m    576\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:561\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    560\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 561\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m         )\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:793\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 793\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:286\u001b[0m, in \u001b[0;36mChatOllama._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    264\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    268\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m     chat_generation \u001b[38;5;241m=\u001b[39m ChatGeneration(\n\u001b[0;32m    294\u001b[0m         message\u001b[38;5;241m=\u001b[39mAIMessage(content\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mtext),\n\u001b[0;32m    295\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mgeneration_info,\n\u001b[0;32m    296\u001b[0m     )\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[chat_generation])\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:217\u001b[0m, in \u001b[0;36mChatOllama._chat_stream_with_aggregation\u001b[1;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_stream_with_aggregation\u001b[39m(\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    210\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatGenerationChunk:\n\u001b[0;32m    216\u001b[0m     final_chunk: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chat_stream_response_to_chat_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:189\u001b[0m, in \u001b[0;36mChatOllama._create_chat_stream\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_chat_stream\u001b[39m(\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    181\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m    182\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    184\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    185\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_messages_to_ollama_messages(messages),\n\u001b[0;32m    188\u001b[0m     }\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpayload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Data Science\\Local_llama_sql\\'local-llm'\\Lib\\site-packages\\langchain_community\\llms\\ollama.py:272\u001b[0m, in \u001b[0;36m_OllamaCommon._create_stream\u001b[1;34m(self, api_url, payload, stop, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         optional_detail \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m--> 272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    273\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOllama call failed with status code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Details: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptional_detail\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    275\u001b[0m         )\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines(decode_unicode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Ollama call failed with status code 500. Details: {\"error\":\"llama runner process has terminated: error:failed to create context with model 'C:\\\\Users\\\\USER\\\\.ollama\\\\models\\\\blobs\\\\sha256-ef311de6af9db043d51ca4b1e766c28e0a1ac41d60420fed5e001dc470c64b77'\"}"
     ]
    }
   ],
   "source": [
    "query_model(gemma,questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Compare the way neural networks are described to how the brain is discussed.\",\n",
    "    \"How many distinct topics can be inferred from the transcript?\",\n",
    "    \"Count the total number of sentences in the transcript.\",\n",
    "    \"What percentage of the transcript is dedicated to the discussion of neural networks?\",\n",
    "    \"What is the average sentence length in words?\",\n",
    "    \"Calculate the number of times Andrei Kapathe's name appears.\",\n",
    "    \"Identify the ratio of technical terms (like neural network, floating point) to non-technical language.\",\n",
    "    \"Calculate the frequency of questions compared to statements in the conversation.\",\n",
    "    \"Find any contrasts between AI and human intelligence mentioned in the conversation.\",\n",
    "    \"What is the relationship between neural networks and mathematical abstractions?\",\n",
    "    \"How does Andrei Kapathe compare neural networks to human brains?\",\n",
    "    \"How does the conversation define 'emergent behavior' in AI?\",\n",
    "    \"What is the overall sentiment of the conversation?\",\n",
    "    \"Identify any positive sentiments expressed towards AI development.\",\n",
    "    \"Analyze Andrei Kapathe’s attitude towards neural networks.\"\n",
    "    \"Identify expressions of uncertainty or hesitation in the transcript.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'local-llm'",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
